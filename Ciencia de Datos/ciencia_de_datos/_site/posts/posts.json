[
  {
    "path": "posts/2021-05-27-modelos-lineales-generalizados/",
    "title": "Modelos lineales generalizados",
    "description": "Sobre los MLG.",
    "author": [
      {
        "name": "Eduardo Selim M. M.",
        "url": {}
      },
      {
        "name": "Carlos A. Ar.",
        "url": {}
      }
    ],
    "date": "2021-06-06",
    "categories": [
      "regresion"
    ],
    "contents": "\r\n\r\nContents\r\nFormulaci√≥n del modelo\r\nDefinici√≥n (familia lineal exponencial)\r\nEjemplo:\r\n\r\nFunciones link\r\nEjemplos\r\n\r\nEstimaci√≥n y predicci√≥n\r\nEstimaci√≥n m√°ximo veros√≠mil\r\nAlgunas propiedades\r\n\r\nEvaluaci√≥n de la bondad de ajuste\r\nDevianza\r\n¬øC√≥mo se obtiene la devianza?\r\npseudo\\(R^2\\)\r\nAIC y BIC\r\n\r\n\r\n\\[\r\n\\underbrace{g(y)}_{\\text{Funci√≥n } \\\\ \\text{de la respuesta.}} = \\beta_0 + \\beta_1x_1 + ... + \\beta_k x_k + \\epsilon\r\n\\]\r\nFormulaci√≥n del modelo\r\nHay dos componentes\r\nComponente 1\r\nComponente 2\r\nFamilia de distribuciones lineal exponencial. La elecci√≥n de una distribuci√≥n particular generalmente se ayuda de la naturaleza de la variable respuesta en un escenario.\r\nFunci√≥n link. Ya que se especific√≥ una distribuci√≥n de la familia lineal exponencial, se necesita relacionar a la media de la componente sistem√°tica\r\n\\[\r\n\\beta_0 + \\beta_1x_1 + ... + \\beta_k x_k + \\epsilon\r\n\\]\r\nDefinici√≥n (familia lineal exponencial)\r\nSe dice que una distribuci√≥n pertenece a la familia lineal exponencial si su funci√≥n de densidad se puede escribir como:\r\n\\[\r\nf(y; \\theta, \\phi) = \\exp\\bigg\\{ \\frac{y\\theta - b(\\theta)}{\\phi} + S(y,\\theta)\\bigg\\}\r\n\\]\r\ndonde\r\n\\(\\theta\\): Es el par√°metro de inter√©s (generalmente de la media).\r\n\\(\\phi\\): Par√°metro de escala.\r\n\\(b(\\theta)\\): Funci√≥n de \\(\\theta\\) (conocido)\r\n\\(S(y, \\phi)\\): Es una funci√≥n de \\(\\phi\\) (conocido)\r\nAfortunadamente, muchos de los distribudores que ya conocen pertenecen a la familia exponencial lineal\r\nBernoulli\r\nGamma\r\nBeta\r\nPoisson\r\nNormal\r\nGamma Inversa\r\nBinomial\r\nGeom√©trica\r\nGaussiana Invertida\r\n\r\nBinomial Negativa\r\n\r\nSi la distribuci√≥n de \\(Y\\) pertenece a la LED (Linear Exponencial Distribution) entonces\r\n\\[\r\n\\mu := \\mathbb{E}(Y) = b'(\\theta)\\\\\r\nVar(Y) = \\phi b''(\\theta)\r\n\\]\r\nEs √∫til explicar a la \\(Var(Y)\\) en t√©rminos de \\(\\mathbb{E}(Y)\\) i.e.¬†\\(Var(Y) = \\phi \\nu(\\mu)\\) a \\(\\nu(\\mu)\\) se le conoce como funci√≥n varianza.\r\nUna propiedad bonita en LED es que \\(\\nu(\\mu) = b''(\\theta)\\)\r\nEjemplo:\r\nSi \\(Y\\sim Poisson(\\lambda)\\), es decir, \\(f_Y(y) = \\frac{e^{-\\lambda}\\lambda^y}{y!} \\bigg|^y_{\\{0,1,...\\}}\\) ¬øY pertenece a la familia exponencial lineal? S√≠\r\nDemostraci√≥n.\r\n\\[\r\nf_Y(y) = \\frac{e^{-\\lambda}\\lambda^y}{y!} = \\exp\\{ -\\lambda + y\\log(y) - \\log(y!)\\} = \\exp\\{  y\\theta - e^\\theta - \\log(y!)\\}, \\\\ \\text{ donde } \\theta = \\log(\\lambda)\\\\\r\n\\\\\r\n\\therefore f_{Y} \\in LED_{\\Box}\r\n\\]\r\nEn el caso poisson se tiene que\r\n\\[\r\n\\theta = \\log(\\lambda)\\\\\r\nb(\\theta) = e^\\theta\\\\\r\n\\phi = 1\\\\\r\nS(y, \\phi) = -\\log(y!)\r\n\\]\r\n\\[\r\n\\Rightarrow\r\n\\]\r\n\\[\r\n\\mathbb{E}(Y) = b'(\\theta) = e^\\theta = \\lambda \\\\\r\nVar(Y) =\\phi b''(\\theta) = 1 \\cdot e^\\theta = \\lambda\r\n\\]\r\nQue es algo ya esperado\r\nFunciones link\r\nEsta relaciona a la media de la respuesta con la combinaci√≥n lineal de las variables explicativas i.e.\r\n\\[\r\ng(\\mu) = \\mathbb{x}^T \\beta = \\beta_0 + \\beta_1x_1 + ... + \\beta_k x_k \r\n\\]\r\nDonde \\((\\beta_0,.... \\beta_k) = \\beta\\) es un vector de par√°metros a estimar donde \\(g(\\cdot)\\) es mon√≥tona (creciente o decreciente).\r\nLa elecci√≥n de \\(g(\\cdot)\\) est√° motivada por la forma funcional entre la respuesta, y las variables explicativas.\r\nGML: Una LED para la respuesta & Una funci√≥n link\r\nHay una funci√≥n link especial, que reconoce como la funci√≥n link can√≥nica que satisface la siguiente:\r\n\\[\r\ng(\\mu) = \\theta\r\n\\] donde es el par√°metro de la LED.\r\nEjemplos\r\nNormal: \\(g(\\mu) = \\mu\\)\r\nBernoulli: \\(g(\\pi) = \\log(\\frac{\\pi}{1-\\pi})=: logit(\\pi)\\)\r\nPoisson: \\(g(\\mu) = \\log(\\mu)\\)\r\nGamma: \\(g(\\mu) = \\frac{1}{\\mu}\\)\r\nInversa Gaussiana: \\(g(\\mu) = \\frac{1}{\\mu^2}\\)\r\nRecordatorio: Para el caso Bernoulli\r\n\\[\r\n\\log\\bigg(\\frac{\\pi}{1-\\pi}\\bigg) = \\beta_0 + \\beta_1x_1 +... + \\beta_kx_k \r\n\\iff\r\n\\pi = \\frac{e^{\\beta_0 + \\beta_1x_1 + ... + \\beta_k x_k }}{1+e^{\\beta_0 + \\beta_1x_1 + ... + \\beta_k x_k }}\r\n\\]\r\nSi \\(\\pi \\geq 0.5 \\rightarrow \\hat{y} = 1\\)\r\nSi \\(\\pi < 0.5 \\rightarrow \\hat{y} = 0\\)\r\nRecordatorio: Poisson\r\n\\[\r\n\\log(\\lambda) = \\beta_0 + \\beta_1x_1 +... + \\beta_kx_k \\\\\r\n\\rightarrow \\lambda = \\exp\\{\\beta_0 + \\beta_1x_1 +... + \\beta_kx_k \\}\\\\\r\n\\rightarrow \\hat{\\lambda} = \\exp\\{\\hat{\\beta_0} + \\hat{\\beta_1}x_1 +... + \\hat{\\beta_k}x_k \\}\r\n\\]\r\nComo siempre hay que saber ¬øQu√© nos interesa?\r\nEstimar \\(\\beta'^s\\)\r\nLa variabilidad de los \\(\\beta'^s\\)\r\nBondad de ajuste: Devianza\r\nPoder de predicci√≥n\r\nConstrucci√≥n del modelo (selecci√≥n de variables explicativas).\r\nEstimaci√≥n y predicci√≥n\r\nSe observan \\(y_1, ..., y_n\\) independientes entre s√≠ todas de la familia exponencial lineal pero posiblemente con diferentes valores de \\(\\theta\\) y \\(\\phi\\) i.e.¬†\\(\\theta_1, ..., \\theta_n\\) y \\(\\phi_1, ..., \\phi_n\\) y por lo tanto diferentes medias.\r\nEstimaci√≥n m√°ximo veros√≠mil\r\nSea \\(L\\) la funci√≥n de verosimilitud. Como \\(f_{Y_i} \\in LED\\) Entonces:\r\n\\[\r\nL(\\beta) = \\prod_{i=1}^n f_{Y_i}(y_i) = \\prod_{i=1}^n \\exp\\bigg\\{\\frac{y_i\\theta_i - b(\\theta_i)}{\\phi_i} + S(y_i, \\phi_i)\\bigg\\}\r\n\\]\r\nAdem√°s vemos que se est√° utilizando el link can√≥nico y esto nos permitir√° escribir:\r\n\\[\r\nL(\\beta) = \\prod_{i=1}^n \\exp\\bigg\\{\\frac{y_i (\\mathbb{x}_i^{_T}\\beta) - b(\\mathbb{x}_i^{_T}\\beta)}{\\phi_i} + S(y_i, \\phi_i)\\bigg\\}\r\n\\]\r\nComo antes, preferimos obtener la log-verosimilitud.\r\n\\[\r\nl(\\beta) = \\log(L(\\beta)) = \\sum_{i=1}^n \\bigg(\\frac{y_i (\\mathbb{x}_i^{_T}\\beta) - b(\\mathbb{x}_i^{_T}\\beta)}{\\phi_i} + S(y_i, \\phi_i)\\bigg)\r\n\\]\r\nPara encontrar el estimador m√°ximo veros√≠mil,\r\n\\[\r\n\\text{Ecuaci√≥n score:}\\\\\r\n\\boxed{\\frac{\\partial}{\\partial \\beta} l(\\beta) = \\underline{0}}\r\n\\]\r\nEn este caso\r\n\\[\r\n\\frac{\\partial}{\\partial \\beta} l(\\beta) = \\sum_{i=1}^n \\bigg(\\frac{y_i \\mathbb{x}_i - b'(\\mathbb{x}_i^{_T}\\beta)\\mathbb{x}_i}{\\phi_i}\\bigg) = \\sum_{i=1}^n \\bigg(\\frac{y_i \\mathbb{x}_i - \\mu_i\\mathbb{x}_i}{\\phi_i}\\bigg) = \\sum_{i=1}^n \\bigg(\\frac{y_i  - \\mu_i}{\\phi_i}\\bigg)\\mathbb{x}_i\r\n\\]\r\nSe tiene que resolver\r\n\\[\r\n\\sum_{i=1}^n \\bigg(\\frac{y_i  - \\mu_i}{\\phi_i}\\bigg)\\mathbb{x}_i = \\underline{0} = \\begin{pmatrix}\r\n0 \\\\\r\n   \\vdots \\\\\r\n 0\r\n \\end{pmatrix}\r\n\\]\r\n‚ÄúMala‚Äù noticias. Esto se resuelve num√©ricamente\r\nAfortunadamente lo hace R o Python.\r\nResumiendo\r\nSup√≥ngase que se desea estimar\r\n\\[\r\n\\beta = (\\beta_0, ..., \\beta_k) \\rightarrow \\hat{\\beta} = (\\hat{\\beta}_0, ..., \\hat{\\beta}_k)\r\n\\]\r\nPaso 1: Calcular el valor estimado de la ‚Äúlinked mean‚Äù\r\n\\[\r\ng(\\hat{\\mu}) = \\mathbb{x}^T \\hat{\\beta} = \\hat{\\beta_0} + \\hat{\\beta_1}x_1 + ... + \\hat{\\beta_k} x_k \r\n\\]\r\nPaso 2: Invertir \\(g\\), para obtener la media ajustada/estimada, i.e.\r\n\\[\r\n\\hat{\\mu} = g^{-1} (\\mathbb{x}^{_T}\\hat{\\beta})\r\n\\]\r\nNotaci√≥n. Sea la notaci√≥n \\(\\mu\\) √≥ \\(\\hat{y}\\) para denotar a la media ajustada.\r\nAlgunas propiedades\r\n\\(\\mu\\) es el estimador m√°ximo veros√≠mil de \\(\\mu = g^{-1}(\\underline{x}^{_T}\\beta)\\)\r\nEste es:\r\nConsistente\r\nAsint√≥ticamente insesgado\r\nAsint√≥ticamente gaussiano\r\nLa propiedad que hace especial a la funci√≥n link can√≥nica es que el estimado es insesgado.\r\nEjemplo\r\nEn el caso Bernoulli \\(g(\\pi) = \\log(\\frac{\\pi}{1-\\pi})\\) ¬øQui√©n es \\(g^{-1}(t)\\)?\r\nSea \\(z = \\log(\\frac{\\pi}{1-\\pi})\\), despejemos a \\(\\pi\\)\r\n\\[\r\ne^{z} = \\frac{\\pi}{1-\\pi} \\iff e^z-\\pi e^z = \\pi \\iff e^z = \\pi(1+e^z) \\iff \\pi = \\frac{e^z}{1+e^z} \\\\\r\n\\therefore g^{-1}(t) = \\frac{e^t}{1+e^t} \r\n\\]\r\nEntonces nos recuerda a un viejo conocido üë¥üèª\r\n\\[\r\n\\hat{\\pi} = \\frac{e^{\\mathbb{x}^{_T} \\hat{\\beta}}}{1+e^{\\mathbb{x}^{_T} \\hat{\\beta}}} \\\\\r\n \\text{Probabilidades estimadas en el modelo de regresi√≥n log√≠stica}\r\n\\]\r\nEvaluaci√≥n de la bondad de ajuste\r\nEl GLM ya no se tiene la descomposici√≥n\r\n\\[\r\nTSS = RSS + RegSS\r\n\\]\r\nüò¢ Por lo tanto no est√° definido el coeficiente de determinaci√≥n \\[R^2\\] üò¢\r\nLas medidas comunes son la devianza y la pseudo \\(R^2\\)\r\nModelo Saturado\r\nEl modelo saturado es uno con la misma distribuci√≥n que la respuesta y funci√≥n link que el GLM ajustado pero con tantos par√°metros como observaciones.\r\nEsto permite maximizar la funci√≥n de verosimilitud sobre una base observaci√≥n por observaci√≥n.\r\n\r\n¬øQu√© significa esto?\r\nEl modelo saturado es tal que los valores ajustados son exactamente iguales a los valores observados, i.e.\r\n\\[\r\n\\underbrace{\\hat{\\mu}_i = y_i}_{\\text{bajo el modelo saturado}} \\text{ para todo } i = 1,...,n\r\n\\]\r\n¬øY la justificaci√≥n matem√°tica?\r\n\\[\r\n\\frac{\\partial}{\\partial \\theta_i} \\log(f(y_i;\\theta_i,\\phi_i)) = \\frac{y_i - \\overbrace{b'(\\theta_i)}^{\\hat{\\mu_i}}}{\\phi_i} = 0\r\n\\]\r\npor lo tanto, la media ajustada \\(\\hat{\\mu}_i = b'(\\hat{\\theta_i})\\) es igual al valor de la respuesta observada \\(y_i\\), i.e.¬†el modelo saturado genera un ajuste perfecto.\r\nEl modelo m√°s elaborado proporciona el mejor ajuste, por lo tanto debe tener la log-verosimilitud m√°s alta (que cualquier otro GLM ajustado)\r\nDevianza\r\nLa devianza es una medida de bondad de ajuste que se basa en la verosimilitud.\r\nMide cu√°nto se desv√≠a el GLM ajustado, en t√©rminos de la log-verosimilitud, del GLM ‚Äúm√°s elaborado‚Äù, que se conoce como el modelo saturado.\r\n\r\nDefinici√≥n.\r\n\\[\r\nD = 2(l_{\\text{SAT}} - \\underbrace{l}_{\\text{modelo que} \\\\ \\text{estoy evaluando}})\r\n\\]\r\nUna devianza grande es indicativo de un ajuste pobre.\r\nUna devianza peque√±a es indicativo de buen ajuste.\r\n¬øC√≥mo se obtiene la devianza?\r\nPaso 1: Escribir una expresi√≥n gen√©rica para la funci√≥n de verosimilitud, en t√©rminos de las medias desconocidas \\(\\mu_1, ..., \\mu_n\\) (Recu√©rdese que se est√° inclinado a tratar a la media como un par√°metro GLM).\r\nPaso 2: Hacer las sustituciones\r\n\\(\\mu_i \\mapsto y_i\\) para el modelo saturado. Con esto tenemos \\(l_{\\text{SAT}}\\)\r\n\\(\\mu_i \\mapsto \\hat{\\mu}_i\\) para el modelo saturado. Con esto tenemos \\(l\\)\r\n\r\nPaso 3: Hacer el c√°lculo \\(D = 2(l_{SAT} - l)\\) en t√©rminos de \\(y_i'^s\\) y \\(\\hat{\\mu}_i'^s\\)\r\nEjemplo (Regresi√≥n Poisson)\r\nPara el caso de que \\(y_1, ... , y_n\\) tenga distribuci√≥n Poisson con medias \\(\\mu_1, ..., \\mu_n\\) respectivamente:\r\nPaso 1: Expresi√≥n gen√©rica: \\[\\begin{align*}\r\nl(\\mu_1, ..., \\mu_n) \r\n&= \\log\\bigg(\\prod_{i=1} ^n f(y_i)\\bigg) \\\\\r\n& = \\log\\bigg(\\prod_{i=1} ^n \\frac{e^{-\\mu_i}\\mu_i^{y_i}}{y_i!}\\bigg) \\\\\r\n&= \\sum_{i=1}^n \\bigg(-\\mu_i +y_i\\log(\\mu_i) - \\log(y_i!)\\bigg)\r\n\\end{align*}\\]\r\nPaso 2: Hacer las sustituciones\r\n\\(\\mu_i \\mapsto y_i\\) para el modelo saturado.\r\n\\[\r\nl_{SAT} = \\sum_{i=1}^n \\bigg(-y_i +y_i\\log(y_i) - \\log(y_i!)\\bigg)\r\n\\]\r\n\\(\\mu_i \\mapsto \\hat{\\mu}_i\\) para el modelo saturado.\r\n\\[\r\nl = \\sum_{i=1}^n \\bigg(-\\hat{\\mu}_i +y_i\\log(\\hat{\\mu}_i) - \\log(y_i!)\\bigg)\r\n\\]\r\n\r\nPaso 3:\r\n\\[\r\n\\begin{align*}\r\nD &= 2(l_{SAT} -l) = 2\\sum_{i=1}^n \\bigg( \\hat{\\mu}_i - y_i + y_i(\\log(y_i) - \\log(\\hat{\\mu}_i)) \\bigg) \\\\\r\n&= 2\\sum_{i=1}^n \\bigg( y_i\\log(\\frac{y_i}{\\hat{\\mu}_i})  - (y_i -  \\hat{\\mu}_i) \\bigg) \r\n\\end{align*}\r\n\\]\r\n\\(D\\) debe ser peque√±o. Intuitivamente ‚ÄúSi tengo 2 modelos, me quedo con el de devianza menor‚Äù\r\npseudo\\(R^2\\)\r\nDefinici√≥n.\r\n\\[\r\npseudoR^2 = \\frac{l - l_{IID}}{l_{SAT} - l_{IID}}\r\n\\]\r\npseudo\\(R^2 \\in (0,1)\\)\r\npseudo\\(R^2\\) grande es indicativo de mejor ajuste del modelo.\r\nDonde:\r\n\\(l_{\\text{SAT}}\\): log-verosimilitud del modelo saturado.\r\n\\(l\\): log-verosimilitud del GLM en consideraci√≥n.\r\n\\(l_{\\text{IID}}\\): log-verosimilitud cl√°sica que se aprende en Inferencia Estad√≠stica.\r\nAIC y BIC\r\nSe tiene inter√©s en pruebas de hip√≥tesis y 2 criteriors de selecci√≥n de modelos\r\nAIC = \\(-2l + 2p\\)\r\nBIC = \\(-2l + p\\log(n)\\)\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2021-06-08T10:01:15-05:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-06-05-modelos-lineales-generalizados-2/",
    "title": "Modelos lineales generalizados 2",
    "description": "Sobre los MLG.",
    "author": [
      {
        "name": "Eduardo Selim M. M.",
        "url": {}
      },
      {
        "name": "Carlos A. Ar.",
        "url": {}
      }
    ],
    "date": "2021-06-06",
    "categories": [
      "regresion"
    ],
    "contents": "\r\n\r\nContents\r\nGamma e Inversa Gaussiana\r\nPrueba de devianza\r\n\r\n¬øPor qu√© escoger la funci√≥n link de esta forma? ¬øC√≥mo la encontramos en general?\r\n\\[\r\n\\boxed{g(\\mu) = \\underline{x}^T\\beta}\r\n\\]\r\nHip√≥tesis de la funci√≥n link can√≥nica\r\n\\(g(\\mu) = \\theta\\) donde \\(\\theta\\) proviene de la parametrizaci√≥n como miembro de la familia exponencial. Lo anterior implica:\r\n\\[\r\ng(\\mu) = \\theta \\underbrace{\\Rightarrow}_{\\mu = b'(\\theta) \\\\ \\text{en familia} \\\\ \\text{LED}} g(b'(\\theta)) = \\theta\\\\\r\n\\Rightarrow b'(\\theta) = g^{-1}(\\theta) \\Rightarrow g(\\theta) = (b'(\\theta))^{-1}, \\text{ donde -1 es de la funci√≥n inversa.}\r\n\\]\r\nPara obtener la funci√≥n link can√≥nica vemos, se debe cumplir que\r\n\\[\r\n\\boxed{g(\\theta) = \\bigg(b'(\\theta)\\bigg)^{-1}}\r\n\\]\r\nEjemplos:\r\nSi \\(Y \\sim Poisson(\\lambda)\\), es decir, \\(f_Y(y) = \\frac{e^{-\\lambda}\\lambda^y}{y!} 1_{\\{0, 1, ...\\}}^{(y)}\\) ¬øY pertenece a la familia exponencial lineal? S√≠\r\n\\[\r\n\\begin{align*}\r\n\\frac{e^{-\\lambda}\\lambda^y}{y!}  &= \\exp\\{-\\lambda + y\\log(\\lambda) - \\log(y!)\\} = \\exp\\{y\\theta - e^{\\theta} - \\log(y!)\\} \\\\\r\n&\\text{Donde } \\\\\r\n&\\theta = \\log(\\lambda) \\\\\r\n&b(\\theta) = e^\\theta\\\\\r\n&\\phi = 1 \\\\\r\n&S(y, \\phi) = -\\log(y!) \\\\\r\n\\mathbb{E}(Y) &= b'(\\theta) = e^\\theta = e^{\\log(\\lambda)} = \\lambda \\text{ (como ya esper√°bamos}) \\\\\r\nVar(Y) &= \\phi\\cdot b'(\\theta)\r\n\\end{align*}\r\n\\]\r\nEn este caso, la funci√≥n link can√≥nica es\r\n\\[\r\nb(\\theta)  = e^\\theta, b'(\\theta) = e^\\theta \\\\\r\n\\Rightarrow g(\\theta) = \\bigg(b'(\\theta)\\bigg)^{-1} = \\log(\\theta)\r\n\\]\r\nSi \\(Y \\sim Bnlli(p)\\), es ddecir \\(f(y) = p^y(1-p)^{1-y}\\) ¬øPertenece a la familia exponencial lineal? S√≠\r\n\\[\r\n\\begin{align*}\r\nf(y) &= p^y(1-p)^{1-y} = e^{y\\log(p) + (1-y)\\log(1-p)}\\\\\r\n&= \\exp\\bigg\\{ y\\big[\\log(p) - \\log(1-p)\\big] + \\log(1-p)\\bigg\\} \\\\\r\n&= \\exp\\bigg\\{  y\\log\\bigg( \\frac{p}{1-p}\\bigg) + \\log(1-p) \\bigg\\} \\\\\r\n&= \\exp\\bigg\\{  \\frac{y\\theta-\\log(1+ e^\\theta)}{1} + 0 \\bigg\\} \\\\\r\n\\text{De donde } \\\\\r\n\\theta &= \\log(\\frac{p}{1-p}) \\iff p = \\frac{e^\\theta}{ 1 + e^\\theta} \\\\\r\n\\Rightarrow \\log(1-p) &= \\log\\bigg( 1- \\frac{e^\\theta}{ 1 + e^\\theta} \\bigg) = \\log\\bigg(\\frac{1}{ 1 + e^\\theta} \\bigg) = -\\log(1+e^\\theta) \\\\\r\nb(\\theta) &= \\log(1+ e^\\theta) \\rightarrow b'(\\theta) = \\frac{e^\\theta}{1+e^\\theta}\\\\\r\n\\therefore g(\\theta) &= \\bigg(b'(\\theta)\\bigg)^{-1} = \\log\\bigg(\\frac{\\theta}{1-\\theta}\\bigg)\r\n\\end{align*}\r\n\\]\r\nGamma e Inversa Gaussiana\r\nCuando \\(Y\\) se distribuye Gamma o Inversa Gaussiana, es decir, que su resultado es positivo ‚Äúcontinuo‚Äù con un sesgo (√≥ ligero sesgo) hacia la derecha, tenemos lo siguiente:\r\nGamma\r\n\\[\r\nb(\\theta) = -\\log(\\theta) \\\\\r\nb'(\\theta) = -\\frac{1}{\\theta} \\\\\r\ng(\\mu) = -\\frac{1}{\\mu}\r\n\\]\r\nInversa Gaussiana\r\n\\[\r\nb'(\\theta) = (-2\\theta)^{\\frac{-1}{2}} \\\\\r\ng(\\mu) = \\frac{-1}{2 \\mu^2} \\propto \\frac{1}{\\mu^2}\r\n\\]\r\n\r\nPrueba de devianza\r\nLa prueba de hip√≥tesis m√°s popular para este caso es:\r\n\\[\r\nH_0: \\underbrace{\\beta_1 = \\beta_2 = ...= \\beta_r = 0}_{\\text{un subconjunto de variables}\\\\ \\text{\"explicativas\" no tiene uso}} \\space \\space \\space \\space \\space \\space \\space \\space \\space v.s. \\space \\space \\space \\space \\space \\space \\space \\space \\space H_a: \\text{No hay restricciones sobre los }\\beta'^s \r\n\\]\r\nLa estad√≠stica de prueba es:\r\n\\[\r\nLST := 2(l_1 - l_0)\r\n\\]\r\nDonde \\(l_1, l_0\\) son las verosimilitudes bajo la hip√≥tesis alternativa y nula, respectivamente.\r\nMientras m√°s grande sea LRT (Likehood Ratio Test), m√°s evidencia se tendr√° en contra de \\(H_0\\) (en favor de \\(H_a\\))\r\nN√≥tese que\r\n\\[\r\n\\begin{align*}\r\nLRT &= 2 (l_1- l_0) = 2(l_1 - l_{SAT} - l_0 + l_{SAT}) \\\\\r\n&= \\underbrace{2(l_{SAT} - l_0)}_{\\text{Devianza del} \\\\ \\text{modelo en la} \\\\ \\text{hip√≥tesis nula}} - \\underbrace{2(l_{SAT} - l_1)}_{\\text{Devianza del} \\\\ \\text{modelo en la} \\\\ \\text{hip√≥tesis alternativa}} \\\\\r\n&= D_0 - D_1\r\n\\end{align*}\r\n\\]\r\nA esta prueba se le conoce como Prueba de diferencias de devianza √≥ Prueba de devianza.\r\nRegi√≥n de rechazo\r\nBajo \\(H_0, LRT \\sim \\chi^2_{(r)}\\). Se rechaza \\(H_0\\) si \\(LRT_{obs} > \\underbrace{\\chi^2_{r, \\alpha}}_{\\text{upper cuantil} \\\\ \\text{al nivel } \\alpha}\\)\r\n\r\nDebe ser \\(D_0\\) mayor a \\(D_1\\) pues la estad√≠stica de prueba debe ser positiva, pues el modelo bajo \\(H_0\\) es m√°s restringido, por lo tanto, se aleja m√°s del modelo saturado que bajo \\(H_a\\).\r\n\r\n\r\n\r\n",
    "preview": "posts/2021-06-05-modelos-lineales-generalizados-2/images/mlg2_1.png",
    "last_modified": "2021-06-08T09:57:05-05:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-06-01-series-de-tiempo/",
    "title": "Series de tiempo",
    "description": "Series de tiempo",
    "author": [
      {
        "name": "Eduardo Selim M. M.",
        "url": {}
      },
      {
        "name": "Carlos A. Ar.",
        "url": {}
      }
    ],
    "date": "2021-06-01",
    "categories": [
      "series de tiempo"
    ],
    "contents": "\r\n\r\nContents\r\nAlgunas definiciones\r\nRuido blanco\r\nEstacionariedad d√©bil\r\nAutocorrelaci√≥n con lag \\(k\\)\r\nAutocorrelaci√≥n muestral con lag \\(k\\)\r\nPron√≥stico en ruido blanco (Gaussiano)\r\n\r\nCaminata aleatoria\r\nPron√≥stico en caminata aleatoria\r\nIdentificaci√≥n de una caminata aleatoria\r\n\r\nFiltros\r\nTransformaci√≥n logar√≠tmica\r\nTendencia lineal v.s. caminata aleatoria\r\nPrueba de Dickey-Fuller\r\nVersi√≥n aumentada de Dickey-Fuller\r\n\r\nModelos estacionales\r\nModelos de efectos estacionales fijos\r\n\r\nSuavizamiento (smoothing)\r\nPromedios m√≥viles (moving average)\r\nSuavizamiento exponencial simple\r\n\r\nModelo AR de primer orden (AR(1))\r\nPropiedades del modelo AR(1) estacionario\r\nEstimaci√≥n de par√°metros en AR(1)\r\nResiduales\r\nPredicci√≥n en el modelo AR(1)\r\n\r\n\r\nAlgunas definiciones\r\nLas expresiones de ‚Äúdatos en series de tiempo‚Äù √≥ ‚Äúseries de tiempo‚Äù se refieren a conjuntos de observaciones tomadas en forma secuencial a trav√©s del tiempo.\r\n\r\nEn este caso de puntos que observamos de manera secuencial, usaremos la notaci√≥n \\(\\{x_t\\}_{t\\in\\mathbb{N}^+}\\) si las observaciones est√°n equiespaciadas a lo largo del tiempo.\r\nEjemplo:\r\n\\[\r\nx_1:\\text{ observaci√≥n de hoy} \\\\\r\nx_2:\\text{ observaci√≥n de ma√±ana}\\\\\r\nx_3:\\text{ observaci√≥n de pasado ma√±ana}\r\n\\]\r\nno siempre las series las observaciones de manera equiespaciadas\r\nEjemplo:\r\n\\(\\{x_{t_j}\\}_{j \\in \\mathbb{N}}\\) si las observaciones no est√°n igualmente espaciadas. Observaciones de:\r\n\\[\r\nx_{t_1}: 16 \\text{ abril } 2021 \\\\ \r\nx_{t_2}: 19 \\text{ abril } 2021 \\\\\r\nx_{t_3}: 10 \\text{ mayo } 2021 \\\\\r\nx_{t_4}: 15 \\text{ mayo } 2021\r\n\\]\r\nEl caso m√°s popular es el equiespaciado\r\nUno de los objetivos del an√°lisis de series de tiempo es estudiar la estructura de dependencia de la serie de tiempo.\r\nDe manera m√°s formal\r\nEstructura distribucional, i.e.¬†la funci√≥n de distribuci√≥n conjunta de la serie \\(F_{x_{t_1}, x_{t_2}, ..., x_{t_n}}\\) decimos que el an√°lisis es de primer orden,\r\nEstructura observacional, i.e.¬†la asociaci√≥n de correlaci√≥n entre las observaciones de la serie, decimos que el an√°lisis es de 2¬∞ orden.\r\nDefinici√≥n. Un proceso de serie de tiempo, es un proceso estoc√°stico, i.e.¬†es una colecci√≥n de variables aleatorias \\(\\{x_t\\}_{t\\in T}\\) en el mismo espacio de probabilidad \\((\\Omega, \\mathcal{F}, \\mathbb{P})\\).\r\nSe dice que la serie es a tiempo discreto si \\(T \\subset \\mathbb{Z}\\)\r\nSe dice que la serie es a tiempo continuo si \\(T \\sim \\mathbb{R}, T = [0, \\infty), T = [a, b]\\)\r\nPara \\(\\omega \\in \\Omega\\) fijo, la aplicaci√≥n \\(t \\mapsto X_t(\\omega)\\) es ima trayectoria √≥ una realizaci√≥n del proceso.\r\nDefinici√≥n. Se dice que un proceso estoc√°stico \\(\\{x_t\\}_{t\\in T}\\) es completamente estacionario o fuertemente estacionario si \\(\\forall t_1, ..., t_n \\in T, \\forall t \\in \\mathbb{R}\\) tal que \\(t_1 +t,t_2 +t, ..., t_n +t \\in T\\).\r\n\\[\r\nF_{X_{t_1}, X_{t_2}, ..., X_{t_n}} (a_1, a_2, ..., a_n) = F_{X_{t_1 + t}, X_{t_2+ t}, ..., X_{t_n+ t}} (a_1, a_2, ..., a_n)  \r\n\\]\r\ni.e.¬†el vector \\((X_{t_1}, X_{t_2}, ..., X_{t_n})\\) tiene la misma funci√≥n de distribuci√≥n que el vector \\((X_{t_1 + t}, X_{t_2+ t}, ..., X_{t_n+ t})\\)\r\nEn general, pedir que un proceso sea fuertemente estacionario es bastante ambicioso y en la pr√°ctica resulta bastante complicado de verifican. Dada esta condici√≥n excesiva, surge el concepto de estacionariedad d√©bil.\r\nDefinici√≥n. Se dice que un proceso \\(\\{X_t\\}_{t \\in T}\\) es d√©bilmente estacionario (√≥ estacionario de segundo orden) si \\(\\forall n \\in \\mathbb{N_+}, \\forall t_1, t_2, ..., t_n \\in T, \\forall t \\in \\mathbb{R}\\) tal que \\(t_1+t, t_2+t, ..., t_n+t \\in T\\). Todos los momentos de orden 1 y 2 del vector \\((X_{t_1}, X_{t_2}, ..., X_{t_n})\\) son iguales a los correspondientes momentos de orden 1 y 2 del vector \\((X_{t_1 + t}, X_{t_2+ t}, ..., X_{t_n+ t})\\) es decir\r\n\\[\r\n\\mathbb{E}\\bigg[ X_{t_1}^{r_1} X_{t_2}^{r_2} ... X_{t_n}^{r_n}\\bigg] = \\mathbb{E}\\bigg[ X_{t_1+t}^{r_1} X_{t_2+t}^{r_2} ... X_{t_n+t}^{r_n}\\bigg] \r\n\\]\r\ncon \\(r_1, ..., r_n \\in \\mathbb{N}\\) tal que \\(r_1+r_2 +...+ r_n \\leq 2\\).\r\nCondiciones a verificar para estacionariedad d√©bil\r\n\\[\r\nr_j = 1, r_i = 0 \\\\\r\nr_i = 1, r_j = 1 \\\\\r\nr_i = 2, r_j = 0 \r\n\\]\r\nEsto se reduce a\r\n\\[\r\n\\mathbb{E}(X_{t_j}) = \\mathbb{E}(X_{t_j + t}) \\\\\r\n\\mathbb{E}(X_{t_i} X_{t_j}) = \\mathbb{E}(X_{t_i + t} X_{t_j + t}) \\\\\r\n\\mathbb{E}(X_{t_j} ^2) = \\mathbb{E}(X_{t_j + t}^2) \r\n\\]\r\nEs se reduce a verificar\r\n\\[\r\nCov(X_\\tau, X_s) = Cov(X_{\\tau+t}, X_{s+t})\r\n\\]\r\nTodo ruido blanco es d√©bilmente estacionario.\r\nPero no todo proceso d√©bilmente estacionario es ruido blanco.\r\nEl an√°lisis tradicional de series de tiempo descompone a la serie observada de la siguiente manera.\r\n\\[\r\nX_t = \\underbrace{m_t}_{\\text{componente}\\\\\\text{de tendencia}} + \\underbrace{S_t}_{\\text{componente}\\\\ \\text{estacional} \\\\ \\text{(seasonality)}} + \\underbrace{Y_t}_{\\text{componente}\\\\\\text{aleatoria}}\r\n\\]\r\n\r\nLos objetivos al hacer an√°lisis de series de tiempo son\r\nEstimar \\(m_t, S_t\\)\r\nEstimar \\(Y_t\\)\r\nEncontrar un modelo adecuado para este de entre un cat√°logo de modelos.\r\nEstimar par√°metros.\r\n\r\n\r\nHacer predicciones.\r\nRuido blanco\r\n\\(y_t \\rightarrow\\) Las \\(Y_t'^s\\) son independientes e identicamente distribuidas (generalmente Gaussianas)\r\nEstacionariedad d√©bil\r\nSe dice que una serie de tiempo \\(\\{y_t\\}\\) es d√©bilmente estacionaria √≥ estacionaria de segundo orden si:\r\n\\(\\mathbb{E}(y_t)\\) no depende de \\(t\\)\r\n\\(Cov(y_t, y_s)\\) depende de \\(s\\) y \\(t\\) s√≥lo a trav√©s del lapso de tiempo \\(|t-s|\\)\r\nComo consecuencia, \\(Var(y_t)\\) no depende de \\(t\\)\r\n\r\nAutocorrelaci√≥n con lag \\(k\\)\r\n\\[\r\n\\rho_k = Corr(y_t, y_{t-k}) = \\frac{Cov(y_t, y_{t-k})}{\\sqrt{Var(y_t)Var(y_{t-k})}} = \\frac{Cov(y_t, y_{t-k})}{\\sigma_y^2}\r\n\\]\r\nLibros\r\nBrockwell & Davis. Intro to time series\r\nTibshiarani et. al.¬†Intro to Statistical Learning.\r\nFrees. Regression Techniques for actuarial applications.\r\nAutocorrelaci√≥n muestral con lag \\(k\\)\r\n\\[\r\nr_k := \\frac{\\displaystyle\\sum_{t = k+1}^\\tau (y_{t} - \\bar{y})(y_{t-k} - \\bar{y})}{\\displaystyle\\sum_{t =1}^\\tau(y_{t} - \\bar{y})^2}\r\n\\]\r\ndonde\r\n\\[\r\n\\bar{y} = \\frac{1}{\\tau}\\sum_{t = 1}^\\tau y_t\\\\\r\n\\\\\r\n\\\\\r\ny_1 \\space \\space \\space \\space \\space y_2 \\space \\space \\space \\space \\space ... \\space \\space \\space \\space \\space y_{\\tau-k} \\\\\r\n\\updownarrow \\space \\space \\space \\space \\space \\space \\space \\updownarrow \\space \\space \\space \\space \\space ... \\space \\space \\space \\space \\space \\space \\space \\updownarrow \\\\\r\ny_{k+1} \\space \\space \\space \\space \\space y_{k+2} \\space \\space \\space \\space \\space ... \\space \\space \\space \\space \\space y_{\\tau} \r\n\\]\r\nPron√≥stico en ruido blanco (Gaussiano)\r\nSean \\(y_1, ..., y_T\\) observaciones\r\n\\(\\hat{y}_{T+l} = \\bar{y} =\\displaystyle \\frac{1}{T} \\sum_{t = 1}^T y_t\\)\r\nError de pron√≥stico\r\n\\[\r\ny_{T+l} - \\underbrace{\\bar{y}}_{\\hat{y}_{T+l}} \\sim N(0 , \\sigma^2(1+\\frac{1}{T}))\r\n\\]\r\nIntervalo forecast √≥ intervalos de predicci√≥n\r\n\\[\r\n\\bar{y} \\pm \\underbrace{t_{T-1, \\frac{\\alpha}{2}}}_{\\text{upper-cuantile}} \\sqrt{S_y ^2 \\bigg(1+ \\frac{1}{T}\\bigg)}\r\n\\]\r\nSi T es grande, al \\(95\\%\\)\r\n\\[\r\n\\bar{y} \\pm 1.96\\sqrt{S_y^2} = \\bar{y} \\pm 1.96S_y\r\n\\]\r\nCaminata aleatoria\r\n\\[\r\ny_t = y_0 + \\sum_{i=1} ^t c_i, \\{c_i\\} \\text{ es un ruido blanco}\r\n\\]\r\nAfirmaciones\r\n\\(\\mathbb{E}(y_t) = y_0 + t\\cdot \\mu_c\\)\r\n\\(Var(y_t) = t\\cdot \\sigma^2_c\\)\r\n\\(Cov(y_t, y_s) = min\\{s, t\\}\\cdot\\sigma^2\\)\r\nLa caminata aleatoria no es estacionaria.\r\nDemostraci√≥n: t√∫ puedes üëèüèª\r\nPron√≥stico en caminata aleatoria\r\n\\(y_{T+l} = y_T + \\displaystyle\\sum_{t = T+1}^{T+l} c_k\\)\r\n\\(\\hat{y}_{T+l} = y_T + l\\bar{c}\\) (el pron√≥stico crece linealmente)\r\n\\[\r\ny_{T+l} -  \\hat{y}_{T+l} = \\sum_{t = T+1}^{T+l} c_t - l\\bar{c}\r\n\\]\r\nError est√°ndar del error pron√≥stico\r\n\\[\r\n\\sqrt{\\hat{Var}(y_{T+l} - \\hat{y}_{T+l})} \\approx \\sqrt{\\hat{Var}\\bigg(  \\sum_{t = T+1}^{T+l}c_t \\bigg)} = \\sqrt{S_c^2 \\cdot l}\r\n\\]\r\nError est√°ndar exacto del error de pron√≥stico\r\n\\[\r\n\\sqrt{Var(y_{T+l} - \\hat{y}_{T+l})} = S_c \\sqrt{l\\bigg(1+\\frac{l}{T}\\bigg)}\r\n\\]\r\nIntervalo de predicci√≥n al \\(95\\%\\)\r\n\\[\r\n\\hat{y}_{T+l} \\pm 1.96 \\sqrt{\\hat{Var}(y_{T+l} - \\hat{y}_{T+l})} \\\\\r\n\\text{i.e. } y_T + l\\bar{c} \\pm 1.96 \\sqrt{S_c^2 \\cdot l}\r\n\\]\r\nUn pque√±o aspecto computacional\r\nSi se da el ruido aleatorio (no la caminata aleatoria)\r\n\\(\\hat{y}_{T+l} = y_t + l\\bar{c}\\)\r\n\\(y_T + l\\bar{c} \\pm 1.96\\sqrt{S_c^2 \\cdot l}\\) i.e.¬†se calcula \\(\\bar{c}\\) y \\(S_c^2\\) muestrales (del ruido blanco)\r\n\r\nSi se dan los puntos de la caminata aleatoria\r\n\\(c_t = y_t - y_{t-1}\\) de aqu√≠ se parte\r\n\\(\\bar{c} = \\frac{1}{T}(c_1 + c_2 + ... + C_T) = \\frac{y_T - y_0}{T}\\)\r\n\r\n\r\n\r\nIdentificaci√≥n de una caminata aleatoria\r\n\\(\\mathbb{E}(y_t) = y_0 + t\\cdot\\mu_c\\) esto implica una tendencia una lineal en el tiempo.\r\n\\(Var(y_t) = t \\cdot \\sigma_c ^2\\) la varianza es creciente con respecto al tiempo.\r\nSi \\(\\{y_t\\}\\) es caminata aleatoria\r\n\\[\r\nc_t = y_t - y_{t-1}\r\n\\] debiese ser un ruido blanco y entonces deber√≠a tener correlaciones cercanas a 0 (no significativamente distintas de 0).\r\nLa desviaci√≥n est√°ndar de la serie original \\(\\{y_t\\}\\) debi√©se ser sustiancialmente mayor que la serie de diferencias \\(c_t = y_t - y_{t-1}\\)\r\n\\[\r\nVar(y_t) = t \\cdot \\sigma_c^2 \\\\\r\nVar(c_t) = \\sigma_c^2\r\n\\]\r\nFiltros\r\nUn filtro es un procedimiento para reducir un proceso de serie de tiempo a un ruido blanco.\r\nserie de tiempo \\(\\rightsquigarrow\\) ruido blanco\r\n\r\nDiferenciar, \\(y_t-y_{t-1}\\) es un ejemplo de filtro en caminatas aleatorias.\r\nTransformaci√≥n logar√≠tmica\r\nSea \\(\\{y_t\\}\\) tal que \\(\\boxed{\\mathbb{E}(y_t) = \\mu_t}\\) y \\(\\boxed{\\sqrt{Var(y_t)} = \\mu_t \\cdot \\sigma}\\), donde \\(\\mu_t\\) es uina funci√≥n determinista de \\(t\\) (generalmente creciente).\r\n\\(\\log(y_t) = \\log(\\mu_t) + \\log\\bigg(1+ \\frac{y_t - \\mu_t}{\\mu_t}\\bigg)\\)\r\n\\(\\log(y_t) \\approx \\log(\\mu_t) + \\frac{y_t - \\mu_t}{\\mu_t}\\)\r\n\\[\r\n\\log(1+x) \\approx x\r\n\\]\r\n\\(\\mathbb{E}[\\log(y_t)] \\approx \\log(\\mu_t)\\)\r\n\\(Var[\\log(y_t)] \\approx \\sigma^2\\) i.e.¬†\\(\\log(y_t)\\) tiene varianza aproximadamente constante.\r\nSe puede diferenciar postriormente para remover el nivel de variaci√≥n media (i.e.¬†ver qu√© onda con \\(\\log(\\mu_t)\\))\r\nTendencia lineal v.s. caminata aleatoria\r\nAmbos manejan no-estacionariedad modelo de tendencia lineal\r\n\\[\r\ny_t = \\underbrace{\\beta_0 + \\beta_1 t}_{\\text{determinista}} + \\underbrace{\\epsilon_t}_{\\text{aleatorio}}\r\n\\]\r\n\r\nModelo de caminata aleatoria\r\n\\[\r\ny_t = \\underbrace{y_0 + \\mu_c t}_{\\text{determinista}} + \\underbrace{u_t}_{\\text{aleatorio}} \\\\\r\n\\{\\epsilon_t\\} \\rightarrow \\text{ ruido blanco con media } 0\\\\\r\nu_t = \\sum_{j=1}^t \\epsilon_j \\\\\r\nc_t = \\mu_c + \\epsilon_t\r\n\\]\r\nPrueba de Dickey-Fuller\r\n\\[\r\n\\underbrace{y_t - y_{t-1}}_{y} = \\underbrace{\\overbrace{(\\phi - 1)}^{x_1} y_{t-1} }_{\\text{caminata} \\\\ \\text{aleatoria}} + \\underbrace{\\beta_0 + \\beta_1 \\overbrace{t}^{x_2}}_{\\text{tendencia} \\\\ \\text{lineal}} + \\epsilon_t\r\n\\]\r\nSi \\(\\phi = 1\\) y \\(\\beta_1 = 0\\) entonces\r\n\\[\r\ny_t = \\underbrace{y_{t-1} + \\beta_0 + \\epsilon_t}_{\\text{caminata aleatoria}}\r\n\\]\r\nSi \\(\\phi < 1\\) y \\(\\beta_1 = 0\\) entonces\r\n\\[\r\ny_t = \\underbrace{\\phi y_{t-1} + \\beta_0 + \\epsilon_t}_{\\text{modelo } AR(1)}\r\n\\]\r\nSi \\(\\phi = 0\\) entonces\r\n\\[\r\ny_t = \\underbrace{\\beta_0 + \\beta_1 t + \\epsilon_t}_{\\text{modelo de tendencia lineal}}\r\n\\]\r\nSe contrastan las hip√≥tesis\r\n\\[\r\n\\underbrace{ \\underbrace{H_0: \\phi = 1}_{\\text{caminata} \\\\ \\text{aleatoria}} \\space \\space \\space \\space \\space \\space\\space \\space \\space \\text{v.s.} \\space \\space \\space \\space \\space \\space \\space \\space \\space \\underbrace{H_a : \\phi < 1}_{\\text{tendencia} \\\\ \\text{lineal}}}_{\\text{Prueba de ra√≠z unitaria}}\r\n\\]\r\nDickey-Fuller supone que los errores \\(\\epsilon_t'^s\\) est√°n serialmente no-correlacionados.\r\nVersi√≥n aumentada de Dickey-Fuller\r\nFunciona a√∫n cuando la condici√≥n de no-correlaci√≥n serial est√° dada, se tiene que\r\n\\[\r\n\\underbrace{y_t - y_{t-1}}_{y} = (\\phi-1)\\underbrace{y_{t-1}}_{y} + \\beta_0 + \\beta_1\\underbrace{t}_{x_2} + \\sum_{j=1}^p\\phi_j\\underbrace{(y_{t-j} - y_{t-j-1})}_{x_j+\\epsilon_t}\r\n\\]\r\nModelos estacionales\r\nMuestran comportamiento peri√≥dico visible (determinista √≥ estoc√°stica).\r\nModelos de efectos estacionales fijos\r\nLa componente estacional \\(S_t\\) es determinista.\r\nFunciones estacionales binarias\r\n\\[\r\nz = \r\n\\begin{cases}\r\n1, \\text{ si el evento estacional ocurre}\\\\\r\n0, \\text{ c.o.c.} \r\n\\end{cases} \\\\\r\ny_t = \\underbrace{\\beta_0 + \\beta_1t + \\beta_2t^2}_{\\text{tendencia} \\\\ \\text{cuadr√°tica}} + \\underbrace{\\beta_3z_t}_{\\text{estado} \\\\\\text{estacional}} + \\underbrace{\\epsilon_t}_{\\text{error} \\\\ \\text{aleatorio}}\r\n\\]\r\nque es un modelo de regresi√≥n lineal m√∫ltiple con variables explicativas \\(t, t^2, z\\).\r\nFunciones \\(\\boxed{\\text{trigonom√©tricas}}\\)\r\n\\[\r\ng(t) = a \\cdot \\sin(2\\pi ft + b )\r\n\\]\r\n\\(a\\): amplitud\r\n\\(b\\): phase-shift\r\n\\(f\\): frecuencia\r\n\\(\\frac{1}{f}\\): periodo\r\nLos √°nulos se miden en radianes.\r\n\r\nEn general, para una base estacional, SB, la funci√≥n\r\n\\[\r\ng(t) = a \\cdot \\sin(2\\pi ft + b ), \\underbrace{f = \\frac{1}{SB}}_{\\text{conocido}}\r\n\\]\r\nproporciona una funci√≥n trigonom√©trica que se repite a s√≠ misma cada SB unidades de tiempo.\r\nPrefiere escribirse \\(g(\\cdot)\\) como\r\n\\[\r\n\\boxed{g(t) = \\beta_1 \\sin(2\\pi ft) + \\beta_2 \\cos(2\\pi f t)}\r\n\\]\r\ndonde \\(\\beta_1 = a \\cdot \\cos(b), \\beta_2 = a \\sin(b)\\) y se estiman \\(\\beta_1, \\beta_2\\) por m√≠nimos cuadrados, tratando a \\(\\sin(2\\pi ft)\\) y \\(\\cos(2 \\pi ft)\\) como variables explicativas.\r\n\\[\r\n\\boxed{ \r\n\\begin{align*} \r\ny_t &= \\beta_0 + S_t + \\epsilon_t \\\\\r\n&= \\beta_0 + \\sum_{j=1}^m \\bigg[ \\beta_{1j} \\sin(2\\pi fjt) + \\beta_{2j} \\cos(2\\pi f j t) \\bigg] + \\epsilon_t\r\n\\end{align*}} \\\\\r\n\\text{donde } fj = \\frac{j}{SB}\r\n\\]\r\nEste modelo tiene \\(2m\\) variables explicativas:\r\n\\[\r\n\\sin(2\\pi f j t) \\text{ y } \\cos(2 \\pi f j t), j = 1, ..., m\r\n\\]\r\n\r\n\r\nSuavizamiento (smoothing)\r\nConsiste en crear una serie de tiempo que sea m√°s suave que la serie de tiempo observada en el sentido de que es menos vulnerable a cambios abruptos en los valores de la serie.\r\nSe estudiar√°\r\nPromedios m√≥viles\r\nSuavizamiento exponencial\r\n\r\nPromedios m√≥viles (moving average)\r\nPromedio m√≥vil de longitud k al tiempo \\(t\\)\r\n\\[\r\n\\hat{S}_t = \\frac{1}{k} \\underbrace{(y_t + y_{t-1} + ... + y_{t-k+1})}_{k \\text{ sumandos}}\r\n\\]\r\nMientras m√°s grande sea el valor de \\(k\\), m√°s suaves ser√°n los promedios. (Mientras m√°s chivas üêê est√°s promediando, m√°s se van a acercar a una constante)\r\nLos promedios m√≥viles sirven como los valores ajustados para la serie original.\r\n\r\nPron√≥stico: \\(\\hat{y}_{T+1} = \\hat{S}_T\\)\r\n\\(\\hat{y}_{T+2} = \\hat{S}_{T+1} \\space \\rightarrow\\) pero \\(y_{T+1}\\) se reemplaza por \\(\\hat{S}_T\\)\r\nSe aplica esta idea inductivamente.\r\n\r\n¬øC√≥mo sabemos que \\(k\\) utilizar?\r\nSuavizamiento exponencial simple\r\n\\[\r\n\\hat{S}_t = \\frac{1}{(1-\\omega)^{-1}} \\bigg[ y_t + \\omega y_{t-1} + \\omega^2 y_{t-2} + ... + \\omega^{t-1} y_1 + \\omega^ty_0\\bigg]\r\n\\]\r\n\\(t\\in \\{0,1,...\\}\\)\r\n\\(\\omega \\in (0,1)\\) se tiene que seleccionar\r\nEl peso asignado a \\(y_{t-i}\\) es \\((1-\\omega)\\omega^i\\)\r\n¬øPor qu√© escogiste los ponderadores as√≠? \\((1-\\omega)\\omega^i\\)\r\n\\[\r\n\\sum_{i=0}^\\infty (1-\\omega)\\omega^i = (1-\\omega)\\sum_{i=0}^\\infty \\omega^i = (1-\\omega) \\bigg[\\frac{1}{1-\\omega} \\bigg] = 1\r\n\\]\r\nT√∫ puedes demostrar que \\(\\hat{S}_t = \\hat{S}_{t-1} + (1-\\omega)(y_t - \\hat{S}_{t-1})=(1-\\omega)y_t + \\omega \\hat{S}_{t-1}\\)\r\nMientras m√°s alto sea \\(\\omega\\), menor ser√° el efecto de \\(y_t\\) en \\(\\hat{S}_t\\) y m√°s pronunciada ser√° la cantidad de suavizamiento.\r\n\\(\\omega\\) bajo \\(\\rightarrow\\) mayor efecto de \\(y_t\\)\r\n\\(\\omega\\): par√°metro de suavizamiento\r\n\\[\r\n\\boxed{SS(\\:=\\sum_{t=1}^T (y_t - \\hat{S}_{t-1})^2omega)}\r\n\\]\r\ndepende de \\(\\omega\\) a partir de los estimados exponencialmente suavizados.\r\nSe elige \\(\\omega^*\\) se tal forma que \\(SS(\\omega^*)\\) sea m√≠nimo.\r\nPron√≥stico: \\(\\hat{y}_{T+1} = \\hat{S}_T\\)\r\n$$ {T+2} = {T+1} = (1-)y_{T+1} + _T = (1-) _T + _T = _T \\\r\n$$\r\nModelo AR de primer orden (AR(1))\r\nConocido como modelo Auto regresivo de orden 1.\r\n\\(\\underbrace{y_t}_{\\text{respuesta}} = \\underbrace{\\beta_0 + \\beta_1 y_{t-1}}_{\\text{explicativas}} + \\underbrace{\\epsilon_t}_{\\text{error}}\\)\r\n\\(\\beta_0, \\beta_1\\) son par√°metros desconocidos y \\(\\{\\epsilon_t\\}\\) es un proceso de ruido blanco con media 0.\r\nT√≠picamente se supone que \\(\\epsilon_{t+k}\\) y \\(y_t\\) son independientes para cualesquiera \\(t, k > 0\\).\r\nEl modelo \\(AR(1)\\) es una generalizaci√≥n de un proceso de ruido blanco haciendo \\(\\beta_1 = 0\\)\r\n\\[\r\ny_t = \\beta_0 + \\epsilon_t\r\n\\]\r\nEl modelo \\(AR(1)\\) es una generalizaci√≥n de una caminata aleatoria haciendo \\(\\beta_1 = 1\\)\r\n\\[\r\ny_t - y_{t-1} = \\beta_0 + \\epsilon_t\r\n\\]\r\nPara que el modelo \\(AR(1)\\) sea estacionario, una condici√≥n suficiente es que \\(\\boxed{|\\beta_1|<1}\\), pero \\(\\beta_0\\) puede ser cualquier real.\r\nUna parametrizaci√≥n m√°s popular del modelo \\(AR(1)\\) (que no se usa en Frees) es\r\n\\[\r\ny_t = \\mu + \\phi(y_{t-1} - \\mu) + \\epsilon_t\r\n\\]\r\nPropiedades del modelo AR(1) estacionario\r\nPara un modelo AR(1), \\(y_t = \\beta_0 + \\beta_1y_{t-1} + \\epsilon_t\\)\r\nDemuestra que:\r\n\\(\\mathbb{E}(y_t) = \\beta_0 + \\beta_1 \\mathbb{E}(y_{t-1}) + \\mathbb{E}(\\epsilon_{t}) = \\frac{\\beta_0}{1-\\beta_1}\\)\r\n\\(Var(y_t) = \\beta_1^2Var(y_{t-1}) + Var(\\epsilon_{t}) = \\frac{\\sigma^2_{\\epsilon}}{1-\\beta^2_1}\\)\r\nFunci√≥n de autocorrelaci√≥n\r\nPara \\(k = 1, 2, ...\\)\r\n\\(Cov(y_t, y_{t-k}) = \\beta_1^kVar(y_t)\\)\r\n\\[\r\n\\boxed{Corr(y_t, y_{t-k}) = \\beta_1^k =: \\rho_k}\r\n\\]\r\nComo se est√° suponiendo que \\(|\\beta_1|<1\\), la magnitud de las autocorrelaciones decrece exponencialmente con el lag \\(k\\), i.e.\r\n\\[\r\n\\boxed{\r\n\\text{La aplicaci√≥n}\\\\\r\nk\\mapsto \\rho_k =\\beta_1^k \\\\\r\n\\text{decrece exponencialmente}\r\n}\r\n\\]\r\nSi \\(\\beta_1 > 0\\), las autocorrelaciones son positivas pero se encogen con el lag. Para \\(\\beta \\approx 1\\), la curva de autocorrelaci√≥n parece relativamente suave.\r\nSi \\(\\beta_1 < 0\\), las autocorrelaciones alternan de positivo a negativo con magnitudes que decrecen exponencialmente.\r\nEstimaci√≥n de par√°metros en AR(1)\r\nSe estudiar√° el m√©todo de m√≠nimos cuadrados condicionales para estimar los 2 par√°metros \\(\\beta_0\\) y \\(\\beta_1\\) del modelo AR(1), bas√°ndose en la serie de tiempo observada \\(\\{y_1, y_2, ..., y_T\\}\\).\r\nPara el modelo AR(1), \\(y_t = \\beta_0 + \\beta_1 y_{t-1} + \\epsilon_t\\), se minimiza la suma de cuadrados condicional\r\n\\[\r\n\\sum_{t=2}^T(y_t - \\mathbb{E}(y_t | y_{t-1}))^2 = \\sum_{t = 2}^T\\bigg[y_t - (\\beta_0 + \\beta_1y_{t-1})\\bigg]^2\r\n\\]\r\ncomo s√≥lo se observa \\(y_1, ..., y_T\\), la suma empieza en \\(t=2\\), no en \\(t-1\\).\r\nSe puede ver al modelo AR(1) como un modelo SLR\r\n\\[\r\n\\begin{equation}\r\n\\left(\r\n\\begin{matrix}\r\ny_2 \\\\\r\ny_3 \\\\\r\n\\vdots \\\\\r\ny_T \r\n\\end{matrix}\r\n\\right)\r\n=\r\n\\left(\r\n\\begin{matrix}\r\n1 & y_1 \\\\\r\n1 & y_2 \\\\\r\n\\vdots & \\vdots \\\\\r\n1 & y_{T-1}\r\n\\end{matrix}\r\n\\right)\r\n\\left(\r\n\\begin{matrix}\r\n\\beta_0  \\\\\r\n\\beta_1\r\n\\end{matrix}\r\n\\right)\r\n+\r\n\\left(\r\n\\begin{matrix}\r\n\\epsilon_2 \\\\\r\n\\epsilon_3 \\\\\r\n\\vdots \\\\\r\n\\epsilon_T\r\n\\end{matrix}\r\n\\right)\r\n\\end{equation} \\\\\r\n\\\\\r\n\\mathbb{Y} = \\mathbb{X} \\beta + \\epsilon\r\n\\]\r\nAplicando la f√≥rmula para \\(\\beta_1\\) en el modelo SLR\r\n\\[\r\n\\boxed{\r\n\\hat{\\beta}_1 = \\frac{\\displaystyle \\sum_{t=2}^T (y_{t-1} - \\bar{y}_{1,T-1})(y_t - \\bar{y}_{2,T})}{\\displaystyle \\sum_{t=2}^T (y_{t-1} - \\bar{y}_{1,T-1})^2}\r\n}\r\n\\]\r\ndonde \\(\\bar{y}_{1, T-1} = \\frac{1}{T-1} \\displaystyle \\sum_{t=1}^{T-1} y_{t}, \\bar{y}_{2, T-1} = \\frac{1}{T-1} \\displaystyle \\sum_{t=2}^{T} y_{t}\\) y tambi√©n \\(\\boxed{\\hat{\\beta}_0 = \\bar{y}_{2, T} - \\hat{\\beta}_1 \\bar{y}_{1, T-1}}\\)\r\nLa expresi√≥n para \\(\\hat{\\beta}_1\\) es muy parecida a la autocorrelaci√≥n de lag 1.\r\nDe hecho, para \\(T\\) grande\r\n$$ {y}{1, T-1} {y}{2, T} {y} =  _{t =1}^Ty_t\\\r\n= r_1 $$\r\nEntonces se tienen las siguientes aproximaciones\r\n\\[\r\n\\hat{\\beta}_1 \\approx r_1 \\space \\space \\space \\text{ y } \\space \\space \\space \\hat{\\beta}_0 = \\bar{y}(1-r_1)\r\n\\]\r\nSi se pide que se calule el LSE (estimador por m√≠nimos cuadrados) de \\(\\beta_1\\) se usa\r\n\\[\r\n\\hat{\\beta}_1 = \\frac{\\displaystyle \\sum_{t=2}^T(y_{t-1} -\\bar{y})(y_{t} -\\bar{y})}{\\displaystyle \\sum_{t=2}^T(y_{t-1} -\\bar{y})^2}\r\n\\]\r\nno usar \\(\\hat{\\beta}_1 = r_1\\), a menos que se pida directamente.\r\nResiduales\r\n\\[\r\n\\boxed{\r\ne_t := y_t - (\\hat{\\beta}_0 + \\hat{\\beta}_1 y_{t-1})\r\n}\r\n\\]\r\nVerificaci√≥n de diagn√≥stico. Si el modelo AR(1) ajustado es adecuado, los residuales se deben parecer a un verdadero ruido blanco \\(\\{ \\epsilon_k\\}\\) que son i.i.d. y por lo tanto sin estructura de correlaci√≥n.\r\nOJO: El residual \\(e_1\\) no est√° disponible, s√≥lo se tienen \\(T-1\\) observaciones de los residuales.\r\nEstimaci√≥n de la varianza del ruido blanco. Los residuales se usan para estimar la varianza del ruido blanco \\(\\sigma_{\\epsilon}^2\\)\r\nA diferencia del marco de regresi√≥n lineal, el promedio de los residuales no es 0.\r\nEl MSE para la varianza del ruido blanco es\r\n\\[\r\n\\boxed{\r\nS^2 = \\frac{1}{T-3} \\sum_{t = 2}^T (e_t - \\bar{e})^2\r\n}\r\n\\]\r\n\r\nPredicci√≥n en el modelo AR(1)\r\nSe har√° pron√≥stico en el modelo AR(1)\r\n\\[\r\ny_t = \\beta_0 + \\beta_1 y_{t-1} + \\epsilon_t\r\n\\]\r\ndonde los par√°metros \\(\\beta_0\\) y \\(\\beta_1\\) se suponen conocidos √≥ eficientemente estimados y por lo tanto con errores despreciables, y la historia de la serie es \\(\\{y_1, ..., y_T\\}\\)\r\nPara predicci√≥n puntual se estudian dos formas\r\nRecursiva.\r\nExpl√≠cita.\r\n\r\n",
    "preview": "posts/2021-06-01-series-de-tiempo/images/st_1.png",
    "last_modified": "2021-06-05T21:53:19-05:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-05-29-resampling/",
    "title": "Resampling",
    "description": "Resampling",
    "author": [
      {
        "name": "Eduardo Selim M. M.",
        "url": {}
      },
      {
        "name": "Carlos A. Ar.",
        "url": {}
      }
    ],
    "date": "2021-05-30",
    "categories": [
      "resampling"
    ],
    "contents": "\r\n\r\nContents\r\nResampling methods\r\nCross-validation\r\n\r\nValidation out-of-sample\r\nDesventajas\r\n\r\nLeave-one-out cross-validation\r\nDesventajas\r\nVentajas\r\n\r\nK-fold cross-validation\r\nVentajas\r\n\r\nSesgo y varianza\r\nTraining MSE v.s. Testo MSE\r\nTrade-off sesgo -varianza\r\n\r\nResampling methods\r\nLos m√©todos de resampling son t√©cnicas estad√≠sticas que se usan para evaluar el performance de un m√©todo de aprendizaje estad√≠stico dado.\r\nEstos implican seleccionar muestras respectivamente de los datos de entrenamiento (‚Äúresampling‚Äù) y reajustar el modelo en cuesti√≥n en cada muestra.\r\nCross-validation\r\nLa cross-validation (CV) es una t√©cnica que se puede usar para estimar el error de prueba haciendo buen uso de los datos de entrenamiento.\r\nEsta t√©cnica tiene varias versiones, en cada una se extrae un subconjunto de las observaciones originales y se aplica el m√©todo de aprendizaje estad√≠stico a las observaciones que se sacaron y se eval√∫a su desempe√±o.\r\nValidaci√≥n out-of-sample.\r\nLeave-one-out cross validation.\r\nK-fold cross-validation.\r\n\r\nValidation out-of-sample\r\nEs conceptualmente el m√©todo m√°s simple de cross validation.\r\nConsiste en una separaci√≥n aleatoria de las observaciones disponibles en 2 partes de tama√±o comparable.\r\nConjunto de entrenamiento.\r\nConjunto de validaci√≥n.\r\nEl modelo se ajusta en el conjunto de entrenamiento y se usa el modelo ajustado para hacer predicciones de las respuestas para las observaciones en el conjunto de validaci√≥n.\r\nEl MSE sobre el conjunto de validaci√≥n es un estimado del error de prueba.\r\n\r\nDesventajas\r\nAunque es simple de llevar a cabo, la validaci√≥n out-of-sample tiene al menos 2 desventajas:\r\nDepende mucho de c√≥mo se construyen los conjuntos de entrenamiento y prueba. Dependiendo de la construcci√≥n de estos 2 conjuntos, el estimado del error de prueba puede ser muy diferente considerablemente.\r\nSolo un sobconjunto de las observaciones en el data-set original se usa para ajustar el modelo (los datos de entrenamiento). Con menos observaciones usadas para entrenar el m√©todo de aprendizaje estad√≠stico, el error de validaci√≥n tiende a sobre-estimar la tasa de error de prueba para el modelo ajustado en el data-set completo.\r\n\r\nLeave-one-out cross-validation\r\nEl leave-one-out cross-validation (Loocv) es un refinamiento del m√©todo del conjunto de validaci√≥n.\r\nEn vez de separar aleatoriamente a las observaciones en 2 partes, el Loocv define repetidamente al conjunto de entrenamiento como un sub-conjunto que contiene todas excepto una de las observaciones disponibles y el ‚Äúconjunto‚Äù de validaci√≥n es la observaci√≥n restante, i.e.\r\nConjunto de entrenamiento: \\(n-1\\) observaciones.\r\nConjunto de validaci√≥n: 1 observaci√≥n.\r\n\r\nDe manera m√°s espec√≠fica, el Loocv empieza usando \\((x_1, y_1)\\) como conjunto de validaci√≥n a las observaciones restantes \\(\\{(x_2, y_2), ..., (x_n, y_n)\\}\\) como el conjunto de entrenamiento en el que se ajustar√° el m√©todo de aprendizaje estad√≠stico. Se obtiene una predicci√≥n \\(\\hat{y}_{(1)}\\) usando el valor de \\(x_1\\) y\r\n\\[\r\n\\text{MSE}_1 := (y_1 - \\hat{y}_{(1)})^2 \r\n\\]\r\nes un estimado del error de prueba.\r\nEl procedimiento se repite con \\((x_i, y_i)\\) como conjunto de validaci√≥n y \\(\\{(x_j, y_j)\\}_{i \\neq j}\\) como conjunto de entrenamiento, y se obtiene un estimado del error de prueba MSE\\(_i\\)\r\nDefinici√≥n: Bas√°ndose en MSE\\(_1\\), MSE\\(_2\\), ‚Ä¶, MSE\\(_n\\), el estimado Loocv del error de prueba cs\r\n\\[\r\nCV_{(n)} : = \\frac{1}{n} \\sum_{i=1}^n (y_i - \\hat{y}_{(i)})^2\r\n\\]\r\nDesventajas\r\nUna desventaja potencial de Loocv es que su c√°lculo puede ser computacionalmente demandante pues requiere entrenar \\(n\\) modelos.\r\nPara modelos de regresi√≥n lineal, ajustados usando un m√≠nimos cuadrados ordinarios, se puede usar la siguiente f√≥rmula\r\n\\[\r\nCV_{(n)} = \\frac{1}{n} \\sum_{i=1}^n \\bigg(\\frac{y_i - \\hat{y}_i}{1-h_{ii}}\\bigg)^2\r\n\\]\r\ndonde \\(\\hat{y}_i\\) es el i-√©simo valor ajustado en el data-set completo y \\(h_{ii}\\) es el i-√©simo leverage.\r\nSin embargo, dicha f√≥rmula no aplica en otros contextos, adem√°s del regresi√≥n.\r\nLoocv es un m√©todo general que se puede aplicar a casi cualquier procedimiento de aprendizaje estad√≠stico.\r\nVentajas\r\nLoocv tiene mucho menos sesgo. En Loocv se aplica repetidamente el m√©todo de aprendizaje estad√≠stico a conjuntos de entrenamiento que consisten de \\(n-1\\) observaciones (casi tantas como hay en el data set completo).\r\nLoocv tiende a dar una tasa de error de prueba que tiene un mucho menor sesgo en comparaci√≥n con el m√©todo de conjunto de out-of-sample.\r\nMientras que en el m√©todo out-of-sample las tasas de error de validaci√≥n dependen √∫nicamente de las observaciones que est√°n en el conjunto de entrenamiento, en Loocv no se deoende de esta composici√≥n.\r\nLa divisi√≥n entrenamiento/validaci√≥n no carga aleatoriedad y el estimado Loocv del error de prueba no muestra variabilidad.\r\n\r\nK-fold cross-validation\r\nEl k-fold cross-validation es un m√©todo intermedio entre el out-of-sample y el Loocv.\r\nEn √©te m√©todo se divide a las observaciones en \\(k\\) ‚Äúfolds‚Äù (pliegues/secciones) de tama√±o comparable.\r\nUn fold se ocupa como conujnto de validaci√≥n y los otros folds sirven como conjunto de entrenamiento.\r\nEste procedimiento se repite para cada fold y se obtienen \\(k\\) estimados del error prueba MSE\\(_1\\), MSE\\(_2\\), ‚Ä¶, MSE\\(_k\\)\r\nEl estimado \\(k\\)-fold del error de prueba es\r\n\\[\r\nCV_{(k)} = \\frac{1}{k} \\sum_{i=1}^k \\text{MSE}_i\r\n\\]\r\nLoocv es un caso especial de \\(k\\)-fold cross-validatioon con \\(k=n\\)\r\nLas elecciones comunes de \\(k\\) en la pr√°ctica son \\(k = 5, k = 10\\)\r\n\r\nVentajas\r\nSi \\(k<n\\), un m√©rito obvio del \\(k\\)-fold cross-validation comparado con Loocv es que \\(k\\)-fold CV es computacionalmente no demandante, pues se ajustan \\(k\\) modelos en vez de \\(n\\).\r\nSesgo y varianza\r\nMientras m√°s observaciones de entrenamiento, menos sesgo\r\n\\[\r\n\\text{SESGO: Loocv} < \\text{k-fold} < \\text{out-of-sample}\r\n\\]\r\nSin embargo, para la varianza ocurre al rev√©s\r\n\\[\r\n\\text{VARIANZA: out-of-sample} < \\text{k-fold} < \\text{Loocv}\r\n\\]\r\nHablando vagamente, loocv tiene la varianza m√°s alta pues\r\n\\[\r\nCV_{(n)} = \\frac{1}{n} \\sum_{i=1}^n \\text{MSE}_i\r\n\\]\r\nes un promedio de \\(n\\) cantidades altamente correlacionadas (pues b√°sicamente corresponde a las mismas observaciones).\r\n\r\nTraining MSE v.s. Testo MSE\r\n\r\n\\[\r\n\\text{Training MSE} = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{f}(x_i))\r\n\\]\r\nUn modelo con training MSE bajo, no necesariamente tiene un testMSE bajo.\r\nEl ‚Äúmejor‚Äù modelo es aquel que minimiza el test MSE.\r\nTrade-off sesgo -varianza\r\n\\[\r\n\\underbrace{\\mathbb{E}\\bigg[ (y_0 - \\hat{f}(x_0))^2 \\bigg]}_{\\text{test MSE esperado} \\\\ \\text{es }x_n} = Var(\\hat{f}(x_0)) + \\bigg[ \\text{Sesgo}(\\hat{f}(x_0))  \\bigg]^2 + \\underbrace{Var(\\epsilon_i)}_{\\text{Error irreducible}}\r\n\\]\r\nHay que hablar largo y tendido de este tema‚Ä¶\r\n\r\n\r\n\r\n",
    "preview": "posts/2021-05-29-resampling/images/resampling_1.png",
    "last_modified": "2021-06-05T21:54:48-05:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-05-27-introduccin-a-redes-neuronales/",
    "title": "Introducci√≥n a redes neuronales",
    "description": "Redes neuronales 1",
    "author": [
      {
        "name": "Eduardo Selim M. M.",
        "url": {}
      },
      {
        "name": "Carlos A. Ar.",
        "url": {}
      }
    ],
    "date": "2021-05-29",
    "categories": [
      "redes neuronales"
    ],
    "contents": "\r\n\r\nContents\r\nFeeed forward\r\n\r\nConsid√©rese un problema de clasificaci√≥n binaria \\(G=0\\) √≥ \\(G=1\\), a partir de las covariables \\(x_1,...,x_p\\)\r\nCuando se estudi√≥ regresi√≥n polinomial e interacciones, b√°sicamente se consider√≥ una transformaci√≥n de las variables originales existentes. Con esta idea en mente, se pueden construir \\(m\\) nuevas entradas de la siguiente forma:\r\n\r\npara \\(k = 1, 2, ..., m\\). Donde \\(h(\\cdot)\\) una funci√≥n adecuada (que se especificar√° m√°s adelante) y por supuesto \\(\\theta_{k0}, \\theta_{k1}, ..., \\theta_{kp}\\) son par√°metros que eventualmente se tendr√°n que estimar.\r\nAhora se modelar√° la probabilidad de clase 1 a partir de regresi√≥n log√≠stica pero en ves de usar las variables originales \\(x_1, ..., x_p\\), se usan estas variables derivadas \\(a_1, ..., a_m\\)\r\n\\[\r\nP_1(\\underline{x}) = logit(\\beta_0 + \\beta_0 a_1 + ... + \\beta_ma_m) \\\\\r\n\\text{Donde a } a_1, ..., a_m \\text{ se conocen como nuevas variables o variables derivadas.}\r\n\\]\r\nSe puede representar esto mediante un grafo dirigido\r\n\r\nLa funci√≥n \\(h(\\cdot)\\) debe ser no-lineal; ya que si fuera lineal, en realidad no se estar√≠a transformando (pues combinaciones lineales de combinaciones lineales son combinaciones lineales üòÜ).\r\nSe puede demostrar que si se definen suficientes entradas derivadas (i.e.¬†\\(m\\) es suficientemente grande) entonces la funci√≥n \\(P_1(\\underline{x})\\) puede aproximar cualquier funci√≥n continua.\r\nLa funci√≥n \\(h(\\cdot)\\) se conoce como funci√≥n de activaci√≥n.\r\nAlgunos ejemplos de funciones de activaci√≥n son;\r\nTangente hiperb√≥lica: \\(h(x) = \\frac{e^{x}-e^{-x}}{e^{x}+e^{-x}}\\)\r\nReLU (Rectified Linear Unit). \\(h(x) = \\max\\{0, x\\}\\)\r\nSigmoide: \\(h(x) = \\frac{1}{1+e^{-x}} = \\frac{e^{x}}{e^{x}+1}\\)\r\nLeaky ReLU: \\(h(x) = \\max\\{\\frac{x}{10}, x\\}\\)\r\nStep (heavyside) \\(h(x) = 1^x_{[0, \\infty)} = \\begin{cases} 1, \\text{ si } x\\geq 0, \\\\ 0, \\text{ si } x < 0\\end{cases}\\)\r\n\r\nTareita: Revisar el artpiculo Cybento, G(1989). ‚ÄúApproximations by superpositions of sigmoidal functions‚Äù. Mathematics of control, Signals and Systems 303-314. Reporte:\r\nEste procedimiento se basa en el Teorema de Aproximaci√≥n Universal, que en su versi√≥n simple, establece que cualquier funci√≥n se puede aproximar mediante superposici√≥n de funciones tipo sigmoide.\r\nEjemplo:\r\nConsid√©rese una arquitectura muy sencilla\r\n\r\nEs decir, s√≥lo se tiene una variable explicativa \\(x_1\\) y se derivar√°n 2 nuevas variables \\(a_1, a_2\\). Entonces, se hace una regresi√≥n log√≠stica para predecir \\(G = 1\\) o \\(G = 0\\)\r\n\\[\r\np_1(x ; a_1, a_2) = logit(\\beta_0 + \\beta_1a_1 + \\beta_2a_2)\r\n\\]\r\nDonde\r\n\\[\r\na_1(x) := h(\\beta_{10} + \\beta_{11}x_1)\\\\\r\na_2(x) := h(\\beta_{20} + \\beta_{21}x_1) \r\n\\]\r\ncon \\(h(\\cdot)\\) preestablecida. Para este ejemplo, sup√≥ngase que \\(h(x) = \\frac{1}{1+ e^{-x}}\\)\r\nObservaci√≥n: En esta especificaci√≥n, hay 7 par√°metros, que eventualmente tendr√°n que estimar: \\(\\beta_0, \\beta_1, \\beta_2, \\beta_{10}, \\beta_{11}, \\beta_{20}, \\beta_{21}\\) ¬øC√≥mo estimar estos \\(\\beta'^s\\)?\r\nComo se est√° con un problema de clasificaci√≥n, se estimar√°n estos par√°metros minimizando la devianza √≥ devianza regularizada\r\nEl problema de optimizaci√≥n se escribe f√°cil, pero no es sencillo de resolver.\r\n¬øExiste soluci√≥n?\r\nSi existe, ¬øes √∫nica?\r\n¬øC√≥mo encuentro la soluci√≥n?\r\n¬øAnal√≠ticamente?\r\n¬øNum√©ricamente?\r\n\r\n\r\nFeeed forward\r\nSe generalizar√° esta idea de aproximar la respuesta para definir la arquitectura b√°sica de una red neuronal.\r\nA las variables originales se les conoce como capa de entrada de la red.\r\nA la variable de salida se le conoce como capa de salida.\r\nA las capas inmediatas se les conoce como capas ocultas.\r\nCuando hay todas las conexiones de una capa a la otra se dice que la red es competamente conexa.\r\nComo se vio en el ejemplo, para hacer los c√°lculos en la red se empezar√° con la primera capa haciendo combinaciones lineales (operaci√≥n suma) y posteriormente se aplica la funci√≥n \\(h(\\cdot)\\) (funci√≥n de activaci√≥n).\r\nUna vez que se calcul√≥ la segunda capa, se calcula la 3era de la misma forma:\r\nCombinaciones lineales (operaci√≥n suma).\r\nAplicaci√≥n de \\(h\\) (funci√≥n de activaci√≥n).\r\n\r\n\r\nNotaci√≥n:\r\n\\(L\\) n√∫mero total de capas\r\n1 capa de entrada\r\n1 capa de salida\r\n\\(L-2\\) capas ocultas\r\n\r\n\\(x = (x_1, ..., x_p)\\), variables originales.\r\n\\(n_l\\): n√∫mero de unidades (neuronas / nodos) de la capa \\(l\\) , \\(l = 1, ..., L\\)\r\n\\(a_j^{(l)}\\): valor que toma la unidad \\(j\\) de la capa \\(l, j = 0,1, ..., n_l, l = 1, 2, ..., L\\)\r\nPara cualquier \\(l \\in \\{1, 2, ..., L \\}, a_0^{(l)} \\equiv 1\\) i.e.¬†es el coeficiente de sesgo/‚Äúordenada al origen‚Äù.\r\n\\(a_j^{(l)} \\equiv x_j\\) (valores de la primera capa)\r\n\\(\\theta_{i,k}^{(l)}\\): Ponderaci√≥n/coeficiente dela entrada \\(a_k^{(l-1)}\\) en la entrada \\(a_i^{(l)}\\)\r\n\r\nEjemplo\r\n\r\nPara calcular los valores de salida de una red a partir de ponderaciones y datos de entrada, se usa el algoritmo feed-forward\r\nPara la primera capa, se escriben las variables de entrada\r\n\\[\r\na_j^{(1)} := x_j, j=1,2,...,n_1, (n_1 = p)\r\n\\]\r\nPara la segunda capa (√≥ la primera capa oculta)\r\n\\[\r\na_{j}^{(2)} = h\\bigg( \\theta_{_{j,0}}^{^{(1)}} + \\theta_{_{j,1}}^{^{(1)}}a_1^{(1)} + ... + \\theta_{_{j,n_1}}^{^{(1)}}a_{n_1}^{(1)} \\bigg) =h\\bigg( \\theta_{_{j,0}}^{^{(1)}} + \\sum_{k=1}^{n_1}\\theta_{_{j,k}}^{^{(1)}}a_{k}^{(1)} \\bigg)\\\\ j = 1,2,...,n_2\r\n\\]\r\nPara la \\(l\\)-√©sima capa\r\n\\[\r\na_{j}^{(l)} = h\\bigg( \\theta_{_{j,0}}^{^{(l-1)}} + \\theta_{_{j,1}}^{^{(l-1)}}a_1^{(l-1)} + ... + \\theta_{_{j,n_2}}^{^{(l-1)}}a_{n_2}^{(l-1)} \\bigg) =h\\bigg( \\theta_{_{j,0}}^{^{(l-1)}} + \\sum_{k=1}^{n_2}\\theta_{_{j,k}}^{^{(l-1)}}a_{k}^{(l-1)} \\bigg)\\\\ j = 1,2,...,n_l\r\n\\]\r\nPara la capa final √≥ capa de salida (suponiendo un problema de clasificaci√≥n binaria)\r\n\\[\r\np_1 = h\\bigg( \\theta_{_{1,0}}^{^{(L-1)}} + \\sum_{k=1}^{n_{L-1}}\\theta_{_{j,k}}^{^{(L-1)}}a_{k}^{(L-1)} \\bigg)\r\n\\]\r\nCada capa se caracteriza por el conjunto de par√°metros\r\n\\[\r\n\\Theta^{(l)} \\in m^{(\\mathbb{R})}_{ n_l\\times n_{l-1}}\r\n\\] i.e.¬†\\(\\Theta^{(l)}\\) es una matriz de \\(n_l \\times n_{l-1}\\)\r\n\r\nLa red completa se caracteriza por:\r\nEl n√∫mero de capas\r\nEl n√∫mero de nodos de cada capa\r\nLas matrices de ponderaciones/coeficientes en cada capa \\(\\Theta^{(1)}, \\Theta^{(2)}, ..., \\Theta^{(L-1)}\\)\r\nOjo: Tambi√©n se podr√≠a variar la funci√≥n de activaci√≥n en cada capa.\r\nNotaci√≥n: \\(a^{(l)} := (a_0^{(l)}, a_1^{(l)}, ..., a_{n_l}^{(l)})\\) i.e.¬†el vector de unidades de la capa \\(l\\).\r\nEntonces el algoritmo feed-forward en notaci√≥n matricial es:\r\nCapa 1: \\(a^{(1)} = x \\in \\mathbb{R}^p, i.e., n_1 = p\\)\r\nCapa: 2: \\(a^{(2)} = h(\\underbrace{\\Theta^{(1)}}_{n_2 \\times p} \\underbrace{a^{(1)}}_{p\\times1}) \\in \\mathbb{R}^{n_2}\\)\r\n¬°Ojo!: Abuso de notaci√≥n. \\(h\\) se aplica componente a componente sobre los vectores correspondientes.\r\n\r\nCapa \\(l\\) (capa oculta)\r\n\\[\r\na^{(l)} = h(\\underbrace{\\Theta^{(1)}}_{n_l \\times n_{l-1}} \\space \\space \\space \\underbrace{a^{(1)}}_{n_{l-1}\\times1}) \\in \\mathbb{R}^{n_l}\r\n\\]\r\nCapa de salida:\r\nPara un problema de clasificaci√≥n binaria\r\n\\[\r\na^{(L)} = p_1 = logit(\\Theta^{(L-1)} a^{(L-1)})\r\n\\]\r\nPara un problema de regresi√≥n\r\n\\[\r\na^{(L)} = \\Theta^{(L-1)} a^{(L-1)}\r\n\\]\r\n\r\n\r\n",
    "preview": "posts/2021-05-27-introduccin-a-redes-neuronales/images/rn1_1.png",
    "last_modified": "2021-05-29T22:18:02-05:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-05-29-redes-neuronales-2/",
    "title": "Redes neuronales 2",
    "description": "Redes neuronales 2",
    "author": [
      {
        "name": "Eduardo Selim M. M.",
        "url": {}
      },
      {
        "name": "Carlos A. Ar.",
        "url": {}
      }
    ],
    "date": "2021-05-29",
    "categories": [
      "redes neuronales"
    ],
    "contents": "\r\nRecu√©rdese que en un problema de clasificaci√≥n binaria, la devianza con regulaci√≥n ridge es\r\n\\[\r\nD = \\frac{-2}{n} \\sum_{i=1} ^n \\bigg[y_i \\log(p_1(x_i)) + (1-y_i)\\log(p_i(x_i))\\bigg] + \\underbrace{\\lambda \\sum_{l=2} ^L\\sum_{k=1} ^{n_{l-1}}\\sum_{j=1} ^{n_l} (\\theta_{j,k}^{(l)})^2}_{\\text{Penalizaci√≥n ridge}}\r\n\\]\r\nPara minimizar esta devianza se tienen que obtener las derivadas con respecto a \\(\\theta_{j,k}^{(l)}\\) (son un mont√≥n de derivadas) El vector de todas estas derivadas se conoce como gradiente.\r\nObservaci√≥n. Para la funci√≥n de activaci√≥n \\(h(x) = \\frac{1}{1+e^{-x}}\\) se tiene que\r\n\\[\r\n1-h(x) = \\frac{e^{-x}}{1+e^{-x}}\\\\\r\nh'(x) = \\frac{e^{-x}}{(1+e^{-x})^2} = \\frac{e^{-x}}{1+e^{-x}} \\cdot \\frac{1}{1+e^{-x}} = [1-h(x)]h(x)\\\\\r\n\\rightarrow h'(x)  = h(x) [1-h(x)]\r\n\\]\r\nSe considerar√° el problemma de minimizaci√≥n de la devianza sin penalizaci√≥n.\r\nPrimero se calcular√°n las derivadas parciales para un solo caso de entrenamiento \\((x, y)\\)\r\n\\[\r\nD = -y\\log(p_1(x)) + (1-p)\\log(1-p_1(x))\r\n\\]\r\ny despu√©s se suma sobre toda la muestra de entrenamiento.\r\nEntonces, lo que se quiere es calcular \\(\\boxed{\\frac{\\partial}{\\partial \\theta_{j,k}^{(l)}}D}\\)\r\nSeg√∫n lo anterior,\r\n\\[\r\na_j^{(l+1)} = h( z_j^{(l+1)} ), \\text{ donde } z^{(l+1)} := \\Theta^{(l)}a^{(l)}\\\\\r\n\\text{i.e. }z_j^{(l+1)} = \\sum_{k=0}^{n_l} \\theta_{j,k}^{(l)} a^{(l)}\r\n\\]\r\nObs√©rvese que seg√∫n la regla de la cadena\r\n\\[\r\n\\frac{\\partial}{\\partial \\theta_{j,k}^{(l)}}D = \\sum_{t=1}^{n_l}\\frac{\\partial}{\\partial a_{t}^{(l)}}D \\cdot \\frac{\\partial}{\\partial \\theta_{j,k}^{(l)}} a_t^{(l+1)}\r\n\\]\r\nsin embargo \\(\\theta_{j,k}^{(l)}\\) solo aparece en la red en el segmento \r\nEntonces, \\(\\frac{\\partial}{\\partial \\theta_{j,k}^{(l)}} a_t^{(l+1)} = 0, t\\neq j\\) (pues \\(a_t^{l+1}\\) no depende de \\(\\theta_{j,k}^{(l)}\\))\r\nDe aqu√≠ que, para cualesquiera \\(j \\in \\{ 1, 2, ..., n_{l+1}\\},k\\in \\{0, 1, ..., n_l\\}\\) se tiene que\r\n\\[\r\n\\frac{\\partial}{\\partial \\theta_{j,k}^{(l)}}D = \r\n\\frac{\\partial}{\\partial a_{j}^{(l+1)}}D \r\n\\cdot \r\n\\frac{\\partial}{\\partial \\theta_{j,k}^{(l)}} a_j^{(l+1)} \r\n\\space \\space \\space \\space \\space \\space \\space \\space \\space \\space \\space \\space \\space \\space \\space \\space \r\n\\dotso (\\heartsuit)\r\n\\]\r\nPrimero obtengamos \\(\\frac{\\partial}{\\partial \\theta_{j,k}^{(l)}} a_j^{(l+1)}\\):\r\n\\[\r\na_j^{(l+)} = h(z_j^{(l+)}) = h\\bigg(  \\sum_{k=0}^{n_l} \\theta_{j,k}^{(l)} a^{(l)} \\bigg)\r\n\\]\r\ndonde las \\(a_k^{(l)}\\) no depende de \\(\\theta_{j,k}^{(l)}\\)\r\nDe aqu√≠ que\r\n\\[\\begin{align*}\r\n\r\n\\frac{\\partial}{\\partial \\theta_{j,k}^{(l)}} a_j^{(l+1)} &= h'(z_j^{(l+)}) \\cdot \\frac{\\partial}{\\partial \\theta_{j,k}^{(l)}} z_j^{(l+1)} = h'(z_j^{(l+1)}) \\cdot a_k^{(l)}\\space \\space \\space \\space \\space \\space \\space \\space \\space \r\n\\dotso (1)\\\\\r\n\\text{Sustituyendo en } (\\heartsuit)\\\\\r\n\r\n\\frac{\\partial}{\\partial \\theta_{j,k}^{(l)}}  D &= \\frac{\\partial}{\\partial a_{j}^{(l+1)}}D \r\n\\cdot \r\n\\frac{\\partial}{\\partial \\theta_{j,k}^{(l)}} a_j^{(l+1)} \\\\\r\n& = \\underbrace{\\frac{\\partial}{\\partial a_{j}^{(l+1)}}D  \\cdot  h'(z_j^{(l+1)})}_{c_j^{(l+1)}} \\cdot a_k^{(l)} \\\\\r\n&= c_j^{(l+1)} \\cdot a_k^{(l)}\r\n\\end{align*}\\]\r\nEs decir,\r\n\\[\r\n\\frac{\\partial}{\\partial \\theta_{j,k}^{(l)}}  D =  c_j^{(l+1)} \\cdot a_k^{(l)} \\space \\space \\space \\space ...(\\bigstar)\r\n\\]\r\nAhora se estudiar√° \\(\\frac{\\partial}{\\partial a_{j}^{(l+1)}}D\\) para \\(j \\in \\{1, .., n_l\\}\\)\r\nDe nuevo, usando la regla de la cadena\r\n\\[\r\n\\frac{\\partial}{\\partial a_{j}^{(l+1)}}D = \\sum_{s=1}^{n_{l+1}}  \\frac{\\partial}{\\partial a_{s}^{(l+1)}}D \\cdot   \\frac{\\partial}{\\partial a_{j}^{(l)}}  a_{s}^{(l+1)} \\space \\space \\space \\space \\space \\space ...(\\blacklozenge)\r\n\\]\r\n\r\nPero\r\n\\[\\begin{align*}\r\n\r\n\\frac{\\partial}{\\partial a_{j}^{(l)}} a_{s}^{(l+1)} &=  \\frac{\\partial}{\\partial a_{j}^{(l)}} h(z_{s}^{(l+1)}) \\\\\r\n& = \\frac{\\partial}{\\partial a_{j}^{(l)}} h \\bigg(\\sum_{k=0}^{n_l} \\theta_{j,k}^{(l)} a^{(l)}\\bigg) \\\\\r\n& = h'(z_{s}^{(l+1)}) \\theta_{s,j}^{(l)}\\\\\r\n\\text{Sustituyendo en } (\\blacklozenge)\\\\\r\n\\frac{\\partial}{\\partial a_{j}^{(l)}}D\r\n&= \\sum_{s = 1}^{n_l} \\frac{\\partial}{\\partial a_{s}^{(l+1)}}D \\cdot h'(z_s^{(l+1)}) \\theta_{s,j}^{(l)} \\\\\r\n& = \\sum_{s = 1}^{n_l} c_{s,j}^{(l+1)} \\cdot \\theta_{s,j}^{(l)} \\\\\r\n\\Rightarrow \\underbrace{\\frac{\\partial}{\\partial a_{j}^{(l)}} D \\cdot h'(z_j^{(l)})}_{c_j^{(l)}} \r\n&= \\bigg[\\sum_{s = 1}^{n_l} c_{s,j}^{(l+1)} \\cdot \\theta_{s,j}^{(l)} \\bigg] \\cdot h'(z_j^{(l)}) \\\\\r\n\\Rightarrow c_j^{(l)} &= \\bigg[\\sum_{s = 1}^{n_l} c_{s,j}^{(l+1)} \\cdot \\theta_{s,j}^{(l)} \\bigg] \\cdot h'(z_j^{(l)}) \\space \\space \\space \\space ...(\\clubsuit)\\\\\r\nj\\in\\{1, 2, ..., n_l\\}, \\\\\r\nl\\in\\{2, ..., L-1\\}\r\n\\end{align*}\\]\r\nObservaci√≥n. La expresi√≥n \\((\\clubsuit)\\) es una f√≥rmula recursiva que se puede usar en \\((\\bigstar)\\)\r\nN√≥tese que, para este caso de clasificaci√≥n \\[\\begin{align*}\r\n\r\nc_1 ^{(L)} &= \\frac{\\partial}{\\partial a_{1}^{(L)}} D \\cdot h'(z_1^{(L)}) = \\frac{\\partial}{\\partial p_{1}} D \\cdot h'(z_1^{(L)}) , \\text{ pues } p_1 = a_1^{(L)} = h(z_1^{(L)})\\\\\r\n&= \\bigg[ -\\frac{\\partial}{\\partial p_{1}} \\big(y\\log(p_1) + (1-y) log(p_1)\\big) \\bigg] h'(z_1^{(L)}) \\\\\r\n&=-\\bigg[ \\frac{y}{p_1} - \\frac{1-y}{1-p_1} \\bigg]h'(z_1^{(L)})\\\\\r\n&=\\frac{1-y}{1-p_1}\\bigg[ 1 - \\frac{y(1-p_1)}{(1-y)p_1}\\bigg]h'(z_1^{(L)})\\\\\r\n&=\\frac{1-y}{1-p_1}\\bigg[ 1 - \\frac{y(1-p_1)}{(1-y)p_1}\\bigg]h(z_1^{(L)})[1-h(z_1^{(L)})]\\\\\r\n&=\\frac{1-y}{1-p_1}\\bigg[ 1 - \\frac{y(1-p_1)}{(1-y)p_1}\\bigg]p_1(1-p_1)\\\\\r\n&= (1-y) \\bigg[ 1 - \\frac{y(1-p_1)}{(1-y)p_1} \\bigg]p_1 = (1-y) \\bigg[ p_1 - \\frac{y(1-p_1)}{1-y} \\bigg]\\\\\r\n& =(1-y)p_1 - y(1-p_1) = p_1 - yp_1 -y + yp_1 =p_1-y\r\n\r\n\\end{align*}\\]\r\nY se puede usar \\((\\clubsuit)\\) recursivamente para obtener \\(c_j^{(l)}\\) y \\((\\bigstar)\\)\r\n\r\n\r\n\r\n",
    "preview": "posts/2021-05-29-redes-neuronales-2/images/rn2_2.png",
    "last_modified": "2021-05-29T20:41:59-05:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-05-29-redes-neuronales-3/",
    "title": "Redes neuronales 3",
    "description": "Redes neuronales 3",
    "author": [
      {
        "name": "Eduardo Selim M. M.",
        "url": {}
      },
      {
        "name": "Carlos A. Ar.",
        "url": {}
      }
    ],
    "date": "2021-05-29",
    "categories": [
      "redes neuronales"
    ],
    "contents": "\r\n\r\nContents\r\nDescenso estoc√°stico\r\nAlgor√≠tmo de descenso estoc√°stico\r\nRazones de uso del descenso estoc√°stico\r\nTasa de aprendizaje\r\n\r\n\r\nDescenso estoc√°stico con momento\r\n\r\nDescenso estoc√°stico\r\nUna de las alternativas m√°s comunes para hacer el ajuste en redes grandes es descanso estoc√°stico y algunas de sus cariantes.\r\nDescanso estoc√°stico por minilotes. En √©ste, el c√°lculo del gradiente se hace sobre una submuestra relativamente peque√±a de la muestra de entrenamiento.\r\nA esta submuetra se le conoce como minilote.\r\nEn cada iteraci√≥n, se mueve hacia la direcci√≥n de descanso de ese minilote.\r\nLa muestra de entrenamiento se divide al azar en minilotes haciendo una actualizaci√≥n de los par√°metros en cada minilote.\r\nUn recorrido sobre todos los minilotes se conoce como √©poca.\r\n\r\nAlgor√≠tmo de descenso estoc√°stico\r\nSe separa al azar los datos de entrenamiento en \\(n\\) minilotes cada uno de tama√±o \\(m\\), i.e.¬†la muestra de entrenamiento es de tama√±o \\(n\\cdot m\\)\r\nPara √©poca \\(e \\in \\{1,2,...,n_l\\}\\)\r\nCalcular el gradiente sobre el minilote y hacer actualizaci√≥n, sucesivamente para cada uno de los minilotes \\(k = 1,2,...,n\\) \\[\\begin{align*}\r\n\\beta_{i+1} \\leftarrow \\beta_i - \\eta \\frac{1}{m} \\sum_{j = 1}^m \\nabla D_j^{(m)} (\\beta_i)\r\n\\end{align*}\\]\r\ndonde \\(D_j^{k}(\\beta_j)\\) esta funci√≥n objetivo (devfianza, suma de cuadrados, etc.) para el \\(j\\)-√©simo caso del minilote \\(k\\).\r\nRepetir para la siguiente √©poca.\r\nSe puede reordenar al azar los minilotes para evitar ciclos.\r\n\r\nNota: A \\(\\eta\\) se le conocce como la tasa de aprendizaje.\r\n\r\nRazones de uso del descenso estoc√°stico\r\nMuchas veces no es necesario usar todos los datos para encontrar una buena direcci√≥n de descenso.\r\nSe puede ver a la direcci√≥n de descenso en gradiente como un valor esperado sobre la muestra de entrenamiento (ya que se ‚Äúresta‚Äù un promedio sobre el conjunto de entrenamiento).\r\nUna submuestra (minilote) puede ser suficiente para estimar este valor esperado (con menor costo de c√≥mputo).\r\nAdem√°s, puede no ser tan buena idea intentar estimar el gradiente con la mejor precisi√≥n, pues solamente es una direcci√≥n de descenso local as√≠ que puede que no se proporcione la mejor decisi√≥n de a d√≥nde moverse en cada punto. Es mejor hacer iteraciones m√°s r√°pidas con direcciones estimadas.\r\n\r\nCalcular el gradiente completo para descenso en gradiente es computacionalmente ineficiente. Si el conjunto de entrenamiento es muy grande, el descenso en gradiente no es factible.\r\nCOn respecto al tama√±o del minilote, minilotes m√°s grandes dan mejores eficiencias en paralelizaci√≥n (pues hay multiplicaci√≥n de minilotes). Sin embargo, con mililotes m√°s grandes puede que se haga trabajos de m√°s (por lo que se dijo eternamente). El mejor punto est√° en minilotes peque√±os (no se aprovecha paralelismo) √≥ grandes (se hace demasiado trabajo por iteraci√≥n).\r\nLa propiedad m√°s importante de descenso estoc√°stico es minilotes es que su convergencia no depende del tama√±o del conjunto de entrenamiento, i.e.¬†el tiempo de iteraci√≥n para descenso estoc√°stico no crece con el n√∫mero de casos totales.\r\nSe puede obtener buenos ajustes incluso con tama√±os muy grandes de conjuntos de entrenamiento.\r\nEn este sentido, descenso estoc√°stico estacala bien, el factor limitante es el tama√±o del minilote y el n√∫mero de iteraciones.\r\n\r\nEs importante permutar al azar los datos antes de hacer los minibatches, pues √≥rdenes naturales en los datos pueden afectar la convergencia. Permutar los minibatches en cada iteraci√≥n puede acelerar la convergencia.\r\nTasa de aprendizaje\r\nPara seleccionar la tasa de aprendizaje, se ibservan las curvas n√∫mero de iteraciones \\(\\mapsto\\) funci√≥n objetivo tanto para las muestras de entrenamiento como el de validaci√≥n.\r\nSi la tasa es muy grande, habr√° oscilaciones grandes e incrementos grandes en la funci√≥n objetivo (llevando a errores de entrenamiento grandes).\r\nAlgunas oscilaciones suaves no tienen problemas, son end√©micos de la naturaleza estoc√°stica del algor√≠tmo.\r\nSi la tasa es muy baja, el aprendizaje es alto y puede que se quede en un valor muy alto de la funci√≥n objetivo.\r\nEs importante explorar distintas tasas de aprendizaje c√∫n cuando no parezca haber oscilaciones grandes o convergencia muy lenta. En algunos casos, si la tasa es demasiado grande, puede que el algor√≠tmo llegue a zonas con gradientes cercanos a 0 y tenga dificultas para moverse.\r\nLa tasa de aprendizaje es uno de los par√°metros m√°s importantes a tunear.\r\nDescenso estoc√°stico con momento\r\nSe separa al azar los datos de entrenamiento en \\(n\\) minlotes de tama√±o \\(m\\).\r\nPara √©pocas \\(e \\in \\{ 1, 2, ..., n_{\\rho}\\}\\)\r\nCalcular el gradiente sobhre el minlote, y hacer la actualizaci√≥n sucesivamente para cada uno de los minilotes \\(k = 1,2,...,n\\)\r\n\\[\\begin{align*}\r\n\\beta_{i+1} & \\leftarrow \\beta_i+ \\nu \\\\\r\n\\nu &\\leftarrow \\alpha \\nu -\\eta \\frac{1}{m} \\sum_{j=1}^m\\bar{\\nu}D_j^{(k)}(\\beta_i)\r\n\\end{align*}\\]\r\ndonde \\(D_j^{(k)}(\\beta_i)\\) es la funci√≥n objetivo (devianza, suma de cuadrados, etc.) para el \\(j\\)-√©simo caso del minilote \\(k\\). \\(\\nu\\) se le conoce como velocidad\r\n\r\nRepetir para la siguiente √©poca.\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2021-06-05T21:55:06-05:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-05-29-redes-neuronales-4/",
    "title": "Redes neuronales 4",
    "description": "Redes neuronales 4",
    "author": [
      {
        "name": "Eduardo Selim M. M.",
        "url": {}
      },
      {
        "name": "Carlos A. Ar.",
        "url": {}
      }
    ],
    "date": "2021-05-29",
    "categories": [
      "redes neuronales"
    ],
    "contents": "\r\n\r\nContents\r\nRedes convolucionales\r\nPropiedades\r\nConexiones ra‚Äôas\r\nPar√°metros compartidos\r\nEquivarianza\r\n\r\n\r\nFiltros convolucionales\r\nFiltros en una dimensi√≥n\r\n\r\n\r\nRedes convolucionales\r\nLas redes convolucionales son un tipo de red que utiliza ciertos supuestos acerca de las ponderaciones, a diferencia de las redes totalmente conexas donde las ponderaciones pueden tomar cualquier valor.\r\nEstas adecuaciones sirven para explotar la estructura de se√±ales, muy √∫til para ciertas aplicaciones de sonido, im√°genes y texto.\r\nEn estos casos, se trata de entradas que tienen una estuctura adicional de proximidad (pixeles cercanos o lejanos, tiempos cercanos o lejanos, etc.)\r\nLas redes convolucionales son la arquitectura m√°s exitosa para trabajar problemas con estructura espacial o temporal.\r\nPropiedades\r\nHay 3 propiedades b√°sicas que se quieren rescatar con el uso de redes convolucionales:\r\nConexiones ra‚Äôas\r\nExisten unidades que s√≥lo est√°n conectadas a una fracci√≥n relativamente peque√±a de la capa anterior (a diferencia de las redes totalmente conexas). Por ejemplo, una unidad que quiere detectar una forma en una esquina de una imagen no necesita estar conectada a pixeles de otras partes de la imagen.\r\nPar√°metros compartidos\r\nDiferentes unidades tienen ponderaciones compartidas. Por ejemplo, una unidad que busca detectar cierto sonido en diferentes partes de una grabaci√≥n pueden utilizar las mismas ponderaciones. Se puede ‚Äúmover‚Äù el derector (con las mismas ponderaciones) alo largo de la grabaci√≥n para ver d√≥nde detecta el sonido de inter√©s.\r\nEquivarianza\r\nUna traslaci√≥n de ina entrada (es tiempo o espacio) genera una translaci√≥n equivalente en la salida. Por ejemplo, si una unidad asociada a la esquina superior derecha de una imagen detecta un patr√≥n, entonces habr√° otra unidad que puede detectar el patr√≥n en la esquina inferior.\r\nTodas estas propiedades inducen estructura en comparaci√≥n con una red totalmente conexa.\r\nCuando esta estructura es la adecuada, no genera sesgo adicional y reduce considerablemtne la varianza y el tama√±o de los modelos.\r\nEl √©xito en este tipo de redes est√° en encontrar la estructura apropiada para el problema que se ent√° trabajando.\r\nFiltros convolucionales\r\nFiltros en una dimensi√≥n\r\nEl caso que quiz√° ya conocen es el de filtros en series de tiempo.\r\nUn filtro es una transformaci√≥n de una se√±al que pretende extraer ciertas caracter√≠sticas y suprimir otras.\r\nPor ejemplo, para una serie y sus correspondientes promedios m√≥viles centrados de longitud \\(5\\). Los promedios m√≥viles filtran las componentes de frecuencia alta (variaciones en tiempos cortos).\r\nSe puede escribir este filtro de la siguiente manera\r\n\\[\r\ny_t : = \\frac{1}{5}(x_{t-2} + x_{t-1} + x_{t} + x_{t+1} + x_{t+2})\r\n\\]\r\ndonde \\(\\{x_t\\}\\) es la serie original y \\(\\{y_t\\}\\) es la serie filtrada.\r\nSe puede escribir esta operaci√≥n de la siguiente forma: \\[\\begin{align*}\r\nf &= \\frac{1}{5} (..., 0,0,1,1,1,1,1,0,0,...)\\\\\r\n\\text{donde } f_s &= \r\n\\begin{cases}\r\n\\frac{1}{5}, \\text{ si } s = -2, -1, 0, 1, 2 \\\\\r\n0, \\text{ c.o.c.}\r\n\\end{cases} \\\\\r\n\\text{Entonces}\\\\\r\ny_t &= x_{t-2}f_2 + x_{t-1}f_1 + x_{t}f_0+ x_{t+1}f_1 + x_{t}f_2 \\\\\r\n&=\\sum_{s = -\\infty}^{\\infty} x_sf_{s-t}\r\n \r\n\\end{align*}\\]\r\nEste es un ejemplo de filtro convolucional del tipo que se usa en redes neuronales: Es un vector \\(f\\) que se aplica a la serie \\(\\{x_t\\}\\) como en la ecuaci√≥n anterior para obtener una serie transformada (filtrada) \\(\\{y_t\\}\\). El vector se desplaza a lo largo de la serie para obtener distintos valores filtrados.\r\nOtro ejemplo son las diferencias de orden 1: la diferencia entre el valor actual menos el valor anterior.\r\nEste filtro toma valores altos cuando la serie y el valores bajos cuando la serie decrece.\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2021-06-05T21:55:21-05:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-05-26-regresin-lineal-mltiple/",
    "title": "Regresi√≥n lineal m√∫ltiple",
    "description": "Repaso de regresi√≥n lineal con m√∫ltiples variables explicativas.",
    "author": [
      {
        "name": "Eduardo Selim M. M.",
        "url": {}
      },
      {
        "name": "Carlos A. Ar.",
        "url": {}
      }
    ],
    "date": "2021-05-26",
    "categories": [
      "regresion"
    ],
    "contents": "\r\n\r\nContents\r\nEstimador de \\(\\beta\\)\r\nIntervalo de confianza para \\(\\hat{\\beta}\\)\r\n\r\n\r\n\\[\r\ny = \\underbrace{\\beta_0 + \\beta_1x_1 + \\beta_2x_2 +...+ \\beta_kx_k+\\epsilon}_{\\text{funci√≥n de regresi√≥n}}\r\n\\]\r\nMuestralmente\r\n\\[\r\n(y_i, \\underbrace{x_{i1},x_{i1},...,x_{ik}}_{\\text{Covariables, } \\\\ \\text{variables predictoras,} \\\\ \\text{features, } \\\\ \\text{variables explicativas}}), \\space \\space \\space \\space i = 1,2,...,n \\\\ \\text{Donde } n \\text{ es el n√∫mero de observaciones.} \r\n\\]\r\nEntonces \\(y_i = \\beta_0 + \\beta_1 x_{i1} + ... + \\beta_k x_{ik} + \\epsilon_i\\) donde \\(\\epsilon_i \\sim N(0 , 1)\\) adem√°s de ser i.i.d.\r\nComo antes\r\n\\[\r\n\\mathbb{E}(y_i)= \\beta_0 + \\beta_1 x_{i1} + ... + \\beta_k x_{ik}\r\n\\]\r\nInterpretaci√≥n muy popular es que \\(\\beta_j\\) es el cambio esperado en \\(y\\), por unidad de cambio en \\(x_j\\) (ceteris paribus) puesto que\r\n\\[\r\n\\frac{\\partial \\mathbb{E}(y_i)}{\\partial x_j} = \\beta_j\r\n\\]\r\nEn t√©rminos matriciales\r\n\\[\r\n\\begin{equation}\r\n \\underbrace{\\begin{pmatrix}\r\n   y_1 \\\\\r\n   y_2 \\\\\r\n   \\vdots \\\\\r\n   y_n\r\n \\end{pmatrix}}_{y_{n \\times 1}}\r\n = \r\n\\underbrace{\\begin{pmatrix}\r\n   1     & x_{11} & x_{12} & \\dotso & x_{1k}\\\\\r\n   1     & x_{21} & x_{22} & \\dotso & x_{2k}\\\\\r\n  \\vdots & \\vdots & \\vdots & \\ddots & \\vdots\\\\\r\n   1     & x_{n1} & x_{n2} & \\dotso & x_{nk}\r\n \\end{pmatrix}}_{\\mathbb{X}_{n \\times (k+1)} \\\\ \\text{Matr√≠z de covariables} \\\\ \\text{Matriz de dise√±o}}\r\n\\underbrace{\\begin{pmatrix}\r\n   \\beta_0 \\\\\r\n   \\beta_1 \\\\\r\n   \\vdots \\\\\r\n   \\beta_k\r\n \\end{pmatrix}}_{\\beta_{(k+1) \\times 1}}\r\n+\r\n\\underbrace{\\begin{pmatrix}\r\n   \\epsilon_1 \\\\\r\n   \\epsilon_2 \\\\\r\n   \\vdots \\\\\r\n   \\epsilon_n\r\n \\end{pmatrix}}_{\\epsilon_{n \\times 1}}\r\n\\end{equation}\r\n\\]\r\nNos hacemos las mismas preguntas de siempre\r\n\\[\r\n\\rightarrow ¬ø\\hat{\\beta}? \\text{ ¬øC√≥mo obtengo los estimadores?}\\\\\r\n\\]\r\n\\[\r\n\\rightarrow y_i \\sim \\hat{y}_i, \\space \\space \\space \\space \\space  \\space \\space \\space \\space \\space \\space \\space \\Rightarrow \\space \\space \\space \\space  \\space\\space \\space \\space \\space  \\space \\space \\space  e_i = y_i - \\hat{y}_i\\\\\r\n\\]\r\n\\[\r\n\\rightarrow \\text{La certidumbre tanto de } \\hat{\\beta} \\text{ como de } \\hat{y}\\\\ \\text{(i.e. intervalos de confianza)} \\\\\r\n\\]\r\n\\[\r\n\\rightarrow \\text{Predicci√≥n: ¬øC√≥mo se comporta el modelo ante variables explicativas no observadas?}\\\\\r\n\\]\r\n\\[\r\n\\rightarrow \\text{Future Engineering, selecci√≥n de variables} \\\\\r\n \\text{¬øQu√© variables aportan a explicar } y \\text{?}\r\n\\]\r\nEstimador de \\(\\beta\\)\r\nSe obtiene por m√≠nimos cuadrados\r\nSe obtienen lo que se conoce como las ecuaciones normales.\r\n\\[\r\ny = \\mathbb{X} \\beta \\underbrace{\\Rightarrow }_{\\text{Multiplicamos por }  \\mathbb{X}^T} \\mathbb{X}^T y = \\mathbb{X}^T \\mathbb{X} \\beta \\\\\r\n\\underbrace{\\Rightarrow }_{\\text{Estamos suponiendo que }\\\\ \\text{esta matr√≠z es invertible}} \\hat{\\beta} = (\\mathbb{X}^T \\mathbb{X})^{-1} \\mathbb{X}^T y\r\n\\]\r\nComo antes\r\n\\[\r\nRSS = \\displaystyle \\sum_{i=1}^n (y_i - \\hat{y})^2  \\\\\r\nRegSS = \\displaystyle \\sum_{i=1}^n(\\hat{y}_i - \\bar{y})^2 \\\\\r\n \\text{ Estamos comparando el modelo de regresi√≥n}\\\\\r\n\\displaystyle TSS = \\sum_{i=1}^n (y_i - \\bar{y})^2 = (n-1) S_y^2\\\\\r\n\\text{Versus el modelo naiive}\\\\\r\n\\text{Valor } F := \\frac{RegSS/k}{Rss/(n-(k+1))}\\\\\r\n\\text{Se utiliza para evaluar si las } k \\text{ variables explicativas}\\\\\r\n\\text{son colectivamente √∫tiles para explicar.}\r\n\\]\r\nCon la hip√≥tesis de normalidad se demuestra que:\r\n\\[\r\n\\hat{\\beta} \\sim N_{k+1} \\bigg(\\beta, \\sigma^2(\\mathbb{X}^T\\mathbb{X})^{-1}\\bigg)\r\n\\]\r\nDefinici√≥n. (Coeficiente de determinaci√≥n \\(R^2\\))\r\n\\[\r\nR^2 = \\frac{RegSS}{TSS} = \\frac{\\displaystyle \\sum_{i=1}^n(\\hat{y}_i - \\bar{y})^2}{\\displaystyle \\sum_{i=1}^n(y_i - \\bar{y})^2}\r\n\\]\r\nTristemente üò¢en MLR (Multiple Linear Regression)ya no se cumple que\r\n\\[\r\nR^2 = r^2\r\n\\]\r\nSin embargo, s√≠ se cumple que\r\n\\[\r\nR^2 = \\bigg[\\frac{\\displaystyle \\sum_{i=1}^n(y_i - \\bar{y})(\\hat{y}_i - \\bar{y})}{\\underbrace{\\sqrt{\\displaystyle \\sum_{i=1}^n(y_i - \\bar{y})^2\\sum_{i=1}^n(\\hat{y}_i - \\bar{y})^2}}_{\\text{Es el cuadrado de la correlaci√≥n} \\\\ \\text{muestral entre }y \\text{ y } \\hat{y}}}\\bigg]^2\r\n\\]\r\n\\[\r\nF = \\frac{n-k-1}{k} \\cdot \\frac{R^2}{1-R^2}\r\n\\]\r\nAhora s√≠ a construir el intervalo de confianza.\r\nIntervalo de confianza para \\(\\hat{\\beta}\\)\r\nEst√° dado por\r\n\\[\r\n\\hat{\\beta}_j \\pm t_{n-(k+1), \\frac{\\alpha}{2}} \\sqrt{S^2 \\bigg(\\mathbb{X}^T\\mathbb{X}\\bigg)^{-1}_{j-1, j+1}}\r\n\\]\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2021-05-26T20:55:48-05:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-05-25-regresin-lineal-simple/",
    "title": "Regresi√≥n lineal simple",
    "description": "Repaso de regresi√≥n lineal con una variable explicativa.",
    "author": [
      {
        "name": "Eduardo Selim M. M.",
        "url": {}
      },
      {
        "name": "Carlos A. Ar.",
        "url": {}
      }
    ],
    "date": "2021-05-25",
    "categories": [
      "regresion"
    ],
    "contents": "\r\n\r\nContents\r\nModelos lineales\r\nRegresi√≥n cl√°sica\r\nModelos lineales generalizados\r\nModelos generalizados aditivos (GAM‚Äôs)\r\n\r\nRegresi√≥n Lineal Simple\r\nSuposiciones del modelo\r\nTSS: Total SS\r\nResidual SS √≥ Error SS\r\nRegSS: Regression SS\r\nLa prueba F\r\n\r\nPropiedades de \\(\\hat{\\beta_0}\\) y \\(\\hat{\\beta_1}\\)\r\nIntervalos de confianza para \\(\\beta_j\\)\r\n\r\n\r\n\r\nModelos lineales\r\nEs una t√©cnica supervisada. La respuesta ser√° \\(y\\) mientras que las variables explicativas, predictivas o covariables se denotar√°n por \\(x_1, x_2, ..., x_p\\). La familia de los modelos lineales es muy vers√°til.\r\nRegresi√≥n cl√°sica\r\n\\[\r\ny = \\beta_0 + \\beta_1 x_1 + ... + \\beta_p x_p\r\n\\]\r\nHay una relaci√≥n lineal entre \\(y\\) y \\(x_1, x_2, ..., x_p\\)\r\nModelos lineales generalizados\r\n\\[\r\ng(y) = \\beta_0 + \\beta_1 x_1 + ... + \\beta_p x_p\r\n\\]\r\nDonde \\(g\\) es una funci√≥n.\r\nEjemplos por excelencia de este tipo de rtegresi√≥n:\r\nRegresi√≥n log√≠stica.\r\nRegresi√≥n Poisson.\r\nModelos generalizados aditivos (GAM‚Äôs)\r\n\\[\r\ny = \\beta_0 + \\beta_1 g(x_1) +\\beta_2 g(x_2) + ... + \\beta_p g(x_p)\r\n\\]\r\nEn general nos interesan al menos 5 cosas (independientemente del modelo lineal a trabajar).\r\n¬øC√≥mo se estiman las \\(\\beta ' ^s\\)?\r\n¬øAlgunas propiedades que tienen los estimadores \\(\\hat{\\beta}'^s\\)?\r\nInsesgado\r\nVarianza\r\nIntervalo de confianza\r\n\r\nPredicci√≥n \\(\\hat{y}_i\\)\r\nBondad de ajuste, es decir ¬ø\\(y_i \\approx \\hat{y_i}\\)?\r\n¬øCu√°les de entre \\(x_1, ..., x_p\\) son importantes para determinar la relaci√≥n con \\(y\\)? Selecci√≥n de variables o feature engineering.\r\nRegresi√≥n Lineal Simple\r\nSuposiciones del modelo\r\nEl modelo SLR (Simple Linear Regression) se basa en algunas suposiciones:\r\n\\[\r\ny_i = \\beta_0 + \\beta_1x_i + \\epsilon_i,\\\\ i = 1,...,n\\text{ es decir, el n√∫mero de observaciones es }n\r\n\\]\r\n\\(y_i'^s\\) son realizaciones de variables aleatorias. Los valores \\(x_i\\) son no-aleatorios.\r\nLas cantidades \\(\\epsilon_1, ..., \\epsilon_n\\) representan errores aleatorios que son independientes entre s√≠ y adem√°s:\r\n\\(\\mathbb{E}(\\epsilon_i) = 0, i = 1,...,n\\)\r\n\\(Var(\\epsilon_i) = \\sigma^2\\) Conocida como Hip√≥tesis de homocedasticidad.\r\nBajo estos supuestos se tiene que\r\n\\(\\mathbb{E}(y_i) = \\beta_0 + \\beta_1x_i\\)\r\n\\(Var(y_i) = Var(\\beta_0 + \\beta_1x_i + \\epsilon_i) = Var(\\epsilon_i) = \\sigma^2\\)\r\nCosas que ya deber√≠amos saber:\r\nEstimaci√≥n de \\(\\beta_0\\) y \\(\\beta_1\\) por m√≠nimos cuadrados.\r\n\\[\r\nSS(\\beta_0, \\beta_1) := \\sum_{i=1}^n[\\underbrace{y_i}_{\\text{observado}} - \\underbrace{(\\beta_0 + \\beta_1x_i)}_{\\text{Supuesto}}]^2\r\n\\]\r\nSe seleccionan \\(\\beta_0, \\beta_1\\) de tal forma que se minimice \\(SS(\\beta_0, \\beta_1)\\) (lo cual es un problema cl√°sico de optimizaci√≥n).\r\n\\[\r\n\\hat{\\beta}_1 = \\frac{\\displaystyle \\sum_{i=1}^n(x_i - \\bar{x})(y_i - \\bar{y})}{\\displaystyle \\sum_{i=1}^n(x_i - \\bar{x})^2} = \\frac{S_{xy}}{S_{xx}}\r\n\\]\r\n\\[\r\n\\hat{\\beta}_0 = \\bar{y} - \\hat{\\beta_1}\\bar{x}\r\n\\]\r\ndonde\r\n\\[\r\nS_{xy} = \\displaystyle \\sum_{i=1}^n(x_i - \\bar{x})(y_i - \\bar{y}) = \\displaystyle \\sum_{i=1}^n x_iy_i - n\\bar{x}\\bar{y}\\\\\r\nS_{xx} = \\displaystyle \\sum_{i=1}^n(x_i - \\bar{x})^2 = \\displaystyle \\sum_{i=1}^n x_i^2 - n\\bar{x}^2\r\n\\]\r\nUna propiedad interesante de estos estimadores es la siguiente\r\n\\[\r\n\\hat{\\beta}_1 = r_{xy}\\frac{S_y}{S_x}\r\n\\]\r\ndonde\r\n\\[\r\nS_y := \\displaystyle \\sqrt{\\frac{1}{n-1} \\sum_{i=1}^{n}(y_i-\\bar{y})^2 }\\\\\r\nS_x := \\displaystyle \\sqrt{\\frac{1}{n-1} \\sum_{i=1}^{n}(x_i-\\bar{x})^2 }\\\\\r\n\\text{Coeficiente de correlaci√≥n muestral entre }x \\text{ y } y:\\\\\r\nr_{xy} = \\frac{S_{xy}}{\\sqrt{S_{xx} S_{yy}}}\r\n\\]\r\nEste resultado ‚Äújustifica‚Äù el caso de la correlaci√≥n como medida de asociaci√≥n lineal y el dibujo que nos encanta ‚ù§Ô∏è\r\n\r\nYa con estos \\(\\hat{\\beta}_0\\) y \\(\\hat{\\beta}_1\\) en la mano, podemos definir \\(\\hat{y}_i = \\hat{\\beta}_0 + \\hat{\\beta}_1 x_i\\) como el ajustado y tambi√©n los residuales como\r\n\\[\r\n\\hat{\\epsilon}_i = e_i := y_i - \\hat{y}_i\r\n\\]\r\nImportante\r\n\\[\r\n\\text{Residuales} \\neq \\text{Errores aleatorio}\\\\\r\n\\underbrace{e_i}_{\\text{Calculables, reales}}\r\n\\space \\space \\space¬†\\space \\space \\space\\space\\space\\space\r\n \\underbrace{\\epsilon_i}_{\\text{Variables aleatorias}\\\\\\text{no observables}}\r\n\\]\r\nEn los cursos se demuestra que\r\n\\(\\displaystyle \\sum_{i=1}^n e_i = 0\\)\r\n\\(\\displaystyle \\sum_{i=1}^n x_ie_i = 0\\)\r\nPara hacer inferencia, tenemos que hacer algunas suposiciones, la m√°s com√∫n es \\(\\epsilon_i \\sim N(0, \\sigma^2)\\) y adem√°s que \\(\\epsilon_1, \\epsilon_2, ..., \\epsilon_n\\) son i.i.d‚Äôs.\r\nEsta suposici√≥n nos lleva a que\r\n\\[\r\ny_i \\sim N(\\beta_0 + \\beta_1x_i, \\sigma^2)\r\n\\]que es algo fuerte de suponer.\r\nTenemos que ‚Äúevaluar‚Äù qu√© tan bueno es el modelo, es decir, si incorporar a la variable \\(x\\) para explicar \\(y\\) es valioso. Entonces\r\n\\[\r\n\\underbrace{\\displaystyle \\sum_{i=1}^n (y_i - \\hat{y}_i)^2}_{\\text{Modelo de}\\\\ \\text{regresi√≥n}} < \\underbrace{\\displaystyle \\sum_{i=1}^n (y_i - \\bar{y}_i)^2}_{\\text{Modelo naive}\\\\ \\text{iid}}\r\n\\]\r\nUna descomposici√≥n popular es:\r\n\\[\r\ny_i - \\bar{y} = y_i - \\hat{y}_i + \\hat{y}_i - \\bar{y} \\\\\r\n\\]\r\n\\[\r\n\\Rightarrow \\text{ (Se demuestra)} \\\\\r\n\\]\r\n\\[\r\n\\underbrace{ \\displaystyle \\sum_{i=1}^n (y_i - \\bar{y})^2}_{\\text{TSS}} = \\underbrace{ \\displaystyle \\sum_{i=1}^n (y_i - \\hat{y}_i)^2}_{\\text{RSS √≥}\\\\\r\n\\text{Error S}} + \\underbrace{ \\displaystyle \\sum_{i=1}^n (\\hat{y}_i - \\bar{y})^2}_{\\text{Reg SS}}\r\n\\]\r\nTSS: Total SS\r\n\\(\\displaystyle \\sum_{i=1}^n (y_i - \\bar{y})^2 = (n-1) S_y^2\\)\r\nVariaci√≥n de la respuesta con respecto a su media muestral \\(\\bar{y}\\)\r\nCantidad de variabilidad inherte en las respuestas antes de realizar la regresi√≥n.\r\nResidual SS √≥ Error SS\r\n\\[\r\nRSS = \\displaystyle \\sum_{i=1}^n (y_i - \\hat{y})^2 \r\n\\]\r\nVariaci√≥n de la respuesta con respecto a la rexta de regresi√≥n\r\nMide la bondad de ajuste de LSR. Mientras m√°s bajo, mejor \\(\\downarrow\\) üòÑ\r\nMide la cantidad de variabilidad de la respuesta que no es explicada a√∫n despu+es de introducir \\(x\\)\r\n\r\nRegSS: Regression SS\r\n\\(RegSS = \\displaystyle \\sum_{i=1}^n(\\hat{y}_i - \\bar{y})^2\\)\r\nVariaci√≥n explicada por el modelo SLR i.e.¬†el conocimiento de \\(x\\) v.s. el deconocimiento de \\(x\\).\r\nMide qu√© tan efectivo es el modelo SLR en explicar la variaci√≥n en \\(y\\). (Incorporar \\(x\\) v.s. no incorporar \\(x\\)).\r\n\r\nTrivialmente \\(RSS < TSS\\)\r\nComo \\(TSS\\) permanece fijo, mientras m√°s grande sea \\(RegSS\\), m√°s peque√±o ser√° \\(RSS\\)\r\n\\[\r\nRegSS \\text{ grande & } RSS \\text{ peque√±o } \\rightarrow \\text{ fue buena idea introducir }x \r\n\\]\r\nLo anterior motiva la definici√≥n de \\(R^2\\) a.k.a. coeficiente de determinaci√≥n\r\n\\[\r\nR^2 := \\frac{RegSS}{TSS} = 1- \\frac{RSS}{TSS}\r\n\\]\r\nSe requiere que \\(R^2\\) sea lo m√°s cercano posible a 1.\r\nMientras m√°s grande sea el valor de \\(R^2\\), m√°s efectiva ser√° la recta de regresi√≥n en reducir la varianza de \\(y\\).\r\nEn SLR hay relaciones entre \\(\\hat{\\beta}_1\\) y \\(RSS\\)\r\n\\(RegSS = \\hat{\\beta}_1^2 S_{xx}\\)\r\n\\(RSS = S_{yy} - \\hat{\\beta}_1^2S_{xx}\\)\r\nComo \\(S_{xx}\\) no cambia, entonces si \\(\\hat{\\beta}_1\\) es grande, sucede que \\(RegSS\\) es grande y por tanto fue buena idea introducir \\(x\\).\r\nTambi√©n se puede demostrar que en SLR\r\n\\[\r\nR^2 = \\underbrace{r_{xy}^2}_{\\text{Cuadrado del}\\\\ \\text{coeficiente de}\\\\ \\text{Correlaci√≥n} \\\\ \\text{muestral}} = \\bigg(\\frac{S_{xx}}{\\sqrt{S_{xx}\\cdot S_{yy}}}\\bigg)^2\r\n\\]\r\nOtra cantidad popular en el an√°lisis de regresi√≥n es\r\n\\[\r\n\\boxed{MSE := \\frac{RSS}{n-2} = \\frac{\\displaystyle \\sum_{i=1}^ne_i^2}{n-2} =: S^2} \r\n\\]\r\nAdem√°s \\(S^2\\) es un estimador insesgado de \\(\\sigma^2\\), es decir \\(\\mathbb{E}(S^2) = \\sigma^2\\)\r\nPara probar formalmente si \\(RegSS = \\displaystyle \\sum_{i = 1} ^n ( \\hat{y}_i - \\bar{y})^2\\) es suficientemente grande, se lleva a cabo\r\nLa prueba F\r\n\\[\r\n\\underbrace{H_0: \\beta_1 = 0}_{\\text{agregar } x \\text{ no} \\\\ \\text{redujo la variabilidad} \\\\ \\text{de }y} \\space \\space \\space \\space \\space \\space \\space H_a: \\beta_1 \\neq 0\r\n\\]\r\nEstad√≠stica de prueba \\(F := \\frac{RegSS/1}{Rss/(n-2)}\\)\r\nSea \\(F_{1, n-2, \\alpha} \\in \\mathbb{R}\\) tal que \\(\\mathbb{P}(F_{1,n-2}> \\underbrace{F_{1, n-2, \\alpha}}_{\\text{upper cuantil}}) = \\alpha\\)\r\nRegla de decisi√≥n\r\nSi \\(\\underbrace{F}_{\\text{estad√≠stica}\\\\ \\text{de prueba}} > F_{1, n-2, \\alpha}\\) entonces se rechaza \\(H_0\\)\r\nO bien a trav√©s del \\(p-value\\)\r\n\\[\r\n\\text{Si } \\mathbb{P}(F_{1,n-2} > F) < \\alpha, \\text{ entonces se rechaza } H_0\r\n\\]\r\nMientras m√°s peque√±o sea el \\(p-value\\), se tendr√° evidencia m√°s fuerte para rechazar \\(H_0\\)\r\n\r\nUna relaci√≥n ‚Äúbonita‚Äù entre \\(F\\) y \\(R\\) (en SLR)\r\n\\[\r\nF = \\frac{RegSS/1}{Rss/(n-2)} = (n-2)\\frac{R^2}{1-R^2} = (n-2)\\frac{r_{xy}^2}{1-r_{xy}^2}\\\\\r\n\\text{Obs: la aplicaci√≥n } R^2 \\mapsto F = (n-2)\\frac{R^2}{1-R^2} \\text{ es creciente.}\r\n\\]\r\nPropiedades de \\(\\hat{\\beta_0}\\) y \\(\\hat{\\beta_1}\\)\r\nSi \\(\\epsilon \\sim N(0, \\sigma^2)\\), entonces \\(\\hat{\\beta_0}\\) y \\(\\hat{\\beta_1}\\) tienen tambi√©n distribuci√≥n Gaussiana:\r\n\\[\r\n\\mathbb{E}(\\hat{\\beta_0}) = \\beta_0\\\\\r\n\\mathbb{E}(\\hat{\\beta_1}) = \\beta_1\\\\\r\n\\text{Es decir que son estimadortes insesgados}\\\\\r\nVar(\\hat{\\beta_0}) = \\sigma^2 \\bigg(\\frac{1}{n} + \\frac{\\bar{x}^2}{S_{xx}}\\bigg) \\\\\r\nVar(\\hat{\\beta_1}) = \\frac{\\sigma^2}{S_{xx}}\\\\\r\nCov(\\hat{\\beta_0}, \\hat{\\beta_1}) = \\frac{-\\bar{x}\\sigma^2}{S_{xx}}\r\n\\]\r\nLas desviaciones est√°ndar estimadas de \\(\\hat{\\beta_0}\\) y \\(\\hat{\\beta_1}\\) se denotan como \\(SE(\\hat{\\beta_0})\\) y \\(SE(\\hat{\\beta_1})\\), respectivamente y se conocen como errores est√°ndar.\r\nSon medidas de la confiabilidad √≥ precauci√≥n de los LSE¬¥s\r\nDe donde\r\n\\[\r\nSE(\\hat{\\beta_0}) = \\sqrt{S^2 \\bigg(\\frac{1}{n} + \\frac{\\bar{x}^2}{S_{xx}}\\bigg)} \\\\\r\nSE(\\hat{\\beta_1}) = \\sqrt{\\frac{S^2}{S_{xx}}}\r\n\\]\r\n\\(S^2 \\mapsto SE(\\hat{\\beta}_0^2)\\) es creciente.\r\n\\(S^2 \\mapsto SE(\\hat{\\beta}_1^2)\\) es creciente.\r\n\\(S_{xx} \\mapsto SE(\\hat{\\beta}_0^2)\\) es decreciente.\r\n\\(S_{xx} \\mapsto SE(\\hat{\\beta}_1^2)\\) es decreciente.\r\nRecordemos que \\(S_{xx} = \\displaystyle \\sum_{i=1}^n(x_i-\\bar{x})^2\\)\r\n\r\nLo anterior graficamente se puede ver as√≠\r\n\r\nLos errores est√°ndar ser√°n peque√±os si las observaciones muestran gran tendencia a estar cerca de la recta de regresi√≥n y si los valores observados de la variable explicativa (i.e.¬†\\(x\\)) est√°n m√°s ‚Äúdispersos‚Äù a lo largo del eje \\(x\\) (es decir, \\(S_{xx}\\) grande).\r\nPuede suceder que exista m√°s dispersi√≥n pero eso no es garant√≠a de un ‚Äúbuen ajuste‚Äù.\r\n\r\n\r\nIntervalos de confianza para \\(\\beta_j\\)\r\nA partir de los errores est√°ndar ya definidos, se puede demostrar que los intervalos del \\((1-\\alpha)\\%\\) de confianza para \\(\\beta_j\\) es:\r\n\\[\r\n\\hat{\\beta}_j \\pm \\underbrace{t_{n-2, \\frac{\\alpha}{2}}}_{\\text{upper cuantil}\\\\ \\text{al nivel } \\frac{\\alpha}{2} \\text{ de una} \\\\ \\text{distribuci√≥n } t_{(n-2)}} \\cdot SE(\\hat{\\beta}_j), \\space \\space \\space \\space \\space i = 0,1\r\n\\]\r\nEn general se pueden plantear hip√≥tesis de la siguiente manera:\r\n\\(H_0: \\beta_j = d\\) v.s. \\(H_1: \\beta_j \\neq d\\)\r\n\\(H_0: \\beta_j = d\\) v.s. \\(H_1: \\beta_j > d\\)\r\n\\(H_0: \\beta_j = d\\) v.s. \\(H_1: \\beta_j < d\\)\r\nDonde \\(d \\in \\mathbb{R}\\) especificado por el usuario.\r\nPara este tipo de contraste us√°bamos la prueba \\(t\\).\r\n\\[\r\nt(\\hat{\\beta}_j) = \\frac{\\hat{\\beta}_j - d}{SE(\\hat{\\beta}_j)}, \\space \\space \\space \\space  \\space \\space j = 0,1 \r\n\\]\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2021-05-26T12:33:02-05:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-05-21-regresin-ordinal/",
    "title": "Regresi√≥n ordinal",
    "description": "Definici√≥n y resultados",
    "author": [
      {
        "name": "Eduardo Selim M. M.",
        "url": {}
      },
      {
        "name": "Carlos A. Ar.",
        "url": {}
      }
    ],
    "date": "2021-05-22",
    "categories": [
      "regresion"
    ],
    "contents": "\r\n\r\nContents\r\nModelo logit acumulado\r\nModelo de odds proporcionales\r\nRespuesta de conteo\r\nModelo de regresi√≥n Poisson\r\n\r\nEstimaci√≥n m√°ximo veros√≠mil\r\n\r\nLa variable respuesta es categ√≥rica ordinal.\r\nComo antes \\(\\pi_j = \\mathbb{P}(y = j), j = 1,2,...,c\\)\r\nSolo \\(c-1\\) de estas probabilidades son libres pues \\(\\pi_1 + \\pi_2 +...+\\pi_c = 1\\) y estas probabilidades se requieren modelar en t√©rminos de variables explicativas.\r\nSe estudiar√°n 2 propuestas para este tipo de variables\r\nModelos logit acumulado\r\n\r\nModelo de odds proporcionales\r\n\r\n\r\nModelo logit acumulado\r\nUsa el link logit para explicar las probabilidades acumuladas:\r\n\\[\r\n\\tau_j := \\pi_1 + ... + \\pi_j, j = 1, ..., c-1\r\n\\]\r\nEs decir,\r\n\\[\r\n\\log\\bigg(\\frac{\\tau_j}{1-\\tau_j}\\bigg) = \\underline{x}^T\\beta_j = \\beta_{0j} + \\beta_{1j}x_1 + ... + \\beta_{kj}x_k \r\n\\]\r\nDe nuevo, hay \\(c-1\\) regresiones\r\n\r\n\\(\\log\\bigg(\\frac{\\tau_j}{1-\\tau_j}\\bigg) = \\underline{x}^T\\beta_j\\) se puede escribir como\r\n\\[\r\n\\log\\bigg(\\frac{\\pi_1+...+\\pi_j}{\\pi_{j+1} + ... + \\pi_c}\\bigg) = \\underline{x}^T\\beta_j, j = 1,2,...,c-1\r\n\\]\r\nPor ejemplo, si \\(c = 3\\) y hay 4 variables explicativas \\(x_1, x_2,x_3,x_4\\), se tienen 2 ecuaciones:\r\n\\[\r\n\\log\\bigg(\\frac{\\pi_1}{\\pi_2+\\pi_3}\\bigg) = \\beta_{01} +\\beta_{11}x_1 + \\beta_{21}x_2 + \\beta_{31}x_3 + \\beta_{41}x_4\\\\\r\n\\log\\bigg(\\frac{\\pi_1+\\pi_2}{\\pi_3}\\bigg) = \\beta_{02} +\\beta_{12}x_1 + \\beta_{22}x_2 + \\beta_{32}x_3 + \\beta_{42}x_4\r\n\\]\r\nComo antes, se puede escribir \\(\\tau_j\\) como:\r\n\\[\r\n\\tau_j = \\frac{1}{1+\\exp\\{-\\underline{x}\\beta_j\\}}\r\n\\]\r\nModelo de odds proporcionales\r\nEs un caso particular del modelo logit acumulativo en el que \\(\\beta_{0j}\\) (el intercepto) var√≠a para cada \\(j\\) pero los otros coeficientes de regresi√≥n no dependen de \\(j\\).\r\nLas ecuaciones del modelo son:\r\n\\[\r\n\\log\\bigg(\\frac{\\tau_j}{1-\\tau_j}\\bigg) = \\underbrace{\\beta_{0j}}_{\\text{cambia para cada } j } + \\beta_1x_1 + ... + \\beta_kx_k, j = 1,...,c-1\r\n\\]\r\nDe nuevo, hay \\(c-1\\) regresores.\r\nEstas \\(c-1\\) ecuaciones tienen diferentes interceptos pero la misma pendiente con respecto a cada variable explicativa.\r\nRespuesta de conteo\r\nSe considerar√°n variables respuesta que representan conteos de cierto evento de referencia.\r\nModelo de regresi√≥n Poisson\r\nPara variables de conteo, una elecci√≥n popular es la distribuci√≥n Poisson\r\n\\[\r\ny \\backsim Poisson(\\mu) \\text{ con } g(\\mu) = \\underline{x}^T\\beta\r\n\\]\r\nPara la distribuci√≥n Poisson, la funci√≥n link can√≥nica es la funci√≥n \\(g(\\mu) = \\log(\\mu)\\)\r\nDe aqu√≠ que \\(\\mu = \\exp\\{\\underline{x}^T\\beta\\}\\)\r\nRegresi√≥n:\r\nRespuesta\r\n\r\nLink\r\nPoisson:\r\nPoisson\r\n&\r\nLog\r\n\r\nOffset: En estudios de datos de conteo, los conteos observados \\(y_1,...,y_n\\) pueden no ser directamente comparables entre s√≠, debido a sus exposures. Por ejemplo,\r\nEl n√∫mero de accidentes en un seguro de autom√≥viles depende del n√∫mero de veh√≠culos asegurados y el plazo de la cobertura.\r\nEl n√∫mero de muertes en un estudio de mortalidad se incrementa con el n√∫mero de sujetos y la duraci√≥n del estudio.\r\n\r\n\\(\\log(\\mu_i) = \\underbrace{\\log(E_i)}_{\\text{offset}} + \\beta_0 + \\beta_1x_1 + ... + \\beta_kx_k\\) es decir, se agrega un t√©rmino de ‚Äúexposici√≥n‚Äù, es decir \\(\\mu_i = E_i \\cdot exp\\{\\underline{x}^T_i \\beta\\}\\)\r\n\\(\\log(E_i)\\) se puede pensar como un intercepto observation-specific conocido.\r\nEstimaci√≥n m√°ximo veros√≠mil\r\n\\[\r\nL(\\beta) = \\prod_{i=1}^n \\frac{e^{-\\mu_i} \\mu_i^{y_i}}{y_i !} \\propto  \\prod_{i=1}^n e^{-\\mu_i} \\mu_i^{y_i} = \\prod_{i=1}^n e^{-\\exp\\{-\\underline{x}_i^T\\beta\\}} (\\exp\\{-\\underline{x}_i^T\\beta\\})^{y_i} \r\n\\]\r\nEntonces\r\n\\[ \r\nl(\\beta) = \\sum_{i=1}^n\\bigg(-e^{-\\underline{x}_i^T\\beta} + y_i (\\underline{x}_i^T\\beta)\\bigg) + cte\r\n\\]\r\nDe aqu√≠ que\r\n\\[\r\n\\frac{d}{d\\beta}l(\\beta) = \\sum_{i=1}^n\\bigg(-e^{-\\underline{x}_i^T\\beta} + y_i \\underline{x_i}\\bigg) = \\sum_{i=1}^n(y_i -\\mu_i)\\underline{x_i}\\\\\r\n\\frac{d}{d\\beta}l(\\beta) = 0 \\iff \\underbrace{\\sum_{i=1}^n(y_i -\\mu_i)\\underline{x_i} = \\underline{0}}_{\\text{Se resuelve con respecto de }\\beta \\\\ \\text{que aparece en las }\\mu_i'^s\\text{ pues} \\\\ \\mu_i = \\exp\\{\\underline{x}_i^T\\beta\\}}\\]\r\nLa soluci√≥n \\(\\hat{\\beta}\\) genera las medias ajustadas\r\n\\[\\hat{ \\mu}_i = \\exp\\{\\underline{x}_i^T\\beta\\}\\]\r\nQue satisface\r\n\\[\r\n\\sum_{i=1}^n(y_i -\\hat{\\mu}_i)\\underline{x_i} = \\underline{0}\\\\\r\n\\text{Esto implica que } \\sum_{i=1}^ny_i = \\sum_{i=1}^n \\hat{\\mu}_i\\\\\r\n\\text{Entonces } \\sum_{i=1}^ne_i = \\sum_{i=1}^n (y_i -\\hat{\\mu}_i) = 0\\\\\r\n\\text{i.e. la suma de los residuales es } 0\r\n\\]\r\nLa correspondiente matriz de informaci√≥n\r\n\\[\r\nI(\\beta) = -E\\bigg(\\frac{d^2}{d\\beta d\\beta^T} l(\\beta)\\bigg) = \\sum_{i=1}^{n} \\mu_i \\underbrace{(\\underline{x}_i\\underline{x}_i^T)}_{\\text{una matr√≠z}}\r\n\\]\r\ndepende de \\(\\beta\\) a trav√©s de las \\(\\mu_i¬¥^s\\)\r\nPor ejemplo, cuando hay una sola variable explicativa.\r\n\\[\r\n\\log(\\mu_i) = \\beta_0+\\beta_1x_i, i = 1,2,...,n = (1\\space \\space\\space\\space x_i)  \\binom{\\beta_0}{\\beta_1}\r\n\\]\r\nA partir de la ecuaci√≥n de m√°xima verosimilitud\r\n\\[\r\n\\sum_{i=1}^n (y_i - \\hat{\\mu_i})\\underline{x}_i = \\underline{0} \\iff \\binom{\\sum_{i=1}^n (y_i - \\hat{\\mu_i})}{\\sum_{i=1}^n x_i(y_i - \\hat{\\mu_i})} = \\binom{0}{0}\r\n\\]\r\nEs decir,\r\n\\[\r\n\\begin{cases}\r\n\\displaystyle \\sum_{i=1}^n y_i = \\sum_{i=1}^n \\hat{\\mu}_i\\\\\r\n\\\\\r\n\\displaystyle \\sum_{i=1}^n x_i e_i = 0\r\n\\end{cases}\r\n\\]\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2021-05-21T20:19:34-05:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-05-20-diagnstico-de-modelos/",
    "title": "Diagn√≥stico del modelo",
    "description": "¬øQu√© tan viable es el uso de los modelos?",
    "author": [
      {
        "name": "Eduardo Selim M. M.",
        "url": {}
      },
      {
        "name": "Carlos A. Ar.",
        "url": {}
      }
    ],
    "date": "2021-05-20",
    "categories": [
      "regresion",
      "diagnostico"
    ],
    "contents": "\r\n\r\nContents\r\nResiduales estandarizados y studentizados\r\nIdentificaci√≥n de outliers\r\nDetecci√≥n de relaciones no-lineales omitidas\r\nPuntos de influencia\r\nLeverage\r\nDistancia de Cook\r\n\r\n\r\nRaw-residual: \\(e_i = y_i - \\hat{y}_i\\) idealmente, √©ste aproxima a \\(\\epsilon_i\\) (no observable). Refleja la cantidad de variaci√≥n que est√° a√∫n presente a√∫n en el conocimiento de las variables explicativas.\r\nSi el modelo se ajusta adecuadamente, los residuales deben ser structure-less.\r\nSi \\(|e_i|\\) es ‚Äúgrande‚Äù no hay un buen ajuste de modelo\r\n\\[\r\n|e_i|\\text{ grande } \\rightarrow \\text{Mal ajuste del modelo}\\\\\r\n\\text{¬øQu√© tan grandes?}\r\n\\]\r\nPara todo \\(i \\in \\{1, ..., n\\}\\)\r\n\\[\r\nVar(\\epsilon_i) = \\sigma ^ 2\\\\\r\nVar(e_i) = \\sigma ^ 2(1-h_{ii})\r\n\\]\r\nSe puede ver esto de forma matricial\r\n\\[\r\ne = y -\\hat{y} = y - \\mathbb{X}\\hat{\\beta} = y - \\underbrace{[\\mathbb{X}(\\mathbb{X}^T\\mathbb{X})^{-1}\\mathbb{X}^T]}_{\\mathbb{H}}y\\\\\r\n= y - \\mathbb{H}y\\\\\r\n=\\underbrace{(I-\\mathbb{H})}_{\\text{sim√©trica e idempotente}}y\r\n\\]\r\n\r\n\\(\\mathbb{H} = \\mathbb{X}(\\mathbb{X}^T\\mathbb{X})^{-1}\\mathbb{X}^T \\rightarrow\\) matriz sombrero.\r\n\\(Var(e) = (I - \\mathbb{H})\\sigma ^2 I (I-\\mathbb{H})^T = \\sigma^2(I-\\mathbb{H})(I-\\mathbb{H})^T\\)\r\n\\(Var(e_i) = \\sigma^2(1-\\underbrace{h_{ii}}_{\\text{leverage}}) \\rightarrow\\) Leverage grande \\(\\Rightarrow\\) Varianza baja.\r\nA \\(h_{ii}\\) se le conoce como leverage para la observaci√≥n \\(i\\).\r\nComo \\(\\sigma^2\\) es desconocido, se puede estimar a partir del MSE \\(\\sigma^2\\)\r\n\\[\r\n\\hat{Var}(e_i) = S^2(1-h_{ii}), i = 1, 2, ..., n\r\n\\]\r\nResiduales estandarizados y studentizados\r\nLos raw-residuals no son comparables entre s√≠ y no es f√°cil interpretarlos directamente.\r\nResiduales estandarizados\r\n\\[\r\ne^{st}_{i} := \\frac{e_i}{\\sqrt{S^2(1-h_{ii})}}\r\n\\]\r\nSi el modelo de regresi√≥n es correcto, los \\(e^{st}_{i}¬¥^s\\) tienen aproximadamente la misma varianza (esto los hace comparables) y aproximadamente tienen distribuci√≥n normal/gaussiana est√°ndar.\r\n\\[\r\ne^{st}_{i} \\dot{\\backsim} N(0,1)\r\n\\]\r\n\r\nResiduales studendizados\r\n\\[\r\ne^{stud}_{i} := \\frac{e_i}{\\sqrt{S_{(i)}^2(1-h_{ii})}}\r\n\\]\r\ndonde \\(S_{(i)}^2\\) es el MSE del modelo de regresi√≥n con la i-√©sima observaci√≥n excluida\r\n\\[\r\ne^{stud}_{i} \\backsim t_{n-(k+1)} \\text{ (exacto)}\r\n\\]\r\nEl uso de \\(S^2_{(i)}\\) quita el efecto de la i-√©sima observaci√≥n; de esta forma la i-√©sima observaci√≥n afecta al numerador de \\(e_i^{stud}\\) no su denominador.\r\nIdentificaci√≥n de outliers\r\n\\(\\hat{y}_i\\) es extremo si\r\n\\[\r\n|e^{st}_i| = \r\n\\begin{cases}\r\n\\geq2, \\text{ Frees}\\\\\r\n\\geq 3, \\text{ James estad} \r\n\\end{cases}\r\n\\]\r\n¬øQu√© hacer con outliers?\r\nBorrarlo\r\n\r\nConservarlo pero comentarlo\r\n\r\nHacer el modelo con y sin el outlier\r\n\r\n\r\nDetecci√≥n de relaciones no-lineales omitidas\r\nSi el modelo de regresi√≥n se especific√≥ adecuadamente, los residuales no deben mostrar patrones regulares.\r\nSe puede graficar \\(e\\) (vertical) v.s. alg√∫n predictor \\(x_j\\)\r\nSi hay patr√≥n sistem√°tico es indicacci√≥n de que se requiere usar informaci√≥n adicional para mejorar el modelo.\r\n\r\nEjemplo\r\nEn un SLR \\(y = \\beta_0 + \\beta_1x + \\epsilon\\) la gr√°fica \\(e\\) v.s. \\(x\\) muestra forma de \\(U\\) sugiere que los residuales son cuadr√°ticos en \\(x\\). Es decir\r\n\\[y -\\beta_0 - \\beta_1 \\thickapprox e \\thickapprox \\underbrace{\\gamma_0 + \\gamma_1 x +\\gamma_2x^2}_{\\text{patr√≥n cuadr√°tico}} \\\\\r\n\\Rightarrow y \\thickapprox (\\beta_0 + \\gamma_0) + (\\beta_1+\\gamma_1)x + \\gamma_2x^2\\\\\r\n\\text{que es un modelo de regresi√≥n cuadr√°tico}\\]\r\nPuntos de influencia\r\nDefinici√≥n. Se dice que una observaci√≥n muestral es un punto de influencia si su exclusi√≥n del an√°lisis de regresi√≥n lleva a conclusiones diferentes a aquellas a las que se lleg√≥ en su presencia.\r\nSe estudiar√°n 2 m√©todos para evaluar la influencia de cada observaci√≥n sobre los resultados del modelo global.\r\nLeverage\r\n\r\nDistancia de Cook\r\n\r\n\r\nEl vector de LSE‚Äôs es \\(\\hat{\\beta} = (\\mathbb{X}^T\\mathbb{X})^{-1} \\mathbb{X}\\mathbb{Y}\\)\r\n\\[\r\n\\hat{\\mathbb{Y}} = \\mathbb{X}\\hat{\\mathbb{\\beta}} =\\mathbb{X}[(\\mathbb{X}^T\\mathbb{X})^{-1}\\mathbb{X}^T\\mathbb{Y}] = \\mathbb{H}\\mathbb{Y}\\\\\r\n\\mathbb{H} = \\mathbb{X}(\\mathbb{X}^T\\mathbb{X})^{-1}\\mathbb{X}^T \\rightarrow \\text{ matr√≠z sombrero}\\\\\r\n\\hat{\\mathbb{Y}} = \\mathbb{H}\\mathbb{Y} \\text{ \"Se multiplica a } \\mathbb{Y} \\text{ por } \\mathbb{H} \\text{ para llegar a } \\hat{\\mathbb{Y}}\r\n\\]\r\n\r\nLeverage\r\n\\(h_{ii}\\) : Leverage de la i-√©sima observaci√≥n. Representa el ‚Äúleverage‚Äù (pero √≥ ponderaci√≥n) que el i-√©simo valor respuesta ejerce sobre su propio valor ajustado.\r\nMientras m√°s grande es \\(h_{ii}\\), mayor es la influencia que \\(y_i\\) ejerce sobre \\(\\hat{y}_i\\).\r\n\\(Var(e_i) = \\sigma^2(1-h_{ii})\\). Mientras m√°s grande sea \\(h_{ii}\\), m{as peque√±o ser√° el valor de \\(Var(e_i)\\) y \\(\\hat{y}_i\\) tender√° a ser \\(y_i\\)\r\nSi \\(h_{ii} = 1\\), \\(\\hat{y}_i\\) estar√° forzado a ser \\(y_i\\)\r\n\r\n\\(h_{ii}\\) se obtiene de \\(\\mathbb{H} = \\mathbb{X}(\\mathbb{X}^T\\mathbb{X})^{-1}\\mathbb{X}^T\\) i.e.¬†s√≥lo usa a las variables explicativas, no a las variables respuesta.\r\nEl leverage es una medida de la influencia de una observaci√≥n sobre el modelo solamente en t√©rminos de sus variables explicativas.\r\n\r\nSe puede demostrar que\r\n\\[\r\nh_{ii} \\in \\bigg[\\frac{1}{n}, 1\\bigg]\\\\\r\n\\sum_{i = 1}^{n} h_{ii} = k+1 \\text{, } k \\text{ es el n√∫mero de variables explicativas.}\\\\\r\n\\\\\r\n\\text{El laverage promedio es } \\bar{h} = \\frac{k+1}{n}\r\n\\]\r\nRegla de dedo de Frees\r\nUna observaci√≥n tiene un leverage alto si\r\n\\[\r\nh_{ii} > 3\\bar{h} = \\frac{3(k+1)}{n}\\\\\r\n\\text{Laverage para SLR : } y = \\beta_0 + \\beta_1 x + \\epsilon\\\\\r\nh_{ii} = \\frac{1}{n} + \\frac{(x_i - \\bar{x})^2}{S_{xx}}\\\\\r\n\\text{\"miestras m√°s lejos est√© } x_i \\text{ de } \\bar{x} \\text{,  m√°s grande ser√° el leverage } h_{ii} \\text{\"}\r\n\\]\r\nTanto para SLR y MLR, el leverage es una medida de lejan√≠a (remoteness) de una observaci√≥n de las observaciones restantes, en el espacio de las variables explicativas.\r\nEl leverage es un reflejo de la influencia de la observaci√≥n, pues proporciona una ‚Äúposible raz√≥n‚Äù para que una observaci√≥n sea de influencia: √©sta involucra variables an√≥malas de las variables explicativas (est√° ‚Äúlejana‚Äù del resto de las variables explicativas).\r\nImportante\r\nUna observaci√≥n con leverage alto no necesariamente es de influencia.\r\n‚ÄúUn punto de leverage alto puee o no ser de influencia‚Äù\r\n\r\nLos puntos A y B tienen leverage alto pues est√°n lejos del resto de las observaciones\r\nPero s√≥lo el punto A es de influencia pues las rectas de regresi√≥n con el punto A y sin el punto A, ser√°n muy diferentes.\r\nDistancia de Cook\r\nUna sugerencia para que un punto sea de influencia es que no s√≥lo sea outstanding en los valores de \\(x\\) si no tambi√©n en los de \\(y\\).\r\nLa distancia de cook es una medida que combina ambas dimensiones.\r\nUna manera directa de evaluar la influencia de las observaciones individuales es estudiar los cambios en la varibale respuesta ajustada si se elimina dicha observaci√≥n.\r\nSup√≥ngase que se elimina la i-√©sima observaci√≥n y se ajusta un modelo de regresi√≥n con las \\(n-1\\) observaciones restantes.\r\n\\[\r\n\\hat{y}_{j(i)}: \\text{ valor ajustado de } \\hat{y} \\text{ calculado en ausencia de la observaci√≥n } i\r\n\\]\r\nMientras m√°s grande sea \\(\\hat{y}_j - \\hat{y}_{j(i)}\\), m√°s influencial ser√° la observaci√≥n \\(i\\)\r\nDistancia de cook\r\n\\[\r\nD_i = \\displaystyle \\frac{\\sum_{j=1}^n (\\hat{y}_j - \\hat{y}_{j(i)})^2}{(k+1)S^2}\r\n\\]\r\nDonde \\(S^2\\) es el MSE calculado con el data-set completo\r\n\\(D_i \\dot{\\backsim}F\\) (que sirve para probar valores grandes o peque√±os de \\(D_i\\))\r\nFrees sugiere que \\(D_i > \\frac{1}{n}\\) significa que la observaci√≥n \\(i\\) es de influencia.\r\nLa definici√≥n de la distancia de cook requiere que se ajuste una regresi√≥n en \\((n+1)\\) data-sets:\r\n1 en el data-set completo (para obtener \\(S^2\\))\r\n\\(n\\) para cada uno de lo data-sets que excluye a la observaci√≥n \\(i\\), para calcular los \\(\\hat{y}_{j(i)}'^s\\).\r\n\r\nHay una f√≥rmula algebraicamente equivalente pero computacionalmente m√°s eficiente.\r\n\\[\r\nD_i = \\frac{1}{k+1}(e_i^{st})^2\\frac{h_{ii}}{1-h_{ii}}\r\n\\] solo requiere realizar una regresi√≥n sobre todos los datos.\r\nEn esta expresi√≥n es evidente el impacto de la respuesta \\(y_i\\) (a trav√©s de \\(e_{i}^{st}\\)) y de las covariables \\(x\\) (a trav√©s de \\(h_{ii}\\)).\r\nPara que la distancia de Cook sea grande tiene que ocurrir tanto que \\(e_{i}^{st}\\) sea grande, as√≠ como \\(h_{ii}\\), i.e.¬†la observaci√≥n es outstanding con respecto a los valores de \\(x\\) y los valores de \\(y\\).\r\n\r\n\r\n\r\n",
    "preview": "posts/2021-05-20-diagnstico-de-modelos/images/d_m_1.png",
    "last_modified": "2021-06-05T21:55:39-05:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-05-15-construccin-del-modelo-de-regresin/",
    "title": "Construcci√≥n del modelo de regresi√≥n",
    "description": "Veremos el modelo de regresi√≥n",
    "author": [
      {
        "name": "Eduardo Selim M. M.",
        "url": {}
      },
      {
        "name": "Carlos A. Ar.",
        "url": {}
      }
    ],
    "date": "2021-05-12",
    "categories": [
      "regresion"
    ],
    "contents": "\r\n\r\nContents\r\nTipos de variables explicativas\r\n¬øQu√© pasa con variables categ√≥ricas?\r\n\r\nInteracci√≥n\r\nInteracci√≥n entre las variables explicativas continuas y categ√≥ricas\r\nModelos de regresi√≥n lineal picewise\r\nModelo 1.\r\nModelo 2\r\n\r\n\r\nEl MLR proporciona mayor flexibilidad para describir la relaci√≥n entre la respuesta y las variables explicativas.\r\nEl reto ahora es c√≥mo representar diversos predictores (variables explicativas / covariables) de manera adecuada. (este ‚Äúproblema‚Äù no se presentaba en SLR)\r\nTipos de variables explicativas\r\nnum√©ricas\r\ncateg√≥ricas\r\nLa manera m√°s sencilla de representar en un modelo de regresi√≥n a una variable num√©rica es asignar un coeficiente de regresi√≥n a esta variable, i.e.\r\n\\[\r\ny = \\beta_0 + \\beta_1x + \\text{ t√©rminos que no involucran a } x + \\epsilon\r\n\\]\r\nEn esta especificaci√≥n, en una unidad de incremento en \\(x\\) se espera un incremento en \\(y\\) de \\(\\beta_1\\) unidades.\r\n\\[\r\ny = \\beta_0 + \\beta_1(x+1) + \\text{ t√©rminos que no involucran a } x + \\epsilon\r\n\\]\r\nSin embargo, hay situaciones en las que la relaci√≥n entre \\(x\\) y \\(y\\) no parece ser lineal. Entonces, podr√≠a ser deseable ‚Äúexpedir‚Äù la funci√≥n de regresi√≥n con potencias de \\(x\\), llevando a una especificaci√≥n que se conoce como regresi√≥n polinomial.\r\n\\[\r\ny = \\beta_0 + \\beta_1x + \\beta_2x^2 + ... + \\beta_mx^m + \\text{ t√©rminos que no involucran a } x + \\epsilon\r\n\\]\r\nPara alg√∫n \\(m \\in \\mathbb{N}_+\\)\r\nEn el modelo de regresi√≥n polinomialm no hay linealidad en \\(x\\) sino en los primeros par√°metros \\(\\beta_j'^s\\), por eso se considera un modelo lineal.\r\nUna pregunta que surge naturalmente es c√≥mo determinar el grado del polinomio, i.e.¬†c√≥mo determinar \\(m\\). Lo estudiaremos m√°s adelante mediante algunos m√©todos de selecci√≥n de modelos.\r\n¬øQu√© pasa con variables categ√≥ricas?\r\nHay que representarlas de manera cuantitativa, una manera de hacer esto es la siguiente\r\nPara una variable categ√≥rica con \\(r\\) niveles i.e.¬†con \\(r\\) categor√≠as (\\(r\\geq 2\\))m se necesita introducir \\(r-1\\) variables indicadoras: \\(x_1, x_2, ..., x_{r-1}\\) donde a cada una se le asigna un coeficiente de regresi√≥n (por separado), donde\r\n\\[\r\nx_i = \\begin{cases}\r\n1, \\text{si la categor√≠a es } i,\\\\\r\n0, \\text{ c.o.c.}\r\n\\end{cases}\r\n\\]\r\nEjemplo:\r\n$$ x_{} {}\\\r\nx_1 =\r\n\\[\\begin{cases}\r\n1, \\text{si } x_{\\text{cat}} \\text{ es perro},\\\\\r\n0, \\text{ c.o.c.}\r\n\\end{cases}\\]\r\n\\\r\nx_2 =\r\n\\[\\begin{cases}\r\n1, \\text{si } x_{\\text{cat}} \\text{ es caballo},\\\\\r\n0, \\text{ c.o.c.}\r\n\\end{cases}\\]\r\n$$\r\n\r\nEl √∫ltimo rengl√≥n se conoce como nivel base\r\nNivel de la variable categ√≥rica\r\n\\[\r\nx_1\r\n\\]\r\n\\[\r\nx_2\r\n\\]\r\n\\[\r\n...\r\n\\]\r\n\\[\r\nx_{r-1}\r\n\\]\r\n\\[\r\n1\r\n\\]\r\n1\r\n0\r\n\\[\r\n...\r\n\\]\r\n0\r\n\\[2\\]\r\n0\r\n1\r\n\\[\r\n...\r\n\\]\r\n0\r\n\\[\r\n...\r\n\\]\r\n\r\n\r\n\r\n\r\n\\[\r\nr-1\r\n\\]\r\n0\r\n0\r\n\\[\r\n...\r\n\\]\r\n1\r\n\\[\r\nr\r\n\\]\r\n0\r\n0\r\n\\[\r\n...\r\n\\]\r\n0\r\nEjmplo:\r\nSi \\(x = \\begin{cases} 1, \\text{ para fumadores}\\\\ 0, \\text{ para no fumadores} \\end{cases}\\) Si el estatus de consumo de tabaco es la √∫nica variable explicativa, la ecuaci√≥n del modelo de regresi√≥n es:\r\n\\[\r\n\\mathbb{E}(y) = \\beta_0 +\\beta_1x = \\begin{cases} \r\n\\beta_0 +\\beta_1, \\text{ para fumadores}\\\\\r\n\\beta_0, \\text{ para no fumadores} \\end{cases}\r\n\\]\r\nObservaci√≥n: no es necesario definir una variable indicadora \\(x' = \\begin{cases} 1, \\text{ para fumadores}\\\\ 0, \\text{ para no fumadores} \\end{cases}\\) para indicar a los no-fumadores. Si se definiera dicha variable que \\(x+x'=1\\). Dicha relaci√≥n lineal perfecta entre \\(x\\) y \\(x'\\) desestabilizar√° el proceso de estimaci√≥n, esto se conoce como colinealidad y se estudiar√° m√°s adelante.\r\nEl nivel que se excluye en la descomposici√≥n en variables indicadoras se comoce como nivel baseline √≥ nivel de referencia.\r\nSe se escoge a ‚Äúno-fumador‚Äù como baseline, el coeficiente \\(\\beta_0\\) se puede interpretar como el valor de \\(\\mathbb{E}(y)\\) cuando la observaci√≥n es ‚Äúno-fumador‚Äù y \\(\\beta_1\\) captura la diferencia promedio en \\(\\mathbb{E}(y)\\) entre un fumador y un no-fumador.\r\nEsta codificaci√≥n del estatus de fumador no es la √∫nica. Se puede asignar a ‚Äúfumador‚Äù como un nivel baseline √≥ utilizar una codificaci√≥n \\(-1/1\\). Bajo diferentes codificaciones sus estimaciones parametrales y sus interpretaciones difierir√°n, aunque las predicciones ser√°n las mismas.\r\nSi el nivel baseline es ‚Äúfumadores‚Äù \\(x' = \\begin{cases} 0, \\text{ para fumadores}\\\\ 1, \\text{ para no fumadores} \\end{cases}\\) , la ecuaci√≥n del modelo se convierte en:\r\n\\[\r\n\\mathbb{E}(y) = \\alpha_0 + \\alpha_1x = \\begin{cases} \\alpha_0, \\text{ para fumadores}\\\\ \\alpha_0 +\\alpha_1, \\text{ para no fumadores} \\end{cases}\r\n\\]\r\nEn este caso, \\(\\alpha_0\\) es el valor esperado de la respuesta para fumadores y \\(\\alpha_1\\) representa el incremento en \\(\\mathbb{E}(y)\\) para un no fumador, comparado con un fumador.\r\nPara relacionar la estimaci√≥n de par√°metros en ambas codificaciones se usa el hecho de que \\(x' = 1-x\\), entonces\r\n\\[\r\n\\mathbb{E}(y) = \\alpha_0 + \\alpha_1x' = \\alpha_0 + \\alpha_1(1-x)\\\\\r\n=\\underbrace{(\\alpha_0 + \\alpha_1)}_{\\beta_0} + \\underbrace{(-\\alpha_1)}_{\\beta_1} x\r\n\\]\r\nDe aqu√≠ que \\(\\hat{\\beta_0} = \\hat{\\alpha_0} + \\hat{\\alpha_1}\\) y \\(\\hat{\\beta_1} = -\\hat{\\alpha_1}\\)\r\nSin importar si la codificaci√≥n es \\(0/1\\) √≥ \\(1/0\\), las predicciones son las mismas:\r\n\\[\r\n\\bar{y} = \\underbrace{\\hat{\\beta_0} + \\hat{\\beta_1} \\cdot 1}_{\\text{valor ajustado}\\\\ \\text{bajo codificaci√≥n 1/0}} = (\\hat{\\alpha}_0 + \\hat{\\alpha_1}) -  \\hat{\\alpha_1} = \\hat{\\alpha}_0 = \\underbrace{\\hat{\\alpha_0} + \\hat{\\alpha_1} \\cdot 0}_{\\text{valor ajustado}\\\\ \\text{bajo codificaci√≥n 0/1}} \\\\\r\n\\bar{y} = \\underbrace{\\hat{\\beta_0} + \\hat{\\beta_1} \\cdot 0}_{\\text{valor ajustado}\\\\ \\text{bajo codificaci√≥n 1/0}}= \\hat{\\beta}_0 = \\hat{\\alpha}_0 + \\hat{\\alpha_1}  = \\underbrace{\\hat{\\alpha_0} + \\hat{\\alpha_1} \\cdot 1}_{\\text{valor ajustado}\\\\ \\text{bajo codificaci√≥n 0/1}}\\\\\r\n\\therefore \\text{Las preicciones son las mismas}\r\n\\]\r\n\r\nSi se usa la codificaci√≥n 1/-1 (en vez de 1/0 √≥ 0/1) entonces\r\n\\[\r\nx^n = \\begin{cases} 1 \\text{ para fumadores,}\\\\ -1 \\text{ para no fumadores}\\\\ \\end{cases}\r\n\\]\r\nLa ecuaci√≥n del modelo se convierte en\r\n\\[\r\n\\mathbb{E}(y) = \\gamma_0 + \\gamma_1x'' = \\begin{cases} \\gamma_0 + \\gamma_1 \\text{ para fumadores,} \\\\ \\gamma_0 - \\gamma_1 \\text{ para no fumadores}\\end{cases}\r\n\\]\r\nEsta codificaci√≥n 1/-1 tiene la ‚Äúventaja‚Äù de hacer al intercepto \\(\\gamma_0\\) el ‚Äúpromedio global‚Äù de \\(y\\) para todos los individuos ognorando el efecto de fumado/no-fumador. Adem√°s \\(\\gamma_1\\) es la cantidad que los fumadores tienen adicional al promedio y \\(\\gamma_1\\) tambi√©n es la cantidad que los no-fumadores tienen faltante al promedio.\r\nDesde el punto de vista computacional, es conveniente seleccionar al nivel m√°s com√∫n (la de mayor frecuencia) como el nivel baseline.\r\nEsto se debe a que se tendr√° muvhos \\(0'^s\\) en la matr√≠z de dise√±o y ser√° m√°s f√°cil calcular \\((\\mathbb{X}^T\\mathbb{X})^{-1}\\)\r\n\r\nInteracci√≥n\r\nHasta el momento, s√≥lo se han considerado modelos en los que la relaci√≥n entre la respuesta y la variable explicativas es aditiva.\r\n\\[\r\n\\mathbb{E}(y) = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2\r\n\\]\r\nSin embargo, tambi√©n podemos hacer una especificaci√≥n de la forma.\r\n\\[\r\n\\mathbb{E}(y) = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 +\\beta_3 x_3\r\n\\]\r\nAqu√≠ \\(x_3 := x_1 x_2\\) se conoce como variable de interacci√≥n y se le trata como una variable explicativa adicional con un coeficiente de regresi√≥n por separado \\(\\beta_3\\)\r\nObs√©rvese que, incrementar una unidad en x_1\r\n\\[\r\n\\beta_0 + \\beta_1(x_1+1) + \\beta_2x_2 +\\beta_3(x_1+1)x_2\\\\\r\n= \\beta_0 + \\beta_1x_1+\\beta_1 + \\beta_2x_2 +\\beta_3x_1+\\beta_3x_2\\\\\r\n=\\beta_0 + \\beta_1x_1 + \\beta_2x_2 +\\beta_3x_1+(\\beta_3x_2 +\\beta_1)\r\n\\]\r\nEquivalentemente\r\n\\[\r\n\\frac{d}{dx_1}\\mathbb{E}(y) = \\frac{d}{dx_1} (\\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 +\\beta_3 x_1x_2) = \\beta_1 +\\beta_3x_2\r\n\\]\r\nEs decir, el incremento es una unidad en \\(x_1\\) incrementar√° a \\(\\mathbb{E}(y)\\) en \\(\\beta_1 +\\beta_3x_2\\) (que depende de \\(x_2\\))\r\nPor lo tanto, el impacto de cada \\(x\\) var√≠a con en valor tomado por la otra variable explicativa y se dice que \\(x_1\\) y \\(x_2\\) interact√∫an entre s√≠ para afectar \\(\\mathbb{E}(y)\\).\r\n\r\nInteracci√≥n entre las variables explicativas continuas y categ√≥ricas\r\nLa interacci√≥n entre una variable categ√≥rica y una continua tiene una interpretaci√≥n geom√©trica muy importante, que no se puede dar s√≥lo con variables continuas.\r\nConsid√©rese un modelo MLR con una variable explicativa continua \\(x_1\\), una variable binaria \\(x_2\\) y una \\(x_1 x_2\\). La ecuaci√≥n del modelo es:\r\n\\[\r\n\\mathbb{E}(y) = \\beta_0 + \\beta_1x_1+\\beta_2x_2+\\beta_3x_1x_2\\\\\r\n= \\begin{cases} \r\n\\beta_0 +\\beta_1x_1, \\text{ si }x_2 = 0\\\\\r\n(\\beta_0 + \\beta_2) + (\\beta_1 + \\beta_3)x_1, \\text{ si }x_2 = 1\r\n\\end{cases}\r\n\\]\r\nSe puede ver a √©ste como dos modelos SLR por separado: una para \\(x_2=0\\) y otro para \\(x_2=1\\).\r\nObs√©rvese que ambos modelos tienen diferentes interceptos y diferentes pendientes.\r\n\r\n¬øQu√© pasa si \\(\\beta_3 = 0\\)? Es decir, si no hay interacci√≥n. La ecuaci√≥n de modelo se convierte en:\r\n\r\nPara el grupo baeline (i.e.¬†\\(x_2 = 0\\)). El incremento en una unidad es \\(x_1\\) incremento a \\(\\mathbb{E}(y)\\) a \\(\\beta_1\\)\r\nPara el grupo \\(x_2 = 1\\). El incremento es una unidad en \\(x_1\\) incrementa a \\(\\mathbb{E}(y)\\) en \\(\\beta_1 + \\beta_3\\)\r\n\r\nSi \\(\\beta_3 \\neq 0\\), el efecto de \\(x_1\\) sobre \\(y\\) difiere de acuerdo a si \\(x_2 = 0\\) √≥ \\(x_2 = 1\\) ‚Ä¶ una manifestaci√≥n de la interacci√≥n.\r\nSi \\(\\beta_3 = 0\\), la interacci√≥n desaparece y simplemente se est√°n ajustando 2 rectas paralelas (con diferentes interceptos) a los datos.\r\nEn \\(\\mathbb{E}(y) = \\beta_0 + \\beta_1x_1 +\\beta_2x_2 + \\beta_3x_1x_2\\) es poco com√∫n que\r\n\\[\r\n\\underbrace{\\beta_3 \\neq 0}_{\\text{evidenciado por una estad√≠stica grande √≥ un p-value peque√±o.}} \\text{ y } \\underbrace{\\beta_1 = \\beta_2 = 0}_{\\text{con la comesp prueba estad√≠stica}}\r\n\\]\r\nEs decir, el efecto puede ser real pero el de \\(x_1\\) y \\(x_2\\) se insignificante. En este caso se apela a lo que se conoce como ‚Äúprincipio jer√°rquico‚Äù y se incluye no s√≥lo \\(\\beta_3\\) sino tambi√©n \\(\\beta_1\\) y \\(\\beta_2\\) para facilitar la interpretaci√≥n.\r\nModelos de regresi√≥n lineal picewise\r\nEn ciertas aplicaciones puede ser deseable que la variable respuesta muestre cambios abiertos en el comportamiento sobre diferentes intervalos de la variable explicativa (que se conoce como ‚Äúrompimiento estructural‚Äù).\r\nEn el caso en el que una variable explicativa es categ√≥rica ya se explic√≥ (un quiebre por cada nievel). Esto tambi√©n se puede estudiar como una variable explicativa continua.\r\nModelo 1.\r\nConsid√©rese un modelo de variable explicativa \\(x\\).\r\nSea \\(z = 1_{\\{x\\geq c\\}}\\) para alg√∫n \\(c \\in \\mathbb{R}\\).\r\nConsid√©rese la funci√≥n de regresi√≥n:\r\n\\[\r\n\\mathbb{E}(y) = \\beta_0 + \\beta_1x + \\beta_2 z(x-c)\\\\\r\n= \\beta_0 + \\beta_1x + \\beta_2 (x-c)_+ \\text{ donde } u_+ := \\max\\{u ,0\\}\\\\\r\n=\\begin{cases} \r\n\\beta_0 + \\beta_1x \\text{ si } x<c, \\\\\r\n(\\beta_0 -\\beta_2c) + (\\beta_1 +\\beta_2)x \\text{ si } x\\geq c\r\n\\end{cases}\r\n\\]\r\nLa pendiente de la funci√≥n de regresi√≥n cambia abruptamente de \\(\\beta_1\\) a \\(\\beta_1+\\beta_2\\) en \\(x=c\\)\r\nDicho modelo se puede ver como un modelo MLR con dos variables explicativas \\(x\\) y \\((x-c)_+\\) y la inferencia se lleva a cabo como se hace normalmente.\r\nCon este modelo se obtiene una sola funci√≥n de regresi√≥n formada por 2 rectas conectadas continuamente en \\(x = c\\) (que se conoce como kink [torcedura]). Por esta raz√≥n, a este modelo se le conoce como modelo de regresi√≥n lineal pice wise.\r\n\r\nModelo 2\r\nLa funci√≥n de regresi√≥n en un modelo de regresi√≥n lineal picewise no necesita ser continua.\r\nUna funci√≥n de regresi√≥n con saltos resultar√° de ‚Äúinteractuar‚Äù una variable explicativa continua \\(x\\) con la variable dummy \\(z = 1_{\\{x > c\\}}\\)\r\nLa funci√≥n de regresi√≥n es:\r\n\\[\r\n\\mathbb{E}(y) = \\beta_0 + \\beta_1x + \\beta_2 z + \\beta_3zx\\\\\r\n=\\begin{cases} \r\n\\beta_0 + \\beta_1x \\text{ si }z = 0 \\iff x<c, \\\\\r\n(\\beta_0 +\\beta_2c) + (\\beta_1 +\\beta_3)x \\text{ si } z =1 \\iff x\\geq c\r\n\\end{cases}\r\n\\]\r\nQue consiste en dos l√≠neas rectas que generalmente no se conectan, divididas en \\(x = c\\).\r\n\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2021-05-19T23:31:38-05:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-05-14-clustering/",
    "title": "Clustering",
    "description": ".",
    "author": [
      {
        "name": "Eduardo Selim M. M.",
        "url": {}
      },
      {
        "name": "Carlos A. Ar.",
        "url": {}
      }
    ],
    "date": "2021-05-11",
    "categories": [
      "clustering"
    ],
    "contents": "\r\n\r\nContents\r\nDefiniciones generales\r\nClustering por k medias\r\nAlgor√≠tmo: cl√∫stering por k-medias\r\n\r\nCl√∫stering jer√°rquico\r\n\r\nDefiniciones generales\r\nUn m√©todo de clustering se utiliza para agrupar un data-set heterog√©neo en subgrupos homog√©neos que se conocen como clusters. Estrategia no supervisada, es decir, no hay variable respuesta \\(y\\).\r\nRevisaremos\r\nClustering por k-medias\r\nCluestering jer√°rquico\r\n\r\nSe considera\r\nSi se conoce a priori el npumero de sibgrupos, se usa k-medias.\r\nSi no se conoce a priori el n√∫mero de subgrupos, se usa clustering jer√°rquico.\r\n\r\nUn cluster es un grupo de observaciones que son ‚Äúmuy similares‚Äù y tienen varias caracter√≠sticas en com√∫n.\r\nEntonces se quiere cuantificar la noci√≥n de ‚Äúmuy similar‚Äù\r\n\r\nLa cercan√≠a de las observaciones est√° determinada por una distancia.\r\nEn principio, la distancia Euclidiana\r\nPero pueden haber otras metricas\r\n\r\nClustering por k medias\r\nSe quiere agrupar al data-set como \\(\\textbf{k}\\) cl√∫sters disjuntos.\r\nLos datos iniciales son \\(n\\) y est√°n enumerados de 1 a \\(n\\).\r\nLas etiquetas de las observaciones se guardan en \\(C = \\{1,2,...,n\\}\\)\r\n\r\nCon clustering por k-medias se quiere determinar cl√∫sters \\(C_1, C_2, ..., C_k\\)\r\nLas etiquetas en \\(C_i\\) son observaciones que pertenecen al cl√∫ster \\(i\\).\r\nCada observaci√≥n ser√° asignada a un y s√≥lo un cl√∫ster.\r\n\\(C = C_1 \\cup C_2 \\cup ... \\cup C_k\\)\r\nSi \\(i \\neq j\\), entonces \\(C_i \\cap C_j = \\emptyset\\)\r\n\r\nCon clustering por k-medias, se quiere encontrar cl√∫sters \\(C_1,C_2,...,C_k\\) talqes que la variaci√≥n dentro de cada cl√∫ster ser√° lo m√°s peque√±a posible.\r\nMientras m√°s peque√±a sea la variaci√≥n within-cluster, mejor serpa el m√©todo de clustering. üòä\r\nLa variaci√≥n dentro de un cl√∫ster se mide usando una fucni√≥n \\(W(\\cdot)\\)\r\n\\(W(C_j)\\): Variaci√≥n entre las observaciones en el cl√∫ster \\(j\\).\r\n\r\nLa variaci√≥n total est√° dada por\r\n\\[\r\n\\text{Variaci√≥n total } = \\sum_{j = 1}^{k} W(C_j)\r\n\\]\r\nEl clustering por k-medias determinan qu√© cl√∫sters \\(C_1, ..., C_k\\) minimizan la variaci√≥n total\r\n\\[\r\n\\min_{C_1, ..., C_k}\\sum_{j=1}^{k}W(C_j)\r\n\\]\r\nUna forma com√∫n de definir \\(W(\\cdot)\\) es como la distancia Euclidiana entre las observaciones.\r\nSup√≥ngase que las observaciones \\(\\underline{x}_i, \\underline{x}_{i'}\\) est√°n en el k-√©simo cl√∫ster\r\nEsto significa que \\(i, i' \\in C_k\\)\r\n\\[\r\n\\text{Distancia al cuadrado entre } i \\text{ y } i' \\\\\r\n=\\sum_{j=1}^{p}(x_{ij} - x_{i'j})^2\r\n\\]\r\n\r\n\\(W(C_k)\\): Distancia al cuadrado promedio entre las observaciones en el cl√∫ster \\(k\\)\r\n\\[\r\nW(C_k) = \\frac{1}{|C_k|}\\sum_{i,i' \\in C_k} \\sum_{j=1}^{p}(x_{ij} - x_{i'j})^2\r\n\\]\r\nLos cl√∫sters \\(C_1, ..., C_k\\) se obtienen de tal forma que\r\n\\[\r\n\\min_{C_1, ..., C_k}\\bigg\\{ \\sum_{k=1}^K \\frac{1}{|C_k|}\\sum_{i,i' \\in C_k} \\sum_{j=1}^{p}(x_{ij} - x_{i'j})^2 \\bigg\\}\r\n\\]\r\nAlgor√≠tmo: cl√∫stering por k-medias\r\nPaso preliminar, asignar aleatoriamente cada observaci√≥n a un cl√∫ster.\r\nIteraci√≥n. Repetir los siguientes pasos hasta que la asignaci√≥n del cl√∫ster no cambie entre 2 pasos consecutivos:\r\nDeterminar el centroide \\(\\bar{x}_k\\) para cada cl√∫ster \\(C_k\\) para cada \\(k = 1, 2, ..., K\\)\r\n\\[\r\n\\bar{x}_k := (\\bar{x}_{k1}, \\bar{x}_{k2},...,\\bar{x}_{kp})\r\n\\]\r\n(el promedio en el cl√∫ster por cada variable), donde:\r\n\\[\r\n\\bar{x}_{kj} = \\frac{1}{|C_k|}\\sum_{i \\in C_k} x_{ij}, \\space \\space j =1,2, ...,p\r\n\\]\r\nAsignar a cada observaci√≥n al cl√∫ster del centroide m√°s cercano. De hecho, una observaci√≥n \\(\\underline{x}_i\\) pertenece al cl√∫ster \\(k\\).\r\n\\[\r\n\\sum_{j=1}^p(x_{ij}-\\bar{x}_{k'j})^2 \\leq \\sum_{j=1}^p(x_{ij}-\\bar{x}_{k'j}) \\text{  para cada cl√∫ster } k'\r\n\\]\r\nEl algor√≠tmo minimiza la distancia de las observaciones a los centroides. Sin embargo, el problema de optimizaci√≥n establece minimizar la distancia entre las observaciones que pertenecen al mismo cl√∫ster. La siguiente expresi√≥n relaciona ambos problemas\r\n\\[\r\n\\frac{1}{|C_k|}\\sum_{i,i'\\in C_k} \\sum_{j=1}^{p}(x_{ij}-x_{i¬¥j})^2 = 2\\sum_{i \\in C_k} \\sum_{j=1}^{p}(x_{ij}-x_{i¬¥j})^2\r\n\\]\r\nCl√∫stering jer√°rquico\r\nEl m√©todo de clustering jer√°rquico no requiere que se especif√≠que el n√∫mero de cl√∫sters al inicio.\r\nEl cl√∫stering jer√°rquico utiliza un dendograma\r\n\r\nLa construcci√≥n del dendograma es la siguiente:\r\nSe tiene un conjunto de observaciones \\(\\underline{x}_1,\\underline{x}_2,...,\\underline{x}_n\\) cada una de dimensi√≥n p.\r\nEl dendograma se construye de abajo hacia arriba. Hasta abajo se ponen todas las observaciones de manera separada; esto indica que cada observaci√≥n es su propio cl√∫ster, i.e.¬†se tienen \\(n\\) cl√∫sters.\r\nDespu√©s se ‚Äúfusionan‚Äù dos cl√∫sters en uno. As√≠, en el segundo nivel del dendograma se tienen \\(n-1\\) cl√∫sters: \\(n-2\\) con un elemento y 1 con dos observaciones.\r\nEl siguiente paso es crear un tercer nivel fusionando de nuevo 2 cl√∫sters.\r\nSe contin√∫a con este proceso hasta el nivel superior en el que todas las observaciones perteneces a un cl√∫ster.\r\n\r\nHay muchas formas de hacer estas ‚Äúfusiones‚Äù de dos cl√∫sters en uno en cada nivel.\r\nEn cada paso de la construcci√≥n del dendograma se debe determinar la disimilaridad (dissimilarity)\r\nExisten diferentes medidas de disimilaridad.\r\nLinkage: Disimilaridad entre 2 grupos de observaciones.\r\nHay 4 tipos de linkage populares:\r\nCompleto\r\nIndividual (single)\r\nPromedio (average)\r\nCentroide\r\n\r\nLinkage completo. Calcula la disimilaridad entre cada punto del cl√∫ster \\(A\\) y cada punto del cl√∫ster \\(B\\). El linkage completo entre \\(A\\) y \\(B\\) es la distancia m√°xima. Para calcular este, se hacen \\(|A|\\cdot|B|\\) distancias y se toma la m√°xima.\r\nLinkage individual. Calcula la disimilaridad entre cada punto del cl√∫ster \\(A\\) y cada punto del cl√∫ster \\(B\\). El linkage individual entre \\(A\\) y \\(B\\) es la distancia m√≠nima.\r\nObservaci√≥n. Este linkage lleva a cl√∫sters ‚Äúcolgantes‚Äù (trailing cl√∫sters), cl√∫sters en los que un punto a la vez se fusionan con un single cl√∫ster.\r\n\r\n\r\nLinkage promedio. Calcula la disimilaridad entre cada punto del cl√∫ster \\(A\\) y cada punto del cl√∫ster \\(B\\). El linage promedio entre \\(A\\) y \\(B\\) es el promedio de estas distancias.\r\nLinkage centroide. Calcula el centroide de cada cl√∫ster y usa la disimilaridad entre los centroides.\r\nObservaci√≥n. Bajo este m√©todo se tiene la desventaja de que pueden ocurrir ‚Äúinversores‚Äù (la disimilaridad de la fusi√≥n ‚Äúfutura‚Äù es menor que la disimilaridad de una fusi√≥n ‚Äúpasada‚Äù, involucrando los mismos puntos).\r\n\r\nUna vez que se contruy√≥ un dendograma, se puede determinar los cl√∫sters dibujando una recta horizontal en el dendograma.\r\nrecta arriba \\(\\rightarrow\\) pocos cl√∫sters.\r\nrecta abajo \\(\\rightarrow\\) muchos cl√∫sters.\r\n\r\n\r\nWithin-cluster-variation\r\n\\[\r\nW(C_k):=\\sum_{i \\in C_k} \\sum_{j=1}^{p}(x_{ij}- \\bar{x}_{kj})^2\\\\\r\nW_k := \\sum_{k=1}^KW(C_k)\r\n\\]\r\n\\(W_k\\) debe ser peque√±a\r\n\\(k \\mapsto W_k\\) es decreciente\r\n¬øIncrementa el n√∫mero de cl√∫sters? üò¢\r\n\r\nBetween-cluster-variation\r\n\\[\r\nb_k = \\sum_{k=1}^K|C_k|\\sum_{j=1}^{p}(\\bar{x}_{kj}-\\bar{x}_{j})^2\\\\\r\n\\text{\"La suma de las distancias entre los centroides\"}\r\n\\]\r\n\\(b_k\\) debe ser grande\r\n\\(k \\mapsto b_k\\) es creciente\r\n¬øIncrementa el n√∫mero de cl√∫sters? üò¢\r\n\r\n√çndice CH\r\n\\[\r\nCH_k:=\\frac{\\frac{b_k}{k-1}}{\\frac{W_k}{n-k}}\r\n\\]\r\nDonde \\(n\\) es el n√∫mero total de observaciones en el data-set.\r\nEl valor √≥ptimo para \\(k\\) es aquel que maximiza \\(CH_k\\)\r\n\r\n",
    "preview": {},
    "last_modified": "2021-05-25T21:47:33-05:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-05-14-rboles-2/",
    "title": "√Årboles 2",
    "description": "Parte 2 de √°rboles.",
    "author": [
      {
        "name": "Eduardo Selim M. M.",
        "url": {}
      },
      {
        "name": "Carlos A. Ar.",
        "url": {}
      }
    ],
    "date": "2021-05-10",
    "categories": [
      "arboles",
      "bootstrap",
      "bagging"
    ],
    "contents": "\r\n\r\nContents\r\nBootstrap, bagging y random forests\r\nBootstrap\r\nMuestras bootstrap\r\n\r\nBagging\r\n\r\nBootstrap, bagging y random forests\r\nBootstrap\r\nConsid√©rese un data set \\(D\\) con \\(n\\) observaciones, i.e.¬†\\(D\\) ser√° el conjunto de todas las observaciones en el data-set de entrenamiento.\r\n\\[\r\nD = \\{(x_1,y_1), ..., (x_n,y_n)\\}\r\n\\]\r\nLa variable respuesta es \\(y\\).\r\nEn la mayor√≠a de los modelos cl√°sicos, se obtiene un estimador puntual \\(\\hat{y}\\), bas√°ndose en el data-set.\r\nEl data set \\(D\\) es un conjunto de realizaciones independientes de una distribuci√≥n de probabilidad. Si se repite el an√°lisis con otro data-set (que es tambi√©n una relizaci√≥n de dicha distribuci√≥n de probabilidad) el estimado puntual ser√° diferente.\r\nPara estudiar el tipo de variabilidad de la predicci√≥n \\(\\hat{y}\\), se eval√∫a la sensitividad de la predicci√≥n respecto al data-set subyacente.\r\nBootstrapping es una herramineta para generar nuevos data-sets artificiales bas√°ndose en el data-set original.\r\nMuestras bootstrap\r\nEjemplo. Se tienen 5 observaciones \\((x_1,y_1), (x_1,y_1), ... (x_5,y_5)\\) cada observaci√≥n se etiqueta con un n√∫mero del 1 al 5. El n√∫mero de cada observaci√≥n se guarda en el conjunto \\(A\\).\r\nCuando se empieza aqu√≠ con el data-set original, cada n√∫mero aparece exactamente una vez en el conjunto \\(A: A=\\{1,2,3,4,5\\}\\)\r\nAhora se crear√° un nuevo conjunto de datos con 5 observaciones, seleccionando aleatoriamente 5 obs. del conjunto de datos inicial \\(A\\). Se permitir√° que la misma observaci√≥n sea incluida varias vices en el nuevo data set, i.e.¬†se seleccionar√°n aleatoriamente n√∫meros del conjunto \\(A\\) con reemplazo.\r\nLos n√∫meros en el nuevo data-set se guardar√°n en el conjunto \\(A_1\\). Por ejemplo, si \\(A_1 = \\{1, 4, 3, 5, 5\\}\\) entonces el nuevo data-set ser√° \\(D_1 = \\{(x_1, y_1),(x_4, y_4),(x_3, y_3),(x_5, y_5),(x_5, y_5)\\}\\)\r\nSe repetir√° esta construcci√≥n aleatoria de data-sets \\(B\\) veces, obteniendo data-sets \\(D_1, D_2, ..., D_B\\)\r\nA \\(D_1, D_2, ..., D_B\\) se les conoce como muestras bootstrap.\r\nHay a lo m√°s \\(n^n\\) muestras bootstrap\r\nLas muestras bootstrap son data-sets artificiales: estos dara-sets pudieron ocurrir pero nunca se observaron.\r\nConsid√©rese un data-set \\(D\\) con \\(n\\) observaciones \\(D = \\{(x_i,y_i):i=1,...n\\}\\)\r\nSe determinan \\(m\\) muestras bootstrap del data-set original. Sean \\(D_1, ..., D_m\\) dichas muestras bootstrap.\r\n¬øCu√°l es la probabilidad de que la primera observaci√≥n no aparezca en ninguna de las muestras bootstrap?\r\nObs√©rvese que para cualquier \\(j \\in \\{1, ..., m\\}\\)\r\n\\[\r\n\\mathbb{P}((x_1,y_1)\\notin D_j) = \\bigg(1-\\frac{1}{n}\\bigg)^n = \\bigg(\\frac{n-1}{n}\\bigg)^n \r\n\\]\r\nEntonces\r\n\\[\r\n\\mathbb{P}\\bigg((x_1,y_1)\\notin D_1 \\cup D_2 \\cup ... \\cup D_m\\bigg)\\\\\r\n=\\mathbb{P}\\bigg((x_1,y_1)\\notin D_1, (x_2,y_2)\\notin D_2, ..., (x_m,y_m)\\notin D_m\\bigg) \\\\\r\n= \\prod_{j=1}^m \\mathbb{P}\\bigg((x_1,y_1)\\notin D_j\\bigg)= \\bigg(\\mathbb{P}((x_1,y_1)\\notin D_j)\\bigg)^m\\\\\r\n = \\bigg(\\bigg(1-\\frac{1}{n}\\bigg)^n\\bigg)^m = \\bigg(1-\\frac{1}{n}\\bigg)^{nm}\\\\\r\n\\rightarrow_{n \\rightarrow \\infty} (e^{-1})^m = e^{-m} = (0.3678)^m\r\n\\]\r\n\r\nConclusi√≥n. Si se determina una muestra boostrap de un data set grande, aprox \\(\\frac{2}{3}\\) de las observaciones originales estar√°n en la muestra bootstrap y \\(\\frac{1}{3}\\) no aparecer√° en la muestra bootstrap.\r\nBagging\r\nUn √°rbol de decisi√≥n induce una varianza alta con diferentes data sets es probable que se encuentren √°rboles diferentes.\r\nComo se est√° utilizando un √∫nico √°rbol, no se obtiene un algor√≠tmo suficientemente estable.\r\n\r\nSe utiliza el concepto de bagging: se ajustan \\(B\\) √°rboles diferentes y se predice la respuesta utilizando cada √°rbol por separado. Una predicci√≥n final se obtiene ‚Äúpromediando‚Äù las B diferentes predicciones.\r\nRecordatorio: \\(\\mathbb{E}(\\bar{Y}) = \\mathbb{E}(Y), \\space Var(\\bar{Y}) = \\frac{Var(Y)}{n}\\) es decir \\(Var(\\bar{Y}) < Var(Y)\\)\r\nLa t√©cnica de bootstrap lleva a una reducci√≥n de varianza.\r\nCon el data-set original, se har√° un muestreo bootstrap y se obtendr√° un nuevo data-set \\(D_1\\)\r\nCon este data ser \\(D_1\\), se ajustar√° un √°rbol\r\n\\[\r\n\\hat{y}_1 = \\hat{f}_1(\\underline{x})\r\n\\] \\(\\hat{f}_1\\) es el √°rbol ajustado\r\n\\(\\hat{y}_1\\) es la predicci√≥n bas√°ndose en \\(\\hat{f}_1\\)\r\nObtenemos una segunda muestra bootstrap y ajustamos un √°rbol:\r\n\\[\r\n\\hat{y}_2 = \\hat{f}_2(\\underline{x})\r\n\\]\r\nContinuando con este procedimiento, se obtendr√°n \\(B\\) arboles \\(\\hat{f}_1, \\hat{f}_2, ..., \\hat{f}_B\\) y \\(B\\) predicciones \\(\\hat{y}_1, \\hat{y}_2, ..., \\hat{y}_B\\)\r\nEn caso de un √°rbol de regresi√≥n, los vamos a combinar de la siguiente manera\r\n\\[\r\n\\hat{f}^{bag}(\\underline{x}):= \\frac{1}{B}\\sum_{j=1}^{B}\\hat{f}_{j}(\\underline{x})\r\n\\]\r\nEn un √°rbol de clasificaci√≥n, se combina de la siguiente manera\r\n\\[\r\n\\hat{f}^{bag}(\\underline{x})=argmax\\{\\hat{f}_{j}(\\underline{x})\\}\r\n\\]\r\nObs: Un √°rbol individual, en muestra bagged puede tener un MSE menor que el √°rbol bagged.\r\nSe incrementa el n√∫mero de √°rboles individuales para avergiuar si el modelo mejora.\r\nEn caso de que se construya un √°rbol bagged incorporando un gran n√∫mero de √°rboles individuales el MSE (de prueba) ser√° m√°s estable que usa un n√∫mero peque√±o de √°rboles individuales.\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2021-05-25T21:43:12-05:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-05-12-rboles-de-decisin/",
    "title": "√Årboles 1",
    "description": "Parte 1 de √°rboles",
    "author": [
      {
        "name": "Eduardo Selim M. M.",
        "url": {}
      },
      {
        "name": "Carlos A. Ar.",
        "url": {}
      }
    ],
    "date": "2021-05-09",
    "categories": [
      "arboles"
    ],
    "contents": "\r\n\r\nContents\r\n¬øQu√© es un √°rbol de decisi√≥n?\r\n¬øC√≥mo se determinan las subregiones?\r\n\r\nLa funci√≥n de regresi√≥n\r\nDetalles de la construcci√≥n\r\nSplits binarios\r\nReglas de paro\r\nHojas de un √°rbol de decisi√≥n\r\nSplits binarios estandarizados\r\nSplits binarios estandarizados\r\n\r\nPredicciones\r\nBanda de split para √°rboles de regresi√≥n\r\nDefinici√≥n Suma de cuadrados\r\nSplit √≥ptimo\r\n\r\n√Årboles de clasificaci√≥n\r\nMisclassification error para el caso bidimensional\r\n\r\n\r\n¬øQu√© es un √°rbol de decisi√≥n?\r\nHay una variable aleatoria respuesta que se predecir√° utilizando un conjunto de variables explicativas (no aleatorias) que se conocen como variables explicativas. Es decir que es un modelo de aprendizaje supervisado.\r\nLa idea de un √°rbol de decisi√≥n es agrupar los datos en subregiones, en los que la variabilidad en cada subregi√≥n sea relativamente baja.\r\nLas subregiones se determinan usando las variables explicativas de las observaciones.\r\nUna vez que ‚Äúse decide‚Äù la subregi√≥n a la que pertenece una observaci√≥n, una predicci√≥n ser√° m√°s ‚Äúexacta‚Äù ya que la ‚Äúvariabilidad‚Äù en esta subregi√≥n es ‚Äúpeque√±a‚Äù.\r\n¬øC√≥mo se determinan las subregiones?\r\nUn √°rbol de decisi√≥n segmenta al espacio predictor en diferentes regiones utilizando splits binarios consecutivos. Se puede usar un modelo de predicci√≥n diferente en cada una de las subregiones\r\n\r\nSe har√° distinci√≥n entre:\r\n√Årboles de regresi√≥n: Respuesta continua\r\n√Årboles de clasificaci√≥n: Respuesta categ√≥rica.\r\n\r\nEn √°rboles de regresi√≥n, la calidad de las predicciones se puede evaluar midiendo la distancia entra la respuesta predecida y la respuesta observada. \\(y-\\hat{y}\\)\r\nEn √°rboles de clasificaci√≥n, la exactitud/calidad de las predicciones se puede determinar usando el misclasification error (la proporci√≥n de observaciones mal clasificadas). El objetivo es clasificar bien tantas observaciones como sea posible.\r\nSe supondr√° que hay \\(p\\) variables explicativas \\(X_1, X_2, ..., X_p\\) que se usar√°n para predecir una variable respuesta unidimensional \\(Y\\).\r\nSea \\(\\textbf{R}\\) el espacio predictor. El vector \\((X_1, ..., X_p)\\) toma valores en el espacio predictor, i.e.¬†\\((x_1, ..., x_p) \\in \\textbf{R}\\)\r\nLa funci√≥n de regresi√≥n\r\nLa variable respuesta \\(Y\\) es una variable aleatoria y se supone que se cumple la siguiente ecuaci√≥n \\[Y = f(\\underline{X}) +\\epsilon\\] Donde \\(f(\\underline{X}) = \\beta_0 + \\beta_1 X_1 + ... + \\beta_p X_p\\)\r\nLa funci√≥n de regresi√≥n \\(f\\) determina el ‚Äúefecto‚Äù (ojo: da la de causalidad) de las variables explicaticas en la variable respuesta \\(Y\\).\r\nEl t√©rmino de error \\(\\epsilon\\) es una variable aleatoria con media cero, que determina las fluctuaciones de la respuesta.\r\n\r\nConsid√©rese un data set con variables explicativas y respuesta. La idea es explicar c√≥mo se utilizan los √°rboles de decisi√≥n para estimar la funci√≥n \\(f\\). Dicha estimaci√≥n se denotar√° por \\(\\hat{f}\\).\r\nDado \\(\\underline{x}\\in\\textbf{R}\\), se estimar√° la respuesta \\(\\hat{y}\\) utilizando la funci√≥n \\(\\hat{f}\\), i.e.¬†\\[ \\hat{y} = \\hat{f}(\\underline{x})\\]\r\nLa pregunta principal a resolver ¬øCupal deber√≠a ser la respuesta predecida para una nueva observaci√≥n? Esta pregunta se resuelve en dos pasos:\r\n¬øA qu√© subregi√≥n pertenece la observaci√≥n de prueba?\r\n¬øCu√°l es la respuesta predecida en esta regi√≥n?\r\n\r\nDetalles de la construcci√≥n\r\nCuando se construye un √°rbol de decisi√≥n (ya sea de clasificaci√≥n o de regresi√≥n) hay 3 detalles a considerar:\r\nRegla de splitting √≥ptimo. ¬øC√≥mo dividir cada subregi√≥n en nuevas subregiones?\r\nRegla de paro: ¬øCu√°ndo se debe parar la divisi√≥n de una sibregi√≥n?\r\nModelo de predicci√≥n: ¬øCu√°l debe ser la respuesta predecida en cada subregi√≥n?\r\n\r\nUn √°rbol de decisi√≥n es una herramienta que proporciona un plan paso a paso de c√≥mo particionar al espacio predictor completo en subregiones a trav√©s de splits binarios consecutivos.\r\nObservaci√≥n: Existen algor√≠tmos de splitting m√°s complicados adem√°s del binario.\r\nSplits binarios\r\nSe empezar√° dividiendo al espacio predictor completo en 2 subregiones. Se llamar√° a \\(R\\) como nodo ra√≠z\r\nEntonces se dividir√° al nodo ra√≠z en 2 nuevos nodos. Estos 2 nodos deben ser dos subconjuntos disjuntos del nodo ra√≠z.\r\nSean \\(R_{00}\\) y \\(R_{01}\\) los nuevos subconjuntos que conforman al nodo ra√≠z, i.e.¬†\\[R = R_{00} \\cup R_{01}, R_{00} \\cap R_{01} = \\emptyset\\]\r\nSea \\(\\xi_0 := (R_{00}, R_{01})\\). Se dice que \\(\\xi_0\\) es un split bianrio de \\(R\\)\r\n\r\nNotaci√≥n: El primer d√≠gito en la notaci√≥n \\(R_{00}\\) (i.e.¬†‚Äú0‚Äù) denota la ‚Äúgeneraci√≥n‚Äù del nodo y el segundo d√≠gito (‚Äú0‚Äù √≥ ‚Äú1‚Äù) indica si el correspondiente subespacio es hijo izquierdo (\\(R_{00}\\)) √≥ hijo derecho (\\(R_{01}\\)) del nodo madre.\r\nEl espacio predictor \\(\\textbf{R}\\) es la generaci√≥n 0 y los dos nuevos espacios son la generaci√≥n 1.\r\nEl siguiente paso es dividir a ambos subconjuntos \\(R_{00}\\) y \\(R_{01}\\) y as√≠ sucesivamente PERO algunos nodos hijos no se dividen.\r\n\r\nSup√≥ngase que se tiene un nodo \\(R_t\\) en el √°rbol de decisi√≥n y que dicho nodo es de la generaci√≥n k, ie \\(t \\in \\{0, 1\\}^{k+1}\\) (i.e.¬†una sucesi√≥n de \\(0'^s\\) y \\(1'^s\\)).\r\nPor ejemplo, si la generaci√≥n es \\(k=4\\), \\(t\\) puede ser 00101, √≥ 00100, √≥ ‚Ä¶\r\nSe puede separar/dividir este nodo en hijo izquierdo \\(R_{t0}\\) y en hijo derecho \\(R_{t1}\\), usando el split binario \\(\\xi_t = (R_{t0}, R_{t1})\\), donde:\r\n\\(R_t = R_{t0} \\cup R_{t1}\\)\r\n\\(R_{t0} \\cap R_{t1} = \\emptyset\\)\r\n\r\nNotaci√≥n: \\(\\mathbb{T} = \\{t : R_t \\text{ es un nodo del √°rbol de decis√≥n}\\}\\)\r\n¬øCu√°ndo se detiene el splitting? Una regla de paro (stoping rule) determina si un noo dado se divide o no.\r\nReglas de paro\r\nEl objetivo es generar subregiones del espacio predictor completo tal que la variabilidad entre las respuestas en cada subregi√≥n sea suficientemente peque√±a para crear predicciones ‚Äúextra√±as‚Äù.\r\nEjemplo: ‚ÄúParar si el crecimiento en la variabilidad no es suficientemente significativa‚Äù.\r\nEjemplo: ‚ÄúParar si alguno de los nodos hijos (o el mismo padre) tiene pocos elementos‚Äù.\r\n\r\nHojas de un √°rbol de decisi√≥n\r\nCuando se aplica una regla de paro, se obtiene un conjunto de notos finales (nodos sin hijos).\r\nSe llama a estos nodos finales hojas. Los otros nodos se conocen como nodos internos.\r\nSe define al conjunto \\(\\tau\\) de la siguiente forma:\r\nEl nodo \\(R_t\\) es hoja si y s√≥lo si \\(t \\in \\tau\\)\r\n\\(\\tau\\) contiene todos los √≠ndices \\(t\\) tales que \\(R_t\\) es una hoja. Claramente \\(\\tau \\in \\mathbb{T}\\)\r\nPara hacer crecer un √°rbol de decisi√≥n, se aplica una sucesi√≥n finita de splits binarios. Por lo tanto \\(\\tau\\) contiene un n√∫mero finito de hojas.\r\nSe supondr√° que \\(|\\tau| = m\\). Para simplificar la notaci√≥n, se denotar√°n a las hojas por: \\(R_1, ..., R_m\\)\r\nSplits binarios estandarizados\r\nConsid√©rese un nodo \\(R_t\\) de la generaci√≥n \\(k\\)\r\nHay muchas maneras de dividir a este espacio en 2 nodos hijos nuevos (de la generaci√≥n \\(k+1\\))\r\nEl objetivo es buscar la ‚Äúmejor‚Äù divisi√≥n de un nodo dado. Pero dividir un conjunto en dos nuevos subconjuntos se puede volver muy complicado (El problema de optimizaci√≥n puede requerir muchos recursos y no ser√° factible)\r\n\r\nSe buscar√° el mejor split en la clase de los splits binarios estandarizados (computacionalmente factible y relativamente eficiente).\r\nSplits binarios estandarizados\r\nDefinici√≥n: Un split binario estandarizado \\(\\xi_t\\) de \\(R_t\\) divide a solo una dimensi√≥n predictora \\(l \\in \\{1, ..., p\\}\\) (\\(l\\) fija) en dos partes\r\n\r\nConsid√©rese el nodo \\(R_t\\) en un √°rbol de decisi√≥n que se dividir√° en 2 nuevos nodos hijos usando un split binario estandarizado.\r\nSup√≥ngase que la variable \\(x_l\\) es cuantitativa (donde \\(l\\) es la dimensi√≥n con la que se decidi√≥ hacer el split)\r\nEntonces el split binario estandarizado del conjunto \\(R_t\\) divide al espacio en 2 partes usando la constante \\(c \\in \\mathbb{R}\\). \\[(x_1, ...,. x_p) \\in R_{t0} \\iff x_l \\leq c\\]\r\n\\[(x_1, ...,. x_p) \\in R_{t1} \\iff x_l > c\\]\r\nSup√≥ngase que la variable \\(x_l\\) es categ√≥rica. En este caso, \\(x_l = c\\) se interpreta como ‚Äú\\(x_l\\) pertenece a la clase \\(c\\)‚Äù. Un split binario estandarizado para una variable categ√≥rica \\(x_l\\) se define de la siguiente forma: \\[(x_1, ...,. x_p) \\in R_{t0} \\iff x_l \\in C\\] donde \\(C\\) es un subconjunto de todas las posibles categor√≠as que \\(x_l\\) puede tomar.\r\nEjemplo\r\n\\[x_l \\in \\{\\text{\"mexicano\", \"estadounidence\", \"canadiense\"}\\}\\] \\[C = \\{\\text{\"mexicano\", \"canadiense\"}\\}\\]\r\nTe manda al nodo derecho si eres mexicano o canadiense.\r\n\r\n\r\n\\[ R_1 \\cup R_2 \\cup ... \\cup R_m =  R \\] \\[ R_1 \\cap R_2 \\cap ... \\cap R_m =  \\emptyset \\]\r\n\\[\r\ny = f(x) = \\sum_{i=1}^{m} \\lambda_i 1_{(\\underline{x} \\in R_i)} = \\begin{cases}\r\n \\lambda_1 &\\text{ si } \\underline{x} \\in R_1\\\\         \r\n \\lambda_2 &\\text{  si  } \\underline{x} \\in R_2\\\\\r\n...\\\\\r\n\\lambda_m &\\text{ si } \\underline{x} \\in R_m        \r\n\\end{cases}\r\n\\]\r\nPredicciones\r\nSup√≥ngase que se tienen \\(p\\) variables explicativas \\(X_1, X_2, ..., X_p\\) y un √°rbol de decisi√≥n que particiona al espacio predictor en hojas \\(R_1, R_2, ..., R_m\\)\r\nConsid√©rese un vector \\(\\underline{x} \\in R\\). La respuesta \\(y = f(x)\\) se determina de la siguiente forma \\[f(x) = \\sum_{i=1}^{m} \\lambda_i 1_{(\\underline{x} \\in R_i)}\\]\r\ndonde se predice la respuesta usando una constante diferente \\(\\lambda_i\\) en cada hoja \\(R_i\\), es decir, \\(\\lambda_i\\) predice a \\(y\\), en la hoja \\(R_i\\)\r\n\r\nBanda de split para √°rboles de regresi√≥n\r\nSup√≥ngase que las variables respuesta y explicativas son cuantitativas.\r\nHay \\(p\\) variables explicativas \\(x_1, x_2, ..., x_p\\) y se tiene que decidir cu√°l de √©stas usar para dividir el espacio predictor.\r\nAdem√°s, una vez que se decidi√≥ que variable explicativa usar para dividir el espacio, se tiene que decidir d√≥nde dividir √©sta variable, es decir, encontrar el punto de corte \\(c\\)\r\nPor lo tanto, seleccionar un split √≥ptimo se reduce a determinar la variable explicativa \\(x_l\\) y una constante \\(c\\)\r\n\\[ R_{t0}  = \\{\\underline{x} \\in R_t : x_l \\leq c\\}\\]\r\n\\[ R_{t1}  = \\{\\underline{x} \\in R_t : x_l > c\\}\\]\r\nAdem√°s sup√≥ngase que el valor predecido dentro de la regi√≥n \\(R_{t0}\\) es \\(\\lambda_0\\) y dentro de la regi√≥n \\(R_{t1}\\) es \\(\\lambda_1\\)\r\n\\[\r\nf(x)= \\begin{cases}\r\n \\lambda_1 &\\text{ si } \\underline{x} \\in R_{t0}\\\\         \r\n \\lambda_2 &\\text{  si  } \\underline{x} \\in R_{t1}\r\n\\end{cases}\r\n\\]\r\nDefinici√≥n Suma de cuadrados\r\n\\[\r\nSS(l,c;\\lambda_0, \\lambda_1) = \\sum_{\\underline{x}_i \\in R_{t0}} (y_i - \\lambda_0)^2 + \\sum_{\\underline{x}_i \\in R_{t1}} (y_i - \\lambda_1)^2 \r\n\\]\r\nSplit √≥ptimo\r\nEl mejor split se define como el split que minimiza la suma de los cuadrados. Por lo tanto, se busca resolver el siguiente problema de minimizaci√≥n\r\n\\[ \r\n\\min_{l,c} \\bigg\\{ \\min_{\\lambda_0} \\sum_{\\underline{x}_i \\in R_{t0}} (y_i - \\lambda_0)^2 + \\min_{\\lambda_1} \\sum_{\\underline{x}_i \\in R_{t1}} (y_i - \\lambda_1)^2 \\bigg\\}\r\n\\]\r\nLos dos problemas de optimizaci√≥n ‚Äúinternos‚Äù se resuelven f√°cilmente:\r\n\\[\r\n\\hat{\\lambda_0} = \\frac{1}{n_{t0}} \\sum_{\\underline{x}_i \\in R_{t0}} y_i  = \\frac{1}{|R_{t0}|} \\sum_{\\underline{x}_i \\in R_{t0}} y_i  \r\n\\]\r\n\\[\r\n\\hat{\\lambda_0} = \\frac{1}{n_{t0}} \\sum_{\\underline{x}_i \\in R_{t0}} y_i  = \\frac{1}{|R_{t0}|} \\sum_{\\underline{x}_i \\in R_{t0}} y_i  \r\n\\]\r\n\r\nSup√≥ngase que una observaci√≥n \\(\\underline{x} \\in R_{t0}\\) ¬øCu√°l deber√≠a ser la predicci√≥n de \\(\\hat{y}\\)? \\(\\hat{y} := \\hat{\\lambda_0}\\)\r\nEn general la minimizaci√≥n exterior se hace num√©ricamente.\r\nConsid√©rese un nodo \\(R_t\\) que tiene \\(n\\) elementos. Sean \\(y_1, ..., y_n\\) las respuestas y \\(\\underline{x}_1, ..., \\underline{x}_n\\) las correspondientes variables explicativa.\r\nLa suma de los cuadrados, de este nodo, se define como:\r\n\\[\r\nSS(y) := \\sum_{i=1}^n (y_i - \\bar{y})^2\r\n\\]\r\n\r\nSup√≥ngase que se separa a este nodo en un hijo izquierdo y derecho minimizando la suma de cuadrados. La correspondiente suma de cuadrados se denota por \\(SS(\\hat{\\lambda_0}, \\hat{\\lambda_1})\\)\r\nEntonces\r\n\\[SS(\\hat{\\lambda_0}, \\hat{\\lambda_1}) \\leq SS(\\bar{y})\\]\r\nEs decir, \\(SS(\\hat{\\lambda_0}, \\hat{\\lambda_1})\\) est√° acotado por arriba por \\(SS(\\bar{y})\\)\r\n√Årboles de clasificaci√≥n\r\nSe tiene un problema de clasificaci√≥n, cada variable \\(y_i\\) denota cierta clase\r\nSup√≥ngase que hay \\(K\\) clases y que est√°n etiquetadas por los n√∫meros \\(1, 2, ..., K\\)\r\n\r\nConsid√©rese un √°rbol de decisi√≥n con \\(m\\) hojas, denotadas por \\(R_1, R_2, ..., R_m\\)\r\n\\(n_j\\): n√∫mero de observaciones que caen en la hoja \\(R_j\\)\r\n\\(n = n_1 + n_2 + ... + n_m\\)\r\n\r\nSe debe predecir a qu√© clase pertenece un vector predictor \\(\\underline{x}_i\\),\r\n¬øQui√©n debe ser \\(f(\\underline{x}_i)\\) si sabemos que \\(\\underline{x}_i \\in R_i\\)?\r\nUn √°rbol de clasificaci√≥n es adecuado, si es capaz de asignar la clase correcta a la mayor√≠a de las observaciones.\r\nEn cada hoja del √°rbol, se tiene que decidir qu√© clase asignar\r\nLa predicci√≥n en cierta hoja corresponde a la clase que m√°s se repite.\r\nEsta metodolog√≠a se reduce a minimizar la tasa de misclassification, i.e.¬†minimizar la probabilidad de que una observaci√≥n seleccionada aleatoriamente de esta hoja est√© mal clasificada.\r\nLa mejor situaci√≥n ocurre cuando todas las observaciones de una hoja pertenecen a la misma clase (no hay duda cuando se asigna la predicci√≥n en esta hoja y todas las observaciones en esta hoja est√°n correctamente clasificadas.)\r\nnodo puro: nodo en el que todas las observaciones pertenecen a la misma clase.\r\nSup√≥ngase que se construy√≥ un √°rbol de clasificaci√≥n con m hojas.\r\nLa mejor situaci√≥n ocurre cuando todas las m hojas del √°rbol son nodos puros (se puede clasificar a todas las observaciones de entrenamiento correctamente, usando las m hojas)\r\nCuando se construye un √°rbol de clasificaci√≥n, se separa cada nodo en 2 nodos hijos. Se buscan splits que generen nodos hijos que sean ‚Äútan puros como sea posible‚Äù.\r\nSe necesita cuantificar el grado de impureza de un nodo.\r\n\\(P_j\\) cuantifica el grado de impureza del nodo de la hoja \\(R_j\\)\r\nSi la hoja \\(R_l\\) es pura, entonces \\(P_l = 0\\)\r\nMientras m√°s grande sea \\(P_j\\), ‚Äúm√°s impura‚Äù ser√° la hoja \\(R_j\\)\r\n\\(P_j\\) grande \\(\\rightarrow\\) \\(R_j\\) muy impura\r\nSe define la frecuencia de la clase \\(k\\) en la hoja \\(j\\) denotada por \\(\\hat{P}_{jk}\\) donde \\(j\\) representa la hoja y \\(k\\) representa la clase como \\[\\hat{P}_{jk} = \\frac{1}{n_j}\\sum_{\\underline{x}_i \\in R_j}1_{(y_i = k)} \\]\r\n\\(\\hat{P}_{jk}\\) se puede interpretar como la probabilidad emp√≠rica de que una observaci√≥n caiga en la clase \\(k\\), dado que la observaci√≥n pertenece a la hoja \\(R_j\\).\r\nSe considerar√°n 3 medidas de impureza de un nodo:\r\nMisclassification error\r\n√≠ndice de Gini\r\nEntrop√≠a cruzada\r\n\r\nDefinici√≥n. Se define el misclassification error de una hoja \\(R_j\\) como\r\n\\[\r\nE_j := 1- \\max_{k}\\{\\hat{P}_{jk}\\}\r\n\\]\r\nObservaci√≥n:\r\n\\[\r\nE_j = 0 \\iff 1=\\max_{k}\\{\\hat{P}_{jk}\\} \\iff \\max\\{\\hat{P}_{j1}, \\hat{P}_{j2}, ...,\\hat{P}_{jk}\\} \\rightarrow \\exists l \\text{  tal que } \r\n\\] \\[\r\n\\hat{P}_{jl} = 1 \\text{ lo cual implica que los elementos de la hoja }j\\text{ son de la clase } l\r\n\\]\r\n\\(E_j = 0 \\rightarrow\\) Todos los \\(y_i'^{s}\\) en la hoja \\(R_j\\) son de una clase \\(l\\), i.e.¬†la hoja es pura.\r\nUna hoja \\(R_j\\) que es pura, tiene un misclassification error \\(E_j = 0\\)\r\nMientras m√°s grande sea \\(E_j\\), m√°s alta ser√° la impureza de \\(R_j\\)\r\n\\[\r\nE_j \\uparrow \\space \\rightarrow \\space \\text{Pureza de }R_j \\downarrow\r\n\\]\r\nMientras m√°s alto sea el grado de impureza, m√°s dif√≠cil ser√° predecir la clase correctamente en esa hoja particular.\r\nMisclassification error para el caso bidimensional\r\nPara el nodo \\(R_j\\) de un √°rbol de clasificaci√≥n, sup√≥ngase que hay 2 clases para respuesta: 0 √≥ 1.\r\n\\[\r\n\\hat{P} := \\hat{P}_{j0}, \\space 1-\\hat{P} = \\hat{P}_{j1} \\\\\r\nE = 1-\\max\\{p, 1-p\\}\r\n\\]\r\nLa aplicaci√≥n \\(p \\mapsto E\\) no es diferenciable y tiene un m√°ximo en \\(p = \\frac{1}{2}\\)\r\n\r\nDefinici√≥n. Se define el √≠ndice de Gini de la hoja \\(R_j\\) como\r\n\\[\r\nG_j := \\sum_{l = 1}^{k}\\hat{P}_{jl}(1-\\hat{P}_{jl})\r\n\\]\r\nDefinici√≥n. Se define la cross-entropy de la hoja \\(R_j\\) como\r\n\\[\r\nD_j := -\\sum_{l = 1}^{k}\\hat{P}_{jl}\\log(\\hat{P}_{jl})\r\n\\]\r\nPara un nodo \\(R_j\\) de un √°rbol de clasificaci√≥n, sup√≥ngase que hay 2 clases para la respuesta (0 √≥ 1).\r\n\\[\\hat{P}:=\\hat{P}_{j0} \\space 1-\\hat{P}=\\hat{P}_{j1}\\\\ G = 2p(1-p) = 2p-2p^2\\]\r\nLa aplicaci√≥n \\(p \\mapsto G\\) s√≠ es diferenciable y tiene un m√°ximo en \\(p = \\frac{1}{2}\\)\r\nObservaci√≥n:\r\n\r\nSi \\(p=1\\), entonces \\(G = 0\\) y todas las observaciones pertenecen a la clase 0\r\nSi \\(p=0\\), entonces \\(G = 1\\) y todas las observaciones pertenecen a la clase 1\r\n\\[\r\nD = -[p\\log(p) + (1-p)\\log(1-p)] \\space \\text{cross entropy}\r\n\\]\r\nLa aplicaci√≥n \\(p \\mapsto D\\) s√≠ es diferenciable y tiene un m√°ximo en \\(p = \\frac{1}{2}\\)\r\nDemostraci√≥n:\r\n\\[\r\nD¬¥(p) = -[\\log(p)-\\log(1-p)] \\rightarrow D¬¥(p) = 0 \\iff p = \\frac{1}{2} \\\\\r\nD¬¥¬¥(p) = -\\bigg[\\frac{1}{p}+\\frac{1}{1-p}\\bigg] \\rightarrow D¬¥¬¥(\\frac{1}{2}) = -4 < 0_{._\\Box}\r\n\\]\r\nTanto en el √≠ndice de Gini y el cross-entropy, la impureza se maximiza en \\(p=\\frac{1}{2}\\) y entonces la mitad de las hojas pertenecen a la clase 1 y la otra mitad a la clase 0.\r\n\r\n",
    "preview": "posts/2021-05-12-rboles-de-decisin/images/arboles1_3.png",
    "last_modified": "2021-05-15T00:08:44-05:00",
    "input_file": {}
  },
  {
    "path": "posts/welcome/",
    "title": "¬øDe qu√© trata el blog?",
    "description": "¬°La informaci√≥n aqu√≠ presentada es para consultar teor√≠a de Ciencia de Datos que adem√°s se implementa con el programa R!",
    "author": [
      {
        "name": "Eduardo Selim M. M.",
        "url": {}
      },
      {
        "name": "Carlos A. Ar.",
        "url": {}
      }
    ],
    "date": "2021-05-08",
    "categories": [],
    "contents": "\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2021-05-15T00:10:04-05:00",
    "input_file": {}
  }
]
